[
  {
    "id": "XuFhpLTdN-",
    "type": "header",
    "data": {
      "text": "Procrustes Analysis",
      "level": 1
    },
    "index": 0,
    "createdBy": "prizeiskrp",
    "lastEditedBy": "prizeiskrp",
    "topic": "dypjmnttvw"
  },
  {
    "id": "Rw2itgH6Tg",
    "type": "code",
    "data": {
      "code": "import numpy as np\nfrom scipy.linalg import orthogonal_procrustes\nimport matplotlib.pyplot as plt\n\ndef translation_matrix_3d(dx, dy):\n    return np.array([\n        [1, 0, dx],\n        [0, 1, dy],\n        [0, 0, 0],\n    ])\n\ndef rotation_matrix(angle_rad):\n    cos_angle = np.cos(angle_rad)\n    sin_angle = np.sin(angle_rad)\n    return np.array([[cos_angle, -sin_angle], [sin_angle, cos_angle]])\n\ndef scaling_matrix_3d(sx, sy):\n    return np.array([\n        [sx, 0],\n        [0, sy]\n    ])\n\ndef min_max_normalization(data):\n    return (data - np.min(data)) / (np.max(data) - np.min(data))\n\ndef standard_normalization(landmarks):\n    mean_val = np.mean(landmarks, axis=0)\n    std_val = np.std(landmarks, axis=0)\n    return (landmarks - mean_val) / std_val\n\n# https://en.wikipedia.org/wiki/Procrustes_analysis\ndef compute_procrustes_similarity(shape1, shape2):\n  procrustes_distance = np.sqrt(((shape2 - shape1)**2).sum())\n  return max(1-round(procrustes_distance,3),0)\n\ndef compute_procrustes(shape1, shape2):\n    shape1 = shape1.astype(float)\n    shape2 = shape2.astype(float)\n    R, scale = orthogonal_procrustes(shape1, shape2)\n    transformed_shape1 = scale * shape1.dot(R)\n    return transformed_shape1, compute_procrustes_similarity(shape2,transformed_shape1)\n\ndef standard_normalization(shape):\n    shape = shape.astype(float)\n    # centering the shape\n    shape -= np.mean(shape, axis=0)\n    # scale the shape\n    shape /= np.sqrt((shape**2).sum())\n    return shape",
      "language": "python",
      "output": "undefined"
    },
    "index": 1,
    "createdBy": "prizeiskrp",
    "lastEditedBy": "mhqyrebaxg",
    "topic": "dypjmnttvw"
  },
  {
    "id": "Eu53D-ftPW",
    "type": "code",
    "data": {
      "code": "# Landmarks\nhand_open = np.array([\n    [\n        0.3862111568450928,\n        0.9403453469276428\n    ],\n    [\n        0.444118857383728,\n        0.8816303610801697\n    ],\n    [\n        0.4814566373825073,\n        0.7915549278259277\n    ],\n    [\n        0.4956647753715515,\n        0.7123805284500122\n    ],\n    [\n        0.508569598197937,\n        0.6401602625846863\n    ],\n    [\n        0.3920263648033142,\n        0.6721675395965576\n    ],\n    [\n        0.36959102749824524,\n        0.566619336605072\n    ],\n    [\n        0.35014912486076355,\n        0.5084306001663208\n    ],\n    [\n        0.330780029296875,\n        0.45730119943618774\n    ],\n    [\n        0.3367011249065399,\n        0.6862635612487793\n    ],\n    [\n        0.2997554540634155,\n        0.5753514766693115\n    ],\n    [\n        0.27116623520851135,\n        0.5118122100830078\n    ],\n    [\n        0.24341821670532227,\n        0.45756709575653076\n    ],\n    [\n        0.29331904649734497,\n        0.7259061932563782\n    ],\n    [\n        0.2509540319442749,\n        0.6312907338142395\n    ],\n    [\n        0.22074800729751587,\n        0.5784557461738586\n    ],\n    [\n        0.19168047606945038,\n        0.5311246514320374\n    ],\n    [\n        0.2582094669342041,\n        0.7830571532249451\n    ],\n    [\n        0.21213380992412567,\n        0.7309069633483887\n    ],\n    [\n        0.17972202599048615,\n        0.6970048546791077\n    ],\n    [\n        0.14870686829090118,\n        0.6620938777923584\n    ]\n])",
      "language": "python",
      "output": "undefined"
    },
    "index": 2,
    "createdBy": "prizeiskrp",
    "lastEditedBy": "mhqyrebaxg",
    "topic": "dypjmnttvw"
  },
  {
    "id": "zZaJuJ08SZ",
    "type": "code",
    "data": {
      "code": "import js\n\ngoals = [\n  standard_normalization((rotation_matrix(np.pi)@hand_open.T).T)\n]\n\ndef close_to_goal_pose(landmarks, goal=0):\n input_pose = standard_normalization(np.array(landmarks.to_py()))\n _, procrustes_similarity = compute_procrustes(input_pose, goals[goal])\n return procrustes_similarity\n\njs.window.close_to_goal_pose = close_to_goal_pose",
      "language": "python",
      "output": "undefined"
    },
    "index": 3,
    "createdBy": "prizeiskrp",
    "lastEditedBy": "mhqyrebaxg",
    "topic": "dypjmnttvw"
  },
  {
    "id": "325Rqx4Ait",
    "type": "header",
    "data": {
      "text": "Hand open or close",
      "level": 2
    },
    "index": 4,
    "createdBy": "mhqyrebaxg",
    "lastEditedBy": "mhqyrebaxg",
    "topic": "dypjmnttvw"
  },
  {
    "id": "PLrjW8wXQm",
    "type": "code",
    "data": {
      "code": "<video id=\"webcam\" style=\"width: 1280px; height: 720px;\" autoplay playsinline></video>\n<script type=\"module\">\nimport {HandLandmarker,FilesetResolver,DrawingUtils} from \"https://cdn.skypack.dev/@mediapipe/tasks-vision@0.10.0\";\nconst vision = await FilesetResolver.forVisionTasks(\"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm\");\nconst handLandmarker = await HandLandmarker.createFromOptions(vision, {\n    baseOptions: {\n      modelAssetPath: `https://storage.googleapis.com/mediapipe-models/hand_landmarker/hand_landmarker/float16/1/hand_landmarker.task`,\n      delegate: \"GPU\"\n    },\n    runningMode: \"video\",\n    numHands: 1\n});\n\nlet lastVideoTime = -1;\nasync function predictWebcam() {\n    let startTimeMs = performance.now();\n    if (lastVideoTime !== video.currentTime) {\n        lastVideoTime = video.currentTime;\n        const results = handLandmarker.detectForVideo(video, startTimeMs);\n        if (results.landmarks.length !== 0) {\n          const hand = results.landmarks[0].map(l => ([l.x, l.y]))\n          console.log(close_to_goal_pose(hand) > 0.65)\n        }\n    }\n    requestAnimationFrame(predictWebcam); \n}\nconst video = document.getElementById(\"webcam\");\nconst stream = await navigator.mediaDevices.getUserMedia({video: true, audio: false});\nvideo.srcObject = stream;\nvideo.addEventListener(\"loadeddata\", predictWebcam);\n</script>",
      "language": "html",
      "output": ""
    },
    "index": 5,
    "createdBy": "prizeiskrp",
    "lastEditedBy": "mhqyrebaxg",
    "topic": "dypjmnttvw"
  },
  {
    "id": "gs6ZA0WKoh",
    "type": "header",
    "data": {
      "text": "Find your goal pose",
      "level": 2
    },
    "index": 6,
    "createdBy": "mhqyrebaxg",
    "lastEditedBy": "mhqyrebaxg",
    "topic": "dypjmnttvw"
  },
  {
    "id": "9gLkc9ywrH",
    "type": "code",
    "data": {
      "code": "<button onclick=\"savePose()\">Save your pose</button>\n<script>\n  window.reachPose = false;\n   function savePose() {\n      window.reachPose = true;\n   }\n</script>",
      "language": "html",
      "output": "<button onclick=\"savePose()\">Save your pose</button>\n<script>\n  window.reachPose = false;\n   function savePose() {\n      window.reachPose = true;\n   }\n</script>"
    },
    "index": 7,
    "createdBy": "mhqyrebaxg",
    "lastEditedBy": "mhqyrebaxg",
    "topic": "dypjmnttvw"
  },
  {
    "id": "orJN3-HXNS",
    "type": "code",
    "data": {
      "code": "<video id=\"webcam\" style=\"width: 1280px; height: 720px;\" autoplay playsinline></video>\n<script type=\"module\">\nimport {PoseLandmarker,FilesetResolver,DrawingUtils} from \"https://cdn.skypack.dev/@mediapipe/tasks-vision@0.10.0\";\nconst vision = await FilesetResolver.forVisionTasks(\"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm\");\nconst poseLandmarker = await PoseLandmarker.createFromOptions(vision, {\n    baseOptions: {\n        modelAssetPath: `https://storage.googleapis.com/mediapipe-models/pose_landmarker/pose_landmarker_full/float16/latest/pose_landmarker_full.task`,\n        delegate: \"GPU\"\n    },\n    runningMode: \"video\",\n    numPoses: 1,\n    minPoseDetectionConfidence: 0.8,\n    minPosePresenceConfidence: 0.8,\n    minTrackingConfidence: 0.8\n});\n\nconst video = document.getElementById(\"webcam\");\nconst stream = await navigator.mediaDevices.getUserMedia({video: true, audio: false});\nvideo.srcObject = stream;\nvideo.play();\n\nlet lastVideoTime = -1;\nasync function predictWebcam() {\n    let startTimeMs = performance.now();\n    if (lastVideoTime !== video.currentTime) {\n        lastVideoTime = video.currentTime;\n        poseLandmarker.detectForVideo(video, startTimeMs, (result) =>  {\n             if (result.landmarks.length === 0) {\n               return;\n             }\n             if (window.reachPose) {\n                const body = result.landmarks[0].map(l => ([l.x, l.y]));  \n                console.log(body);\n                window.reachPose = false;\n             }\n          }\n        );\n    }\n   window.requestAnimationFrame(predictWebcam);\n}\nvideo.addEventListener(\"loadeddata\", predictWebcam);\n</script>",
      "language": "html",
      "output": ""
    },
    "index": 8,
    "createdBy": "mhqyrebaxg",
    "lastEditedBy": "mhqyrebaxg",
    "topic": "dypjmnttvw"
  },
  {
    "id": "NgZG3mvUzA",
    "type": "header",
    "data": {
      "text": "Replication",
      "level": 2
    },
    "index": 9,
    "createdBy": "prizeiskrp",
    "lastEditedBy": "mhqyrebaxg",
    "topic": "dypjmnttvw"
  }
]