[
  {
    "id": "vd8DWis0oq",
    "type": "paragraph",
    "data": {
      "text": ""
    },
    "index": -1,
    "createdBy": "f313b510-8ff6-4ef7-8c27-070c2ae45fc1",
    "lastEditedBy": "f313b510-8ff6-4ef7-8c27-070c2ae45fc1",
    "topic": "c70506cc-aefb-479a-9eee-9f7ef37b9d2c",
    "crdts": {
      "operations": [
        [
          {
            "creator": "pkhexmkwbs",
            "body": [
              {
                "ifMatch": {
                  "$set": {
                    "id": "vd8DWis0oq",
                    "type": "paragraph",
                    "data": {
                      "text": ""
                    },
                    "index": 0,
                    "createdBy": "f313b510-8ff6-4ef7-8c27-070c2ae45fc1",
                    "lastEditedBy": "f313b510-8ff6-4ef7-8c27-070c2ae45fc1",
                    "topic": "c70506cc-aefb-479a-9eee-9f7ef37b9d2c"
                  }
                }
              }
            ],
            "time": 1684302235317.02
          }
        ]
      ],
      "hash": "c38f034b4211d95d8c7112f3ab63c9bd0449b6514210149d470042b2d931c71d"
    },
    "_meta": {
      "lwt": 1684302238004.02
    },
    "_deleted": false,
    "_attachments": {},
    "_rev": "2-lxgnmepxds"
  },
  {
    "id": "V790qmV3Ym",
    "type": "header",
    "data": {
      "text": "Track human from image",
      "level": 1
    },
    "index": 1,
    "createdBy": "f313b510-8ff6-4ef7-8c27-070c2ae45fc1",
    "lastEditedBy": "f313b510-8ff6-4ef7-8c27-070c2ae45fc1",
    "topic": "c70506cc-aefb-479a-9eee-9f7ef37b9d2c",
    "crdts": {
      "operations": [
        [
          {
            "creator": "pkhexmkwbs",
            "body": [
              {
                "ifMatch": {
                  "$set": {
                    "id": "V790qmV3Ym",
                    "type": "header",
                    "data": {
                      "text": "",
                      "level": 2
                    },
                    "index": 1,
                    "createdBy": "f313b510-8ff6-4ef7-8c27-070c2ae45fc1",
                    "lastEditedBy": "f313b510-8ff6-4ef7-8c27-070c2ae45fc1",
                    "topic": "c70506cc-aefb-479a-9eee-9f7ef37b9d2c"
                  }
                }
              }
            ],
            "time": 1684303671213.01
          }
        ],
        [
          {
            "body": [
              {
                "ifMatch": {
                  "$set": {
                    "data": {
                      "text": "Trac",
                      "level": 2
                    },
                    "index": 1,
                    "lastEditedBy": "f313b510-8ff6-4ef7-8c27-070c2ae45fc1",
                    "_deleted": false
                  }
                }
              }
            ],
            "creator": "pkhexmkwbs",
            "time": 1684303673792.06
          }
        ],
        [
          {
            "body": [
              {
                "ifMatch": {
                  "$set": {
                    "data": {
                      "text": "Track&nbsp;",
                      "level": 2
                    },
                    "index": 1,
                    "lastEditedBy": "f313b510-8ff6-4ef7-8c27-070c2ae45fc1",
                    "_deleted": false
                  }
                }
              }
            ],
            "creator": "pkhexmkwbs",
            "time": 1684303674472.01
          }
        ],
        [
          {
            "body": [
              {
                "ifMatch": {
                  "$set": {
                    "data": {
                      "text": "Track human from&nbsp;",
                      "level": 2
                    },
                    "index": 1,
                    "lastEditedBy": "f313b510-8ff6-4ef7-8c27-070c2ae45fc1",
                    "_deleted": false
                  }
                }
              }
            ],
            "creator": "pkhexmkwbs",
            "time": 1684303676280.01
          }
        ],
        [
          {
            "body": [
              {
                "ifMatch": {
                  "$set": {
                    "data": {
                      "text": "Track human from image",
                      "level": 2
                    },
                    "index": 1,
                    "lastEditedBy": "f313b510-8ff6-4ef7-8c27-070c2ae45fc1",
                    "_deleted": false
                  }
                }
              }
            ],
            "creator": "pkhexmkwbs",
            "time": 1684303677696.01
          }
        ],
        [
          {
            "body": [
              {
                "ifMatch": {
                  "$set": {
                    "data": {
                      "text": "Track human from image",
                      "level": 1
                    },
                    "index": 1,
                    "lastEditedBy": "f313b510-8ff6-4ef7-8c27-070c2ae45fc1",
                    "_deleted": false
                  }
                }
              }
            ],
            "creator": "pkhexmkwbs",
            "time": 1684303680374.06
          }
        ]
      ],
      "hash": "0d9344d4efd2ec3738b06d629d44ced084cf27009822ea86d7ba3171584c6731"
    },
    "_meta": {
      "lwt": 1684303680375.01
    },
    "_deleted": false,
    "_attachments": {},
    "_rev": "7-lxgnmepxds"
  },
  {
    "id": "rL2m3m3pob",
    "type": "code",
    "data": {
      "code": "`<img id=\"webcam\" crossorigin src=\"https://www.gannett-cdn.com/presto/2021/01/27/PMCA/3b34404e-8401-4a6d-9d30-38dbe9a274d4-244ff25c-ef77-4d64-9bbc-d0e64ea6de3e_thumbnail.png?width=1280&height=720&fit=crop&format=pjpg&auto=webp\">`",
      "language": "javascript",
      "output": ""
    },
    "index": 2,
    "createdBy": "f313b510-8ff6-4ef7-8c27-070c2ae45fc1",
    "lastEditedBy": "f313b510-8ff6-4ef7-8c27-070c2ae45fc1",
    "topic": "c70506cc-aefb-479a-9eee-9f7ef37b9d2c",
    "crdts": {
      "operations": [
        [
          {
            "creator": "pkhexmkwbs",
            "body": [
              {
                "ifMatch": {
                  "$set": {
                    "id": "rL2m3m3pob",
                    "type": "code",
                    "data": {
                      "code": "",
                      "language": "javascript",
                      "output": ""
                    },
                    "index": 2,
                    "createdBy": "f313b510-8ff6-4ef7-8c27-070c2ae45fc1",
                    "lastEditedBy": "f313b510-8ff6-4ef7-8c27-070c2ae45fc1",
                    "topic": "c70506cc-aefb-479a-9eee-9f7ef37b9d2c"
                  }
                }
              }
            ],
            "time": 1684303683641.01
          }
        ],
        [
          {
            "body": [
              {
                "ifMatch": {
                  "$set": {
                    "data": {
                      "code": "`<img id=\"webcam\" crossorigin src=\"https://www.gannett-cdn.com/presto/2021/01/27/PMCA/3b34404e-8401-4a6d-9d30-38dbe9a274d4-244ff25c-ef77-4d64-9bbc-d0e64ea6de3e_thumbnail.png?width=1280&height=720&fit=crop&format=pjpg&auto=webp\">`",
                      "language": "javascript",
                      "output": ""
                    },
                    "index": 2,
                    "lastEditedBy": "f313b510-8ff6-4ef7-8c27-070c2ae45fc1",
                    "_deleted": false
                  }
                }
              }
            ],
            "creator": "pkhexmkwbs",
            "time": 1684303691592.01
          }
        ],
        [
          {
            "body": [
              {
                "ifMatch": {
                  "$set": {
                    "data": {
                      "code": "`<img id=\"webcam\" crossorigin src=\"https://www.gannett-cdn.com/presto/2021/01/27/PMCA/3b34404e-8401-4a6d-9d30-38dbe9a274d4-244ff25c-ef77-4d64-9bbc-d0e64ea6de3e_thumbnail.png?width=1280&height=720&fit=crop&format=pjpg&auto=webp\">`",
                      "language": "javascript",
                      "output": "<img id=\"webcam\" crossorigin=\"\" src=\"https://www.gannett-cdn.com/presto/2021/01/27/PMCA/3b34404e-8401-4a6d-9d30-38dbe9a274d4-244ff25c-ef77-4d64-9bbc-d0e64ea6de3e_thumbnail.png?width=1280&amp;height=720&amp;fit=crop&amp;format=pjpg&amp;auto=webp\">"
                    },
                    "index": 2,
                    "lastEditedBy": "f313b510-8ff6-4ef7-8c27-070c2ae45fc1",
                    "_deleted": false
                  }
                }
              }
            ],
            "creator": "pkhexmkwbs",
            "time": 1684303693844.01
          }
        ],
        [
          {
            "body": [
              {
                "ifMatch": {
                  "$set": {
                    "data": {
                      "code": "`<img id=\"webcam\" crossorigin src=\"https://www.gannett-cdn.com/presto/2021/01/27/PMCA/3b34404e-8401-4a6d-9d30-38dbe9a274d4-244ff25c-ef77-4d64-9bbc-d0e64ea6de3e_thumbnail.png?width=1280&height=720&fit=crop&format=pjpg&auto=webp\">`",
                      "language": "javascript",
                      "output": ""
                    },
                    "index": 2,
                    "lastEditedBy": "f313b510-8ff6-4ef7-8c27-070c2ae45fc1",
                    "_deleted": false
                  }
                }
              }
            ],
            "creator": "pkhexmkwbs",
            "time": 1684304057992.04
          }
        ]
      ],
      "hash": "0f44d93e6b3e55202ad5742a37ef1989e58ed497ba06d1d452520bcca093ce22"
    },
    "_meta": {
      "lwt": 1684304057992.05
    },
    "_deleted": false,
    "_attachments": {},
    "_rev": "5-lxgnmepxds"
  },
  {
    "id": "fzKJXils13",
    "type": "code",
    "data": {
      "code": "`\n<section>\n<canvas id=\"canvas\"></canvas>\n<script type=\"module\">\n  const canvas = document.getElementById(\"canvas\");\n  const img = document.getElementById('webcam');\n  const ctx = canvas.getContext('2d');\n  canvas.width = img.width;\n  canvas.height = img.height;\n  ctx.drawImage(img, 0, 0, img.width, img.height);\n  ctx.beginPath();\n  ctx.moveTo(img.width/2, 0);\n  ctx.lineTo(img.width/2, img.height);\n  ctx.stroke();\n  import vision from \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0\";\n  const { FaceLandmarker, FilesetResolver, DrawingUtils } = vision;\n  let faceLandmarker;\n  let runningMode = \"IMAGE\";\n  const filesetResolver = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm\"\n  );\n  function calculateCentroid(landmarks) {\n     const sum = landmarks.reduce((acc, landmark) => {\n        acc[0] = landmark.x+acc[0];\n        acc[1] = landmark.y+acc[1];\n        acc[2] = landmark.z+acc[2];\n        return acc;\n     }, [0,0,0]);\n     return sum.map(coord => coord / landmarks.length);\n  }\n  faceLandmarker = await FaceLandmarker.createFromOptions(filesetResolver, {\n    baseOptions: {\n      modelAssetPath: \n      \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task\",\n      delegate: \"GPU\"\n    },\n    outputFaceBlendshapes: true,\n    runningMode,\n    numFaces: 1\n  });\n  const centroid = calculateCentroid(faceLandmarker.detect(img).faceLandmarks[0]);\n  const vcentroid = [centroid[0]*img.width,centroid[1]*img.height];\n  ctx.beginPath();\n  ctx.arc(vcentroid[0], vcentroid[1], 10, 0, 2*Math.PI, true);\n  ctx.fill();\n  const visionLine = 0.5;\n  const distance = visionLine-centroid[0];\n  const relativeDistance = Math.abs(distance)/centroid[0];\n  const threshold = 0.7;\n  const action = relativeDistance >= threshold ? \"NONE\" : distance > 0 ? \"left\" : \"right\";\n  alert(action);\n</script>\n</section>\n`",
      "language": "javascript",
      "output": ""
    },
    "index": 3,
    "createdBy": "f313b510-8ff6-4ef7-8c27-070c2ae45fc1",
    "lastEditedBy": "f313b510-8ff6-4ef7-8c27-070c2ae45fc1",
    "topic": "c70506cc-aefb-479a-9eee-9f7ef37b9d2c",
    "crdts": {
      "operations": [
        [
          {
            "creator": "pkhexmkwbs",
            "body": [
              {
                "ifMatch": {
                  "$set": {
                    "id": "fzKJXils13",
                    "type": "code",
                    "data": {
                      "code": "",
                      "language": "javascript",
                      "output": ""
                    },
                    "index": 3,
                    "createdBy": "f313b510-8ff6-4ef7-8c27-070c2ae45fc1",
                    "lastEditedBy": "f313b510-8ff6-4ef7-8c27-070c2ae45fc1",
                    "topic": "c70506cc-aefb-479a-9eee-9f7ef37b9d2c"
                  }
                }
              }
            ],
            "time": 1684303701047.02
          }
        ],
        [
          {
            "body": [
              {
                "ifMatch": {
                  "$set": {
                    "data": {
                      "code": "`\n<section>\n<canvas id=\"canvas\"></canvas>\n<script type=\"module\">\n  const canvas = document.getElementById(\"canvas\");\n  const img = document.getElementById('webcam');\n  const ctx = canvas.getContext('2d');\n  canvas.width = img.width;\n  canvas.height = img.height;\n  ctx.drawImage(img, 0, 0, img.width, img.height);\n  ctx.beginPath();\n  ctx.moveTo(img.width/2, 0);\n  ctx.lineTo(img.width/2, img.height);\n  ctx.stroke();\n  import vision from \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0\";\n  const { FaceLandmarker, FilesetResolver, DrawingUtils } = vision;\n  let faceLandmarker;\n  let runningMode = \"IMAGE\";\n  const filesetResolver = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm\"\n  );\n  function calculateCentroid(landmarks) {\n     const sum = landmarks.reduce((acc, landmark) => {\n        acc[0] = landmark.x+acc[0];\n        acc[1] = landmark.y+acc[1];\n        acc[2] = landmark.z+acc[2];\n        return acc;\n     }, [0,0,0]);\n     return sum.map(coord => coord / landmarks.length);\n  }\n  faceLandmarker = await FaceLandmarker.createFromOptions(filesetResolver, {\n    baseOptions: {\n      modelAssetPath: \n      \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task\",\n      delegate: \"GPU\"\n    },\n    outputFaceBlendshapes: true,\n    runningMode,\n    numFaces: 1\n  });\n  const centroid = calculateCentroid(faceLandmarker.detect(img).faceLandmarks[0]);\n  const vcentroid = [centroid[0]*img.width,centroid[1]*img.height];\n  ctx.beginPath();\n  ctx.arc(vcentroid[0], vcentroid[1], 10, 0, 2*Math.PI, true);\n  ctx.fill();\n  const visionLine = 0.5;\n  const distance = visionLine-centroid[0];\n  const relativeDistance = Math.abs(distance)/centroid[0];\n  const threshold = 0.7;\n  const action = relativeDistance >= threshold ? \"NONE\" : distance > 0 ? \"l\" : \"r\";\n  console.log(action);\n</script>\n</section>\n`",
                      "language": "javascript",
                      "output": ""
                    },
                    "index": 3,
                    "lastEditedBy": "f313b510-8ff6-4ef7-8c27-070c2ae45fc1",
                    "_deleted": false
                  }
                }
              }
            ],
            "creator": "pkhexmkwbs",
            "time": 1684303706707.02
          }
        ],
        [
          {
            "body": [
              {
                "ifMatch": {
                  "$set": {
                    "data": {
                      "code": "`\n<section>\n<canvas id=\"canvas\"></canvas>\n<script type=\"module\">\n  const canvas = document.getElementById(\"canvas\");\n  const img = document.getElementById('webcam');\n  const ctx = canvas.getContext('2d');\n  canvas.width = img.width;\n  canvas.height = img.height;\n  ctx.drawImage(img, 0, 0, img.width, img.height);\n  ctx.beginPath();\n  ctx.moveTo(img.width/2, 0);\n  ctx.lineTo(img.width/2, img.height);\n  ctx.stroke();\n  import vision from \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0\";\n  const { FaceLandmarker, FilesetResolver, DrawingUtils } = vision;\n  let faceLandmarker;\n  let runningMode = \"IMAGE\";\n  const filesetResolver = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm\"\n  );\n  function calculateCentroid(landmarks) {\n     const sum = landmarks.reduce((acc, landmark) => {\n        acc[0] = landmark.x+acc[0];\n        acc[1] = landmark.y+acc[1];\n        acc[2] = landmark.z+acc[2];\n        return acc;\n     }, [0,0,0]);\n     return sum.map(coord => coord / landmarks.length);\n  }\n  faceLandmarker = await FaceLandmarker.createFromOptions(filesetResolver, {\n    baseOptions: {\n      modelAssetPath: \n      \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task\",\n      delegate: \"GPU\"\n    },\n    outputFaceBlendshapes: true,\n    runningMode,\n    numFaces: 1\n  });\n  const centroid = calculateCentroid(faceLandmarker.detect(img).faceLandmarks[0]);\n  const vcentroid = [centroid[0]*img.width,centroid[1]*img.height];\n  ctx.beginPath();\n  ctx.arc(vcentroid[0], vcentroid[1], 10, 0, 2*Math.PI, true);\n  ctx.fill();\n  const visionLine = 0.5;\n  const distance = visionLine-centroid[0];\n  const relativeDistance = Math.abs(distance)/centroid[0];\n  const threshold = 0.7;\n  const action = relativeDistance >= threshold ? \"NONE\" : distance > 0 ? \"l\" : \"r\";\n  console.log(action);\n</script>\n</section>\n`",
                      "language": "javascript",
                      "output": "\n<section>\n<canvas id=\"canvas\" width=\"1280\" height=\"720\"></canvas>\n<script type=\"module\">\n  const canvas = document.getElementById(\"canvas\");\n  const img = document.getElementById('webcam');\n  const ctx = canvas.getContext('2d');\n  canvas.width = img.width;\n  canvas.height = img.height;\n  ctx.drawImage(img, 0, 0, img.width, img.height);\n  ctx.beginPath();\n  ctx.moveTo(img.width/2, 0);\n  ctx.lineTo(img.width/2, img.height);\n  ctx.stroke();\n  import vision from \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0\";\n  const { FaceLandmarker, FilesetResolver, DrawingUtils } = vision;\n  let faceLandmarker;\n  let runningMode = \"IMAGE\";\n  const filesetResolver = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm\"\n  );\n  function calculateCentroid(landmarks) {\n     const sum = landmarks.reduce((acc, landmark) => {\n        acc[0] = landmark.x+acc[0];\n        acc[1] = landmark.y+acc[1];\n        acc[2] = landmark.z+acc[2];\n        return acc;\n     }, [0,0,0]);\n     return sum.map(coord => coord / landmarks.length);\n  }\n  faceLandmarker = await FaceLandmarker.createFromOptions(filesetResolver, {\n    baseOptions: {\n      modelAssetPath: \n      \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task\",\n      delegate: \"GPU\"\n    },\n    outputFaceBlendshapes: true,\n    runningMode,\n    numFaces: 1\n  });\n  const centroid = calculateCentroid(faceLandmarker.detect(img).faceLandmarks[0]);\n  const vcentroid = [centroid[0]*img.width,centroid[1]*img.height];\n  ctx.beginPath();\n  ctx.arc(vcentroid[0], vcentroid[1], 10, 0, 2*Math.PI, true);\n  ctx.fill();\n  const visionLine = 0.5;\n  const distance = visionLine-centroid[0];\n  const relativeDistance = Math.abs(distance)/centroid[0];\n  const threshold = 0.7;\n  const action = relativeDistance >= threshold ? \"NONE\" : distance > 0 ? \"l\" : \"r\";\n  console.log(action);\n</script>\n</section>\n"
                    },
                    "index": 3,
                    "lastEditedBy": "f313b510-8ff6-4ef7-8c27-070c2ae45fc1",
                    "_deleted": false
                  }
                }
              }
            ],
            "creator": "pkhexmkwbs",
            "time": 1684303710222.02
          }
        ],
        [
          {
            "body": [
              {
                "ifMatch": {
                  "$set": {
                    "data": {
                      "code": "`\n<section>\n<canvas id=\"canvas\"></canvas>\n<script type=\"module\">\n  const canvas = document.getElementById(\"canvas\");\n  const img = document.getElementById('webcam');\n  const ctx = canvas.getContext('2d');\n  canvas.width = img.width;\n  canvas.height = img.height;\n  ctx.drawImage(img, 0, 0, img.width, img.height);\n  ctx.beginPath();\n  ctx.moveTo(img.width/2, 0);\n  ctx.lineTo(img.width/2, img.height);\n  ctx.stroke();\n  import vision from \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0\";\n  const { FaceLandmarker, FilesetResolver, DrawingUtils } = vision;\n  let faceLandmarker;\n  let runningMode = \"IMAGE\";\n  const filesetResolver = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm\"\n  );\n  function calculateCentroid(landmarks) {\n     const sum = landmarks.reduce((acc, landmark) => {\n        acc[0] = landmark.x+acc[0];\n        acc[1] = landmark.y+acc[1];\n        acc[2] = landmark.z+acc[2];\n        return acc;\n     }, [0,0,0]);\n     return sum.map(coord => coord / landmarks.length);\n  }\n  faceLandmarker = await FaceLandmarker.createFromOptions(filesetResolver, {\n    baseOptions: {\n      modelAssetPath: \n      \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task\",\n      delegate: \"GPU\"\n    },\n    outputFaceBlendshapes: true,\n    runningMode,\n    numFaces: 1\n  });\n  const centroid = calculateCentroid(faceLandmarker.detect(img).faceLandmarks[0]);\n  const vcentroid = [centroid[0]*img.width,centroid[1]*img.height];\n  ctx.beginPath();\n  ctx.arc(vcentroid[0], vcentroid[1], 10, 0, 2*Math.PI, true);\n  ctx.fill();\n  const visionLine = 0.5;\n  const distance = visionLine-centroid[0];\n  const relativeDistance = Math.abs(distance)/centroid[0];\n  const threshold = 0.7;\n  const action = relativeDistance >= threshold ? \"NONE\" : distance > 0 ? \"l\" : \"r\";\n  prompt()\n</script>\n</section>\n`",
                      "language": "javascript",
                      "output": "\n<section>\n<canvas id=\"canvas\" width=\"1280\" height=\"720\"></canvas>\n<script type=\"module\">\n  const canvas = document.getElementById(\"canvas\");\n  const img = document.getElementById('webcam');\n  const ctx = canvas.getContext('2d');\n  canvas.width = img.width;\n  canvas.height = img.height;\n  ctx.drawImage(img, 0, 0, img.width, img.height);\n  ctx.beginPath();\n  ctx.moveTo(img.width/2, 0);\n  ctx.lineTo(img.width/2, img.height);\n  ctx.stroke();\n  import vision from \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0\";\n  const { FaceLandmarker, FilesetResolver, DrawingUtils } = vision;\n  let faceLandmarker;\n  let runningMode = \"IMAGE\";\n  const filesetResolver = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm\"\n  );\n  function calculateCentroid(landmarks) {\n     const sum = landmarks.reduce((acc, landmark) => {\n        acc[0] = landmark.x+acc[0];\n        acc[1] = landmark.y+acc[1];\n        acc[2] = landmark.z+acc[2];\n        return acc;\n     }, [0,0,0]);\n     return sum.map(coord => coord / landmarks.length);\n  }\n  faceLandmarker = await FaceLandmarker.createFromOptions(filesetResolver, {\n    baseOptions: {\n      modelAssetPath: \n      \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task\",\n      delegate: \"GPU\"\n    },\n    outputFaceBlendshapes: true,\n    runningMode,\n    numFaces: 1\n  });\n  const centroid = calculateCentroid(faceLandmarker.detect(img).faceLandmarks[0]);\n  const vcentroid = [centroid[0]*img.width,centroid[1]*img.height];\n  ctx.beginPath();\n  ctx.arc(vcentroid[0], vcentroid[1], 10, 0, 2*Math.PI, true);\n  ctx.fill();\n  const visionLine = 0.5;\n  const distance = visionLine-centroid[0];\n  const relativeDistance = Math.abs(distance)/centroid[0];\n  const threshold = 0.7;\n  const action = relativeDistance >= threshold ? \"NONE\" : distance > 0 ? \"l\" : \"r\";\n  console.log(action);\n</script>\n</section>\n"
                    },
                    "index": 3,
                    "lastEditedBy": "f313b510-8ff6-4ef7-8c27-070c2ae45fc1",
                    "_deleted": false
                  }
                }
              }
            ],
            "creator": "pkhexmkwbs",
            "time": 1684303713864.02
          }
        ],
        [
          {
            "body": [
              {
                "ifMatch": {
                  "$set": {
                    "data": {
                      "code": "`\n<section>\n<canvas id=\"canvas\"></canvas>\n<script type=\"module\">\n  const canvas = document.getElementById(\"canvas\");\n  const img = document.getElementById('webcam');\n  const ctx = canvas.getContext('2d');\n  canvas.width = img.width;\n  canvas.height = img.height;\n  ctx.drawImage(img, 0, 0, img.width, img.height);\n  ctx.beginPath();\n  ctx.moveTo(img.width/2, 0);\n  ctx.lineTo(img.width/2, img.height);\n  ctx.stroke();\n  import vision from \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0\";\n  const { FaceLandmarker, FilesetResolver, DrawingUtils } = vision;\n  let faceLandmarker;\n  let runningMode = \"IMAGE\";\n  const filesetResolver = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm\"\n  );\n  function calculateCentroid(landmarks) {\n     const sum = landmarks.reduce((acc, landmark) => {\n        acc[0] = landmark.x+acc[0];\n        acc[1] = landmark.y+acc[1];\n        acc[2] = landmark.z+acc[2];\n        return acc;\n     }, [0,0,0]);\n     return sum.map(coord => coord / landmarks.length);\n  }\n  faceLandmarker = await FaceLandmarker.createFromOptions(filesetResolver, {\n    baseOptions: {\n      modelAssetPath: \n      \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task\",\n      delegate: \"GPU\"\n    },\n    outputFaceBlendshapes: true,\n    runningMode,\n    numFaces: 1\n  });\n  const centroid = calculateCentroid(faceLandmarker.detect(img).faceLandmarks[0]);\n  const vcentroid = [centroid[0]*img.width,centroid[1]*img.height];\n  ctx.beginPath();\n  ctx.arc(vcentroid[0], vcentroid[1], 10, 0, 2*Math.PI, true);\n  ctx.fill();\n  const visionLine = 0.5;\n  const distance = visionLine-centroid[0];\n  const relativeDistance = Math.abs(distance)/centroid[0];\n  const threshold = 0.7;\n  const action = relativeDistance >= threshold ? \"NONE\" : distance > 0 ? \"l\" : \"r\";\n  prompt(action)\n</script>\n</section>\n`",
                      "language": "javascript",
                      "output": "\n<section>\n<canvas id=\"canvas\" width=\"1280\" height=\"720\"></canvas>\n<script type=\"module\">\n  const canvas = document.getElementById(\"canvas\");\n  const img = document.getElementById('webcam');\n  const ctx = canvas.getContext('2d');\n  canvas.width = img.width;\n  canvas.height = img.height;\n  ctx.drawImage(img, 0, 0, img.width, img.height);\n  ctx.beginPath();\n  ctx.moveTo(img.width/2, 0);\n  ctx.lineTo(img.width/2, img.height);\n  ctx.stroke();\n  import vision from \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0\";\n  const { FaceLandmarker, FilesetResolver, DrawingUtils } = vision;\n  let faceLandmarker;\n  let runningMode = \"IMAGE\";\n  const filesetResolver = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm\"\n  );\n  function calculateCentroid(landmarks) {\n     const sum = landmarks.reduce((acc, landmark) => {\n        acc[0] = landmark.x+acc[0];\n        acc[1] = landmark.y+acc[1];\n        acc[2] = landmark.z+acc[2];\n        return acc;\n     }, [0,0,0]);\n     return sum.map(coord => coord / landmarks.length);\n  }\n  faceLandmarker = await FaceLandmarker.createFromOptions(filesetResolver, {\n    baseOptions: {\n      modelAssetPath: \n      \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task\",\n      delegate: \"GPU\"\n    },\n    outputFaceBlendshapes: true,\n    runningMode,\n    numFaces: 1\n  });\n  const centroid = calculateCentroid(faceLandmarker.detect(img).faceLandmarks[0]);\n  const vcentroid = [centroid[0]*img.width,centroid[1]*img.height];\n  ctx.beginPath();\n  ctx.arc(vcentroid[0], vcentroid[1], 10, 0, 2*Math.PI, true);\n  ctx.fill();\n  const visionLine = 0.5;\n  const distance = visionLine-centroid[0];\n  const relativeDistance = Math.abs(distance)/centroid[0];\n  const threshold = 0.7;\n  const action = relativeDistance >= threshold ? \"NONE\" : distance > 0 ? \"l\" : \"r\";\n  console.log(action);\n</script>\n</section>\n"
                    },
                    "index": 3,
                    "lastEditedBy": "f313b510-8ff6-4ef7-8c27-070c2ae45fc1",
                    "_deleted": false
                  }
                }
              }
            ],
            "creator": "pkhexmkwbs",
            "time": 1684303715496.06
          }
        ],
        [
          {
            "body": [
              {
                "ifMatch": {
                  "$set": {
                    "data": {
                      "code": "`\n<section>\n<canvas id=\"canvas\"></canvas>\n<script type=\"module\">\n  const canvas = document.getElementById(\"canvas\");\n  const img = document.getElementById('webcam');\n  const ctx = canvas.getContext('2d');\n  canvas.width = img.width;\n  canvas.height = img.height;\n  ctx.drawImage(img, 0, 0, img.width, img.height);\n  ctx.beginPath();\n  ctx.moveTo(img.width/2, 0);\n  ctx.lineTo(img.width/2, img.height);\n  ctx.stroke();\n  import vision from \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0\";\n  const { FaceLandmarker, FilesetResolver, DrawingUtils } = vision;\n  let faceLandmarker;\n  let runningMode = \"IMAGE\";\n  const filesetResolver = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm\"\n  );\n  function calculateCentroid(landmarks) {\n     const sum = landmarks.reduce((acc, landmark) => {\n        acc[0] = landmark.x+acc[0];\n        acc[1] = landmark.y+acc[1];\n        acc[2] = landmark.z+acc[2];\n        return acc;\n     }, [0,0,0]);\n     return sum.map(coord => coord / landmarks.length);\n  }\n  faceLandmarker = await FaceLandmarker.createFromOptions(filesetResolver, {\n    baseOptions: {\n      modelAssetPath: \n      \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task\",\n      delegate: \"GPU\"\n    },\n    outputFaceBlendshapes: true,\n    runningMode,\n    numFaces: 1\n  });\n  const centroid = calculateCentroid(faceLandmarker.detect(img).faceLandmarks[0]);\n  const vcentroid = [centroid[0]*img.width,centroid[1]*img.height];\n  ctx.beginPath();\n  ctx.arc(vcentroid[0], vcentroid[1], 10, 0, 2*Math.PI, true);\n  ctx.fill();\n  const visionLine = 0.5;\n  const distance = visionLine-centroid[0];\n  const relativeDistance = Math.abs(distance)/centroid[0];\n  const threshold = 0.7;\n  const action = relativeDistance >= threshold ? \"NONE\" : distance > 0 ? \"l\" : \"r\";\n  prompt(action);\n</script>\n</section>\n`",
                      "language": "javascript",
                      "output": "\n<section>\n<canvas id=\"canvas\" width=\"1280\" height=\"720\"></canvas>\n<script type=\"module\">\n  const canvas = document.getElementById(\"canvas\");\n  const img = document.getElementById('webcam');\n  const ctx = canvas.getContext('2d');\n  canvas.width = img.width;\n  canvas.height = img.height;\n  ctx.drawImage(img, 0, 0, img.width, img.height);\n  ctx.beginPath();\n  ctx.moveTo(img.width/2, 0);\n  ctx.lineTo(img.width/2, img.height);\n  ctx.stroke();\n  import vision from \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0\";\n  const { FaceLandmarker, FilesetResolver, DrawingUtils } = vision;\n  let faceLandmarker;\n  let runningMode = \"IMAGE\";\n  const filesetResolver = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm\"\n  );\n  function calculateCentroid(landmarks) {\n     const sum = landmarks.reduce((acc, landmark) => {\n        acc[0] = landmark.x+acc[0];\n        acc[1] = landmark.y+acc[1];\n        acc[2] = landmark.z+acc[2];\n        return acc;\n     }, [0,0,0]);\n     return sum.map(coord => coord / landmarks.length);\n  }\n  faceLandmarker = await FaceLandmarker.createFromOptions(filesetResolver, {\n    baseOptions: {\n      modelAssetPath: \n      \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task\",\n      delegate: \"GPU\"\n    },\n    outputFaceBlendshapes: true,\n    runningMode,\n    numFaces: 1\n  });\n  const centroid = calculateCentroid(faceLandmarker.detect(img).faceLandmarks[0]);\n  const vcentroid = [centroid[0]*img.width,centroid[1]*img.height];\n  ctx.beginPath();\n  ctx.arc(vcentroid[0], vcentroid[1], 10, 0, 2*Math.PI, true);\n  ctx.fill();\n  const visionLine = 0.5;\n  const distance = visionLine-centroid[0];\n  const relativeDistance = Math.abs(distance)/centroid[0];\n  const threshold = 0.7;\n  const action = relativeDistance >= threshold ? \"NONE\" : distance > 0 ? \"l\" : \"r\";\n  console.log(action);\n</script>\n</section>\n"
                    },
                    "index": 3,
                    "lastEditedBy": "f313b510-8ff6-4ef7-8c27-070c2ae45fc1",
                    "_deleted": false
                  }
                }
              }
            ],
            "creator": "pkhexmkwbs",
            "time": 1684303716704.06
          }
        ],
        [
          {
            "body": [
              {
                "ifMatch": {
                  "$set": {
                    "data": {
                      "code": "`\n<section>\n<canvas id=\"canvas\"></canvas>\n<script type=\"module\">\n  const canvas = document.getElementById(\"canvas\");\n  const img = document.getElementById('webcam');\n  const ctx = canvas.getContext('2d');\n  canvas.width = img.width;\n  canvas.height = img.height;\n  ctx.drawImage(img, 0, 0, img.width, img.height);\n  ctx.beginPath();\n  ctx.moveTo(img.width/2, 0);\n  ctx.lineTo(img.width/2, img.height);\n  ctx.stroke();\n  import vision from \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0\";\n  const { FaceLandmarker, FilesetResolver, DrawingUtils } = vision;\n  let faceLandmarker;\n  let runningMode = \"IMAGE\";\n  const filesetResolver = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm\"\n  );\n  function calculateCentroid(landmarks) {\n     const sum = landmarks.reduce((acc, landmark) => {\n        acc[0] = landmark.x+acc[0];\n        acc[1] = landmark.y+acc[1];\n        acc[2] = landmark.z+acc[2];\n        return acc;\n     }, [0,0,0]);\n     return sum.map(coord => coord / landmarks.length);\n  }\n  faceLandmarker = await FaceLandmarker.createFromOptions(filesetResolver, {\n    baseOptions: {\n      modelAssetPath: \n      \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task\",\n      delegate: \"GPU\"\n    },\n    outputFaceBlendshapes: true,\n    runningMode,\n    numFaces: 1\n  });\n  const centroid = calculateCentroid(faceLandmarker.detect(img).faceLandmarks[0]);\n  const vcentroid = [centroid[0]*img.width,centroid[1]*img.height];\n  ctx.beginPath();\n  ctx.arc(vcentroid[0], vcentroid[1], 10, 0, 2*Math.PI, true);\n  ctx.fill();\n  const visionLine = 0.5;\n  const distance = visionLine-centroid[0];\n  const relativeDistance = Math.abs(distance)/centroid[0];\n  const threshold = 0.7;\n  const action = relativeDistance >= threshold ? \"NONE\" : distance > 0 ? \"l\" : \"r\";\n  prompt(action);\n</script>\n</section>\n`",
                      "language": "javascript",
                      "output": ""
                    },
                    "index": 3,
                    "lastEditedBy": "f313b510-8ff6-4ef7-8c27-070c2ae45fc1",
                    "_deleted": false
                  }
                }
              }
            ],
            "creator": "pkhexmkwbs",
            "time": 1684303717416.06
          }
        ],
        [
          {
            "body": [
              {
                "ifMatch": {
                  "$set": {
                    "data": {
                      "code": "`\n<section>\n<canvas id=\"canvas\"></canvas>\n<script type=\"module\">\n  const canvas = document.getElementById(\"canvas\");\n  const img = document.getElementById('webcam');\n  const ctx = canvas.getContext('2d');\n  canvas.width = img.width;\n  canvas.height = img.height;\n  ctx.drawImage(img, 0, 0, img.width, img.height);\n  ctx.beginPath();\n  ctx.moveTo(img.width/2, 0);\n  ctx.lineTo(img.width/2, img.height);\n  ctx.stroke();\n  import vision from \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0\";\n  const { FaceLandmarker, FilesetResolver, DrawingUtils } = vision;\n  let faceLandmarker;\n  let runningMode = \"IMAGE\";\n  const filesetResolver = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm\"\n  );\n  function calculateCentroid(landmarks) {\n     const sum = landmarks.reduce((acc, landmark) => {\n        acc[0] = landmark.x+acc[0];\n        acc[1] = landmark.y+acc[1];\n        acc[2] = landmark.z+acc[2];\n        return acc;\n     }, [0,0,0]);\n     return sum.map(coord => coord / landmarks.length);\n  }\n  faceLandmarker = await FaceLandmarker.createFromOptions(filesetResolver, {\n    baseOptions: {\n      modelAssetPath: \n      \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task\",\n      delegate: \"GPU\"\n    },\n    outputFaceBlendshapes: true,\n    runningMode,\n    numFaces: 1\n  });\n  const centroid = calculateCentroid(faceLandmarker.detect(img).faceLandmarks[0]);\n  const vcentroid = [centroid[0]*img.width,centroid[1]*img.height];\n  ctx.beginPath();\n  ctx.arc(vcentroid[0], vcentroid[1], 10, 0, 2*Math.PI, true);\n  ctx.fill();\n  const visionLine = 0.5;\n  const distance = visionLine-centroid[0];\n  const relativeDistance = Math.abs(distance)/centroid[0];\n  const threshold = 0.7;\n  const action = relativeDistance >= threshold ? \"NONE\" : distance > 0 ? \"l\" : \"r\";\n  prompt(action);\n</script>\n</section>\n`",
                      "language": "javascript",
                      "output": "\n<section>\n<canvas id=\"canvas\" width=\"1280\" height=\"720\"></canvas>\n<script type=\"module\">\n  const canvas = document.getElementById(\"canvas\");\n  const img = document.getElementById('webcam');\n  const ctx = canvas.getContext('2d');\n  canvas.width = img.width;\n  canvas.height = img.height;\n  ctx.drawImage(img, 0, 0, img.width, img.height);\n  ctx.beginPath();\n  ctx.moveTo(img.width/2, 0);\n  ctx.lineTo(img.width/2, img.height);\n  ctx.stroke();\n  import vision from \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0\";\n  const { FaceLandmarker, FilesetResolver, DrawingUtils } = vision;\n  let faceLandmarker;\n  let runningMode = \"IMAGE\";\n  const filesetResolver = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm\"\n  );\n  function calculateCentroid(landmarks) {\n     const sum = landmarks.reduce((acc, landmark) => {\n        acc[0] = landmark.x+acc[0];\n        acc[1] = landmark.y+acc[1];\n        acc[2] = landmark.z+acc[2];\n        return acc;\n     }, [0,0,0]);\n     return sum.map(coord => coord / landmarks.length);\n  }\n  faceLandmarker = await FaceLandmarker.createFromOptions(filesetResolver, {\n    baseOptions: {\n      modelAssetPath: \n      \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task\",\n      delegate: \"GPU\"\n    },\n    outputFaceBlendshapes: true,\n    runningMode,\n    numFaces: 1\n  });\n  const centroid = calculateCentroid(faceLandmarker.detect(img).faceLandmarks[0]);\n  const vcentroid = [centroid[0]*img.width,centroid[1]*img.height];\n  ctx.beginPath();\n  ctx.arc(vcentroid[0], vcentroid[1], 10, 0, 2*Math.PI, true);\n  ctx.fill();\n  const visionLine = 0.5;\n  const distance = visionLine-centroid[0];\n  const relativeDistance = Math.abs(distance)/centroid[0];\n  const threshold = 0.7;\n  const action = relativeDistance >= threshold ? \"NONE\" : distance > 0 ? \"l\" : \"r\";\n  prompt(action);\n</script>\n</section>\n"
                    },
                    "index": 3,
                    "lastEditedBy": "f313b510-8ff6-4ef7-8c27-070c2ae45fc1",
                    "_deleted": false
                  }
                }
              }
            ],
            "creator": "pkhexmkwbs",
            "time": 1684303720049.01
          }
        ],
        [
          {
            "body": [
              {
                "ifMatch": {
                  "$set": {
                    "data": {
                      "code": "`\n<section>\n<canvas id=\"canvas\"></canvas>\n<script type=\"module\">\n  const canvas = document.getElementById(\"canvas\");\n  const img = document.getElementById('webcam');\n  const ctx = canvas.getContext('2d');\n  canvas.width = img.width;\n  canvas.height = img.height;\n  ctx.drawImage(img, 0, 0, img.width, img.height);\n  ctx.beginPath();\n  ctx.moveTo(img.width/2, 0);\n  ctx.lineTo(img.width/2, img.height);\n  ctx.stroke();\n  import vision from \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0\";\n  const { FaceLandmarker, FilesetResolver, DrawingUtils } = vision;\n  let faceLandmarker;\n  let runningMode = \"IMAGE\";\n  const filesetResolver = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm\"\n  );\n  function calculateCentroid(landmarks) {\n     const sum = landmarks.reduce((acc, landmark) => {\n        acc[0] = landmark.x+acc[0];\n        acc[1] = landmark.y+acc[1];\n        acc[2] = landmark.z+acc[2];\n        return acc;\n     }, [0,0,0]);\n     return sum.map(coord => coord / landmarks.length);\n  }\n  faceLandmarker = await FaceLandmarker.createFromOptions(filesetResolver, {\n    baseOptions: {\n      modelAssetPath: \n      \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task\",\n      delegate: \"GPU\"\n    },\n    outputFaceBlendshapes: true,\n    runningMode,\n    numFaces: 1\n  });\n  const centroid = calculateCentroid(faceLandmarker.detect(img).faceLandmarks[0]);\n  const vcentroid = [centroid[0]*img.width,centroid[1]*img.height];\n  ctx.beginPath();\n  ctx.arc(vcentroid[0], vcentroid[1], 10, 0, 2*Math.PI, true);\n  ctx.fill();\n  const visionLine = 0.5;\n  const distance = visionLine-centroid[0];\n  const relativeDistance = Math.abs(distance)/centroid[0];\n  const threshold = 0.7;\n  const action = relativeDistance >= threshold ? \"NONE\" : distance > 0 ? \"l\" : \"r\";\n  alert(action);\n</script>\n</section>\n`",
                      "language": "javascript",
                      "output": "\n<section>\n<canvas id=\"canvas\" width=\"1280\" height=\"720\"></canvas>\n<script type=\"module\">\n  const canvas = document.getElementById(\"canvas\");\n  const img = document.getElementById('webcam');\n  const ctx = canvas.getContext('2d');\n  canvas.width = img.width;\n  canvas.height = img.height;\n  ctx.drawImage(img, 0, 0, img.width, img.height);\n  ctx.beginPath();\n  ctx.moveTo(img.width/2, 0);\n  ctx.lineTo(img.width/2, img.height);\n  ctx.stroke();\n  import vision from \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0\";\n  const { FaceLandmarker, FilesetResolver, DrawingUtils } = vision;\n  let faceLandmarker;\n  let runningMode = \"IMAGE\";\n  const filesetResolver = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm\"\n  );\n  function calculateCentroid(landmarks) {\n     const sum = landmarks.reduce((acc, landmark) => {\n        acc[0] = landmark.x+acc[0];\n        acc[1] = landmark.y+acc[1];\n        acc[2] = landmark.z+acc[2];\n        return acc;\n     }, [0,0,0]);\n     return sum.map(coord => coord / landmarks.length);\n  }\n  faceLandmarker = await FaceLandmarker.createFromOptions(filesetResolver, {\n    baseOptions: {\n      modelAssetPath: \n      \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task\",\n      delegate: \"GPU\"\n    },\n    outputFaceBlendshapes: true,\n    runningMode,\n    numFaces: 1\n  });\n  const centroid = calculateCentroid(faceLandmarker.detect(img).faceLandmarks[0]);\n  const vcentroid = [centroid[0]*img.width,centroid[1]*img.height];\n  ctx.beginPath();\n  ctx.arc(vcentroid[0], vcentroid[1], 10, 0, 2*Math.PI, true);\n  ctx.fill();\n  const visionLine = 0.5;\n  const distance = visionLine-centroid[0];\n  const relativeDistance = Math.abs(distance)/centroid[0];\n  const threshold = 0.7;\n  const action = relativeDistance >= threshold ? \"NONE\" : distance > 0 ? \"l\" : \"r\";\n  prompt(action);\n</script>\n</section>\n"
                    },
                    "index": 3,
                    "lastEditedBy": "f313b510-8ff6-4ef7-8c27-070c2ae45fc1",
                    "_deleted": false
                  }
                }
              }
            ],
            "creator": "pkhexmkwbs",
            "time": 1684303723360.06
          }
        ],
        [
          {
            "body": [
              {
                "ifMatch": {
                  "$set": {
                    "data": {
                      "code": "`\n<section>\n<canvas id=\"canvas\"></canvas>\n<script type=\"module\">\n  const canvas = document.getElementById(\"canvas\");\n  const img = document.getElementById('webcam');\n  const ctx = canvas.getContext('2d');\n  canvas.width = img.width;\n  canvas.height = img.height;\n  ctx.drawImage(img, 0, 0, img.width, img.height);\n  ctx.beginPath();\n  ctx.moveTo(img.width/2, 0);\n  ctx.lineTo(img.width/2, img.height);\n  ctx.stroke();\n  import vision from \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0\";\n  const { FaceLandmarker, FilesetResolver, DrawingUtils } = vision;\n  let faceLandmarker;\n  let runningMode = \"IMAGE\";\n  const filesetResolver = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm\"\n  );\n  function calculateCentroid(landmarks) {\n     const sum = landmarks.reduce((acc, landmark) => {\n        acc[0] = landmark.x+acc[0];\n        acc[1] = landmark.y+acc[1];\n        acc[2] = landmark.z+acc[2];\n        return acc;\n     }, [0,0,0]);\n     return sum.map(coord => coord / landmarks.length);\n  }\n  faceLandmarker = await FaceLandmarker.createFromOptions(filesetResolver, {\n    baseOptions: {\n      modelAssetPath: \n      \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task\",\n      delegate: \"GPU\"\n    },\n    outputFaceBlendshapes: true,\n    runningMode,\n    numFaces: 1\n  });\n  const centroid = calculateCentroid(faceLandmarker.detect(img).faceLandmarks[0]);\n  const vcentroid = [centroid[0]*img.width,centroid[1]*img.height];\n  ctx.beginPath();\n  ctx.arc(vcentroid[0], vcentroid[1], 10, 0, 2*Math.PI, true);\n  ctx.fill();\n  const visionLine = 0.5;\n  const distance = visionLine-centroid[0];\n  const relativeDistance = Math.abs(distance)/centroid[0];\n  const threshold = 0.7;\n  const action = relativeDistance >= threshold ? \"NONE\" : distance > 0 ? \"l\" : \"r\";\n  alert(\"\"action);\n</script>\n</section>\n`",
                      "language": "javascript",
                      "output": "\n<section>\n<canvas id=\"canvas\" width=\"1280\" height=\"720\"></canvas>\n<script type=\"module\">\n  const canvas = document.getElementById(\"canvas\");\n  const img = document.getElementById('webcam');\n  const ctx = canvas.getContext('2d');\n  canvas.width = img.width;\n  canvas.height = img.height;\n  ctx.drawImage(img, 0, 0, img.width, img.height);\n  ctx.beginPath();\n  ctx.moveTo(img.width/2, 0);\n  ctx.lineTo(img.width/2, img.height);\n  ctx.stroke();\n  import vision from \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0\";\n  const { FaceLandmarker, FilesetResolver, DrawingUtils } = vision;\n  let faceLandmarker;\n  let runningMode = \"IMAGE\";\n  const filesetResolver = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm\"\n  );\n  function calculateCentroid(landmarks) {\n     const sum = landmarks.reduce((acc, landmark) => {\n        acc[0] = landmark.x+acc[0];\n        acc[1] = landmark.y+acc[1];\n        acc[2] = landmark.z+acc[2];\n        return acc;\n     }, [0,0,0]);\n     return sum.map(coord => coord / landmarks.length);\n  }\n  faceLandmarker = await FaceLandmarker.createFromOptions(filesetResolver, {\n    baseOptions: {\n      modelAssetPath: \n      \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task\",\n      delegate: \"GPU\"\n    },\n    outputFaceBlendshapes: true,\n    runningMode,\n    numFaces: 1\n  });\n  const centroid = calculateCentroid(faceLandmarker.detect(img).faceLandmarks[0]);\n  const vcentroid = [centroid[0]*img.width,centroid[1]*img.height];\n  ctx.beginPath();\n  ctx.arc(vcentroid[0], vcentroid[1], 10, 0, 2*Math.PI, true);\n  ctx.fill();\n  const visionLine = 0.5;\n  const distance = visionLine-centroid[0];\n  const relativeDistance = Math.abs(distance)/centroid[0];\n  const threshold = 0.7;\n  const action = relativeDistance >= threshold ? \"NONE\" : distance > 0 ? \"l\" : \"r\";\n  prompt(action);\n</script>\n</section>\n"
                    },
                    "index": 3,
                    "lastEditedBy": "f313b510-8ff6-4ef7-8c27-070c2ae45fc1",
                    "_deleted": false
                  }
                }
              }
            ],
            "creator": "pkhexmkwbs",
            "time": 1684303725536.02
          }
        ],
        [
          {
            "body": [
              {
                "ifMatch": {
                  "$set": {
                    "data": {
                      "code": "`\n<section>\n<canvas id=\"canvas\"></canvas>\n<script type=\"module\">\n  const canvas = document.getElementById(\"canvas\");\n  const img = document.getElementById('webcam');\n  const ctx = canvas.getContext('2d');\n  canvas.width = img.width;\n  canvas.height = img.height;\n  ctx.drawImage(img, 0, 0, img.width, img.height);\n  ctx.beginPath();\n  ctx.moveTo(img.width/2, 0);\n  ctx.lineTo(img.width/2, img.height);\n  ctx.stroke();\n  import vision from \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0\";\n  const { FaceLandmarker, FilesetResolver, DrawingUtils } = vision;\n  let faceLandmarker;\n  let runningMode = \"IMAGE\";\n  const filesetResolver = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm\"\n  );\n  function calculateCentroid(landmarks) {\n     const sum = landmarks.reduce((acc, landmark) => {\n        acc[0] = landmark.x+acc[0];\n        acc[1] = landmark.y+acc[1];\n        acc[2] = landmark.z+acc[2];\n        return acc;\n     }, [0,0,0]);\n     return sum.map(coord => coord / landmarks.length);\n  }\n  faceLandmarker = await FaceLandmarker.createFromOptions(filesetResolver, {\n    baseOptions: {\n      modelAssetPath: \n      \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task\",\n      delegate: \"GPU\"\n    },\n    outputFaceBlendshapes: true,\n    runningMode,\n    numFaces: 1\n  });\n  const centroid = calculateCentroid(faceLandmarker.detect(img).faceLandmarks[0]);\n  const vcentroid = [centroid[0]*img.width,centroid[1]*img.height];\n  ctx.beginPath();\n  ctx.arc(vcentroid[0], vcentroid[1], 10, 0, 2*Math.PI, true);\n  ctx.fill();\n  const visionLine = 0.5;\n  const distance = visionLine-centroid[0];\n  const relativeDistance = Math.abs(distance)/centroid[0];\n  const threshold = 0.7;\n  const action = relativeDistance >= threshold ? \"NONE\" : distance > 0 ? \"l\" : \"r\";\n  alert(\"You must \"action);\n</script>\n</section>\n`",
                      "language": "javascript",
                      "output": "\n<section>\n<canvas id=\"canvas\" width=\"1280\" height=\"720\"></canvas>\n<script type=\"module\">\n  const canvas = document.getElementById(\"canvas\");\n  const img = document.getElementById('webcam');\n  const ctx = canvas.getContext('2d');\n  canvas.width = img.width;\n  canvas.height = img.height;\n  ctx.drawImage(img, 0, 0, img.width, img.height);\n  ctx.beginPath();\n  ctx.moveTo(img.width/2, 0);\n  ctx.lineTo(img.width/2, img.height);\n  ctx.stroke();\n  import vision from \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0\";\n  const { FaceLandmarker, FilesetResolver, DrawingUtils } = vision;\n  let faceLandmarker;\n  let runningMode = \"IMAGE\";\n  const filesetResolver = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm\"\n  );\n  function calculateCentroid(landmarks) {\n     const sum = landmarks.reduce((acc, landmark) => {\n        acc[0] = landmark.x+acc[0];\n        acc[1] = landmark.y+acc[1];\n        acc[2] = landmark.z+acc[2];\n        return acc;\n     }, [0,0,0]);\n     return sum.map(coord => coord / landmarks.length);\n  }\n  faceLandmarker = await FaceLandmarker.createFromOptions(filesetResolver, {\n    baseOptions: {\n      modelAssetPath: \n      \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task\",\n      delegate: \"GPU\"\n    },\n    outputFaceBlendshapes: true,\n    runningMode,\n    numFaces: 1\n  });\n  const centroid = calculateCentroid(faceLandmarker.detect(img).faceLandmarks[0]);\n  const vcentroid = [centroid[0]*img.width,centroid[1]*img.height];\n  ctx.beginPath();\n  ctx.arc(vcentroid[0], vcentroid[1], 10, 0, 2*Math.PI, true);\n  ctx.fill();\n  const visionLine = 0.5;\n  const distance = visionLine-centroid[0];\n  const relativeDistance = Math.abs(distance)/centroid[0];\n  const threshold = 0.7;\n  const action = relativeDistance >= threshold ? \"NONE\" : distance > 0 ? \"l\" : \"r\";\n  prompt(action);\n</script>\n</section>\n"
                    },
                    "index": 3,
                    "lastEditedBy": "f313b510-8ff6-4ef7-8c27-070c2ae45fc1",
                    "_deleted": false
                  }
                }
              }
            ],
            "creator": "pkhexmkwbs",
            "time": 1684303727265.01
          }
        ],
        [
          {
            "body": [
              {
                "ifMatch": {
                  "$set": {
                    "data": {
                      "code": "`\n<section>\n<canvas id=\"canvas\"></canvas>\n<script type=\"module\">\n  const canvas = document.getElementById(\"canvas\");\n  const img = document.getElementById('webcam');\n  const ctx = canvas.getContext('2d');\n  canvas.width = img.width;\n  canvas.height = img.height;\n  ctx.drawImage(img, 0, 0, img.width, img.height);\n  ctx.beginPath();\n  ctx.moveTo(img.width/2, 0);\n  ctx.lineTo(img.width/2, img.height);\n  ctx.stroke();\n  import vision from \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0\";\n  const { FaceLandmarker, FilesetResolver, DrawingUtils } = vision;\n  let faceLandmarker;\n  let runningMode = \"IMAGE\";\n  const filesetResolver = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm\"\n  );\n  function calculateCentroid(landmarks) {\n     const sum = landmarks.reduce((acc, landmark) => {\n        acc[0] = landmark.x+acc[0];\n        acc[1] = landmark.y+acc[1];\n        acc[2] = landmark.z+acc[2];\n        return acc;\n     }, [0,0,0]);\n     return sum.map(coord => coord / landmarks.length);\n  }\n  faceLandmarker = await FaceLandmarker.createFromOptions(filesetResolver, {\n    baseOptions: {\n      modelAssetPath: \n      \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task\",\n      delegate: \"GPU\"\n    },\n    outputFaceBlendshapes: true,\n    runningMode,\n    numFaces: 1\n  });\n  const centroid = calculateCentroid(faceLandmarker.detect(img).faceLandmarks[0]);\n  const vcentroid = [centroid[0]*img.width,centroid[1]*img.height];\n  ctx.beginPath();\n  ctx.arc(vcentroid[0], vcentroid[1], 10, 0, 2*Math.PI, true);\n  ctx.fill();\n  const visionLine = 0.5;\n  const distance = visionLine-centroid[0];\n  const relativeDistance = Math.abs(distance)/centroid[0];\n  const threshold = 0.7;\n  const action = relativeDistance >= threshold ? \"NONE\" : distance > 0 ? \"l\" : \"r\";\n  alert(\"You must action);\n</script>\n</section>\n`",
                      "language": "javascript",
                      "output": "\n<section>\n<canvas id=\"canvas\" width=\"1280\" height=\"720\"></canvas>\n<script type=\"module\">\n  const canvas = document.getElementById(\"canvas\");\n  const img = document.getElementById('webcam');\n  const ctx = canvas.getContext('2d');\n  canvas.width = img.width;\n  canvas.height = img.height;\n  ctx.drawImage(img, 0, 0, img.width, img.height);\n  ctx.beginPath();\n  ctx.moveTo(img.width/2, 0);\n  ctx.lineTo(img.width/2, img.height);\n  ctx.stroke();\n  import vision from \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0\";\n  const { FaceLandmarker, FilesetResolver, DrawingUtils } = vision;\n  let faceLandmarker;\n  let runningMode = \"IMAGE\";\n  const filesetResolver = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm\"\n  );\n  function calculateCentroid(landmarks) {\n     const sum = landmarks.reduce((acc, landmark) => {\n        acc[0] = landmark.x+acc[0];\n        acc[1] = landmark.y+acc[1];\n        acc[2] = landmark.z+acc[2];\n        return acc;\n     }, [0,0,0]);\n     return sum.map(coord => coord / landmarks.length);\n  }\n  faceLandmarker = await FaceLandmarker.createFromOptions(filesetResolver, {\n    baseOptions: {\n      modelAssetPath: \n      \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task\",\n      delegate: \"GPU\"\n    },\n    outputFaceBlendshapes: true,\n    runningMode,\n    numFaces: 1\n  });\n  const centroid = calculateCentroid(faceLandmarker.detect(img).faceLandmarks[0]);\n  const vcentroid = [centroid[0]*img.width,centroid[1]*img.height];\n  ctx.beginPath();\n  ctx.arc(vcentroid[0], vcentroid[1], 10, 0, 2*Math.PI, true);\n  ctx.fill();\n  const visionLine = 0.5;\n  const distance = visionLine-centroid[0];\n  const relativeDistance = Math.abs(distance)/centroid[0];\n  const threshold = 0.7;\n  const action = relativeDistance >= threshold ? \"NONE\" : distance > 0 ? \"l\" : \"r\";\n  prompt(action);\n</script>\n</section>\n"
                    },
                    "index": 3,
                    "lastEditedBy": "f313b510-8ff6-4ef7-8c27-070c2ae45fc1",
                    "_deleted": false
                  }
                }
              }
            ],
            "creator": "pkhexmkwbs",
            "time": 1684303730416.06
          }
        ],
        [
          {
            "body": [
              {
                "ifMatch": {
                  "$set": {
                    "data": {
                      "code": "`\n<section>\n<canvas id=\"canvas\"></canvas>\n<script type=\"module\">\n  const canvas = document.getElementById(\"canvas\");\n  const img = document.getElementById('webcam');\n  const ctx = canvas.getContext('2d');\n  canvas.width = img.width;\n  canvas.height = img.height;\n  ctx.drawImage(img, 0, 0, img.width, img.height);\n  ctx.beginPath();\n  ctx.moveTo(img.width/2, 0);\n  ctx.lineTo(img.width/2, img.height);\n  ctx.stroke();\n  import vision from \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0\";\n  const { FaceLandmarker, FilesetResolver, DrawingUtils } = vision;\n  let faceLandmarker;\n  let runningMode = \"IMAGE\";\n  const filesetResolver = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm\"\n  );\n  function calculateCentroid(landmarks) {\n     const sum = landmarks.reduce((acc, landmark) => {\n        acc[0] = landmark.x+acc[0];\n        acc[1] = landmark.y+acc[1];\n        acc[2] = landmark.z+acc[2];\n        return acc;\n     }, [0,0,0]);\n     return sum.map(coord => coord / landmarks.length);\n  }\n  faceLandmarker = await FaceLandmarker.createFromOptions(filesetResolver, {\n    baseOptions: {\n      modelAssetPath: \n      \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task\",\n      delegate: \"GPU\"\n    },\n    outputFaceBlendshapes: true,\n    runningMode,\n    numFaces: 1\n  });\n  const centroid = calculateCentroid(faceLandmarker.detect(img).faceLandmarks[0]);\n  const vcentroid = [centroid[0]*img.width,centroid[1]*img.height];\n  ctx.beginPath();\n  ctx.arc(vcentroid[0], vcentroid[1], 10, 0, 2*Math.PI, true);\n  ctx.fill();\n  const visionLine = 0.5;\n  const distance = visionLine-centroid[0];\n  const relativeDistance = Math.abs(distance)/centroid[0];\n  const threshold = 0.7;\n  const action = relativeDistance >= threshold ? \"NONE\" : distance > 0 ? \"l\" : \"r\";\n  alert(action);\n</script>\n</section>\n`",
                      "language": "javascript",
                      "output": ""
                    },
                    "index": 3,
                    "lastEditedBy": "f313b510-8ff6-4ef7-8c27-070c2ae45fc1",
                    "_deleted": false
                  }
                }
              }
            ],
            "creator": "pkhexmkwbs",
            "time": 1684303731843.02
          }
        ],
        [
          {
            "body": [
              {
                "ifMatch": {
                  "$set": {
                    "data": {
                      "code": "`\n<section>\n<canvas id=\"canvas\"></canvas>\n<script type=\"module\">\n  const canvas = document.getElementById(\"canvas\");\n  const img = document.getElementById('webcam');\n  const ctx = canvas.getContext('2d');\n  canvas.width = img.width;\n  canvas.height = img.height;\n  ctx.drawImage(img, 0, 0, img.width, img.height);\n  ctx.beginPath();\n  ctx.moveTo(img.width/2, 0);\n  ctx.lineTo(img.width/2, img.height);\n  ctx.stroke();\n  import vision from \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0\";\n  const { FaceLandmarker, FilesetResolver, DrawingUtils } = vision;\n  let faceLandmarker;\n  let runningMode = \"IMAGE\";\n  const filesetResolver = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm\"\n  );\n  function calculateCentroid(landmarks) {\n     const sum = landmarks.reduce((acc, landmark) => {\n        acc[0] = landmark.x+acc[0];\n        acc[1] = landmark.y+acc[1];\n        acc[2] = landmark.z+acc[2];\n        return acc;\n     }, [0,0,0]);\n     return sum.map(coord => coord / landmarks.length);\n  }\n  faceLandmarker = await FaceLandmarker.createFromOptions(filesetResolver, {\n    baseOptions: {\n      modelAssetPath: \n      \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task\",\n      delegate: \"GPU\"\n    },\n    outputFaceBlendshapes: true,\n    runningMode,\n    numFaces: 1\n  });\n  const centroid = calculateCentroid(faceLandmarker.detect(img).faceLandmarks[0]);\n  const vcentroid = [centroid[0]*img.width,centroid[1]*img.height];\n  ctx.beginPath();\n  ctx.arc(vcentroid[0], vcentroid[1], 10, 0, 2*Math.PI, true);\n  ctx.fill();\n  const visionLine = 0.5;\n  const distance = visionLine-centroid[0];\n  const relativeDistance = Math.abs(distance)/centroid[0];\n  const threshold = 0.7;\n  const action = relativeDistance >= threshold ? \"NONE\" : distance > 0 ? \"l\" : \"r\";\n  alert(action);\n</script>\n</section>\n`",
                      "language": "javascript",
                      "output": "\n<section>\n<canvas id=\"canvas\" width=\"1280\" height=\"720\"></canvas>\n<script type=\"module\">\n  const canvas = document.getElementById(\"canvas\");\n  const img = document.getElementById('webcam');\n  const ctx = canvas.getContext('2d');\n  canvas.width = img.width;\n  canvas.height = img.height;\n  ctx.drawImage(img, 0, 0, img.width, img.height);\n  ctx.beginPath();\n  ctx.moveTo(img.width/2, 0);\n  ctx.lineTo(img.width/2, img.height);\n  ctx.stroke();\n  import vision from \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0\";\n  const { FaceLandmarker, FilesetResolver, DrawingUtils } = vision;\n  let faceLandmarker;\n  let runningMode = \"IMAGE\";\n  const filesetResolver = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm\"\n  );\n  function calculateCentroid(landmarks) {\n     const sum = landmarks.reduce((acc, landmark) => {\n        acc[0] = landmark.x+acc[0];\n        acc[1] = landmark.y+acc[1];\n        acc[2] = landmark.z+acc[2];\n        return acc;\n     }, [0,0,0]);\n     return sum.map(coord => coord / landmarks.length);\n  }\n  faceLandmarker = await FaceLandmarker.createFromOptions(filesetResolver, {\n    baseOptions: {\n      modelAssetPath: \n      \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task\",\n      delegate: \"GPU\"\n    },\n    outputFaceBlendshapes: true,\n    runningMode,\n    numFaces: 1\n  });\n  const centroid = calculateCentroid(faceLandmarker.detect(img).faceLandmarks[0]);\n  const vcentroid = [centroid[0]*img.width,centroid[1]*img.height];\n  ctx.beginPath();\n  ctx.arc(vcentroid[0], vcentroid[1], 10, 0, 2*Math.PI, true);\n  ctx.fill();\n  const visionLine = 0.5;\n  const distance = visionLine-centroid[0];\n  const relativeDistance = Math.abs(distance)/centroid[0];\n  const threshold = 0.7;\n  const action = relativeDistance >= threshold ? \"NONE\" : distance > 0 ? \"l\" : \"r\";\n  alert(action);\n</script>\n</section>\n"
                    },
                    "index": 3,
                    "lastEditedBy": "f313b510-8ff6-4ef7-8c27-070c2ae45fc1",
                    "_deleted": false
                  }
                }
              }
            ],
            "creator": "pkhexmkwbs",
            "time": 1684303734467.01
          }
        ],
        [
          {
            "body": [
              {
                "ifMatch": {
                  "$set": {
                    "data": {
                      "code": "`\n<section>\n<canvas id=\"canvas\"></canvas>\n<script type=\"module\">\n  const canvas = document.getElementById(\"canvas\");\n  const img = document.getElementById('webcam');\n  const ctx = canvas.getContext('2d');\n  canvas.width = img.width;\n  canvas.height = img.height;\n  ctx.drawImage(img, 0, 0, img.width, img.height);\n  ctx.beginPath();\n  ctx.moveTo(img.width/2, 0);\n  ctx.lineTo(img.width/2, img.height);\n  ctx.stroke();\n  import vision from \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0\";\n  const { FaceLandmarker, FilesetResolver, DrawingUtils } = vision;\n  let faceLandmarker;\n  let runningMode = \"IMAGE\";\n  const filesetResolver = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm\"\n  );\n  function calculateCentroid(landmarks) {\n     const sum = landmarks.reduce((acc, landmark) => {\n        acc[0] = landmark.x+acc[0];\n        acc[1] = landmark.y+acc[1];\n        acc[2] = landmark.z+acc[2];\n        return acc;\n     }, [0,0,0]);\n     return sum.map(coord => coord / landmarks.length);\n  }\n  faceLandmarker = await FaceLandmarker.createFromOptions(filesetResolver, {\n    baseOptions: {\n      modelAssetPath: \n      \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task\",\n      delegate: \"GPU\"\n    },\n    outputFaceBlendshapes: true,\n    runningMode,\n    numFaces: 1\n  });\n  const centroid = calculateCentroid(faceLandmarker.detect(img).faceLandmarks[0]);\n  const vcentroid = [centroid[0]*img.width,centroid[1]*img.height];\n  ctx.beginPath();\n  ctx.arc(vcentroid[0], vcentroid[1], 10, 0, 2*Math.PI, true);\n  ctx.fill();\n  const visionLine = 0.5;\n  const distance = visionLine-centroid[0];\n  const relativeDistance = Math.abs(distance)/centroid[0];\n  const threshold = 0.7;\n  const action = relativeDistance >= threshold ? \"NONE\" : distance > 0 ? \"left\" : \"r\";\n  alert(action);\n</script>\n</section>\n`",
                      "language": "javascript",
                      "output": "\n<section>\n<canvas id=\"canvas\" width=\"1280\" height=\"720\"></canvas>\n<script type=\"module\">\n  const canvas = document.getElementById(\"canvas\");\n  const img = document.getElementById('webcam');\n  const ctx = canvas.getContext('2d');\n  canvas.width = img.width;\n  canvas.height = img.height;\n  ctx.drawImage(img, 0, 0, img.width, img.height);\n  ctx.beginPath();\n  ctx.moveTo(img.width/2, 0);\n  ctx.lineTo(img.width/2, img.height);\n  ctx.stroke();\n  import vision from \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0\";\n  const { FaceLandmarker, FilesetResolver, DrawingUtils } = vision;\n  let faceLandmarker;\n  let runningMode = \"IMAGE\";\n  const filesetResolver = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm\"\n  );\n  function calculateCentroid(landmarks) {\n     const sum = landmarks.reduce((acc, landmark) => {\n        acc[0] = landmark.x+acc[0];\n        acc[1] = landmark.y+acc[1];\n        acc[2] = landmark.z+acc[2];\n        return acc;\n     }, [0,0,0]);\n     return sum.map(coord => coord / landmarks.length);\n  }\n  faceLandmarker = await FaceLandmarker.createFromOptions(filesetResolver, {\n    baseOptions: {\n      modelAssetPath: \n      \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task\",\n      delegate: \"GPU\"\n    },\n    outputFaceBlendshapes: true,\n    runningMode,\n    numFaces: 1\n  });\n  const centroid = calculateCentroid(faceLandmarker.detect(img).faceLandmarks[0]);\n  const vcentroid = [centroid[0]*img.width,centroid[1]*img.height];\n  ctx.beginPath();\n  ctx.arc(vcentroid[0], vcentroid[1], 10, 0, 2*Math.PI, true);\n  ctx.fill();\n  const visionLine = 0.5;\n  const distance = visionLine-centroid[0];\n  const relativeDistance = Math.abs(distance)/centroid[0];\n  const threshold = 0.7;\n  const action = relativeDistance >= threshold ? \"NONE\" : distance > 0 ? \"l\" : \"r\";\n  alert(action);\n</script>\n</section>\n"
                    },
                    "index": 3,
                    "lastEditedBy": "f313b510-8ff6-4ef7-8c27-070c2ae45fc1",
                    "_deleted": false
                  }
                }
              }
            ],
            "creator": "pkhexmkwbs",
            "time": 1684303737600.02
          }
        ],
        [
          {
            "body": [
              {
                "ifMatch": {
                  "$set": {
                    "data": {
                      "code": "`\n<section>\n<canvas id=\"canvas\"></canvas>\n<script type=\"module\">\n  const canvas = document.getElementById(\"canvas\");\n  const img = document.getElementById('webcam');\n  const ctx = canvas.getContext('2d');\n  canvas.width = img.width;\n  canvas.height = img.height;\n  ctx.drawImage(img, 0, 0, img.width, img.height);\n  ctx.beginPath();\n  ctx.moveTo(img.width/2, 0);\n  ctx.lineTo(img.width/2, img.height);\n  ctx.stroke();\n  import vision from \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0\";\n  const { FaceLandmarker, FilesetResolver, DrawingUtils } = vision;\n  let faceLandmarker;\n  let runningMode = \"IMAGE\";\n  const filesetResolver = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm\"\n  );\n  function calculateCentroid(landmarks) {\n     const sum = landmarks.reduce((acc, landmark) => {\n        acc[0] = landmark.x+acc[0];\n        acc[1] = landmark.y+acc[1];\n        acc[2] = landmark.z+acc[2];\n        return acc;\n     }, [0,0,0]);\n     return sum.map(coord => coord / landmarks.length);\n  }\n  faceLandmarker = await FaceLandmarker.createFromOptions(filesetResolver, {\n    baseOptions: {\n      modelAssetPath: \n      \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task\",\n      delegate: \"GPU\"\n    },\n    outputFaceBlendshapes: true,\n    runningMode,\n    numFaces: 1\n  });\n  const centroid = calculateCentroid(faceLandmarker.detect(img).faceLandmarks[0]);\n  const vcentroid = [centroid[0]*img.width,centroid[1]*img.height];\n  ctx.beginPath();\n  ctx.arc(vcentroid[0], vcentroid[1], 10, 0, 2*Math.PI, true);\n  ctx.fill();\n  const visionLine = 0.5;\n  const distance = visionLine-centroid[0];\n  const relativeDistance = Math.abs(distance)/centroid[0];\n  const threshold = 0.7;\n  const action = relativeDistance >= threshold ? \"NONE\" : distance > 0 ? \"left\" : \"right\";\n  alert(action);\n</script>\n</section>\n`",
                      "language": "javascript",
                      "output": "\n<section>\n<canvas id=\"canvas\" width=\"1280\" height=\"720\"></canvas>\n<script type=\"module\">\n  const canvas = document.getElementById(\"canvas\");\n  const img = document.getElementById('webcam');\n  const ctx = canvas.getContext('2d');\n  canvas.width = img.width;\n  canvas.height = img.height;\n  ctx.drawImage(img, 0, 0, img.width, img.height);\n  ctx.beginPath();\n  ctx.moveTo(img.width/2, 0);\n  ctx.lineTo(img.width/2, img.height);\n  ctx.stroke();\n  import vision from \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0\";\n  const { FaceLandmarker, FilesetResolver, DrawingUtils } = vision;\n  let faceLandmarker;\n  let runningMode = \"IMAGE\";\n  const filesetResolver = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm\"\n  );\n  function calculateCentroid(landmarks) {\n     const sum = landmarks.reduce((acc, landmark) => {\n        acc[0] = landmark.x+acc[0];\n        acc[1] = landmark.y+acc[1];\n        acc[2] = landmark.z+acc[2];\n        return acc;\n     }, [0,0,0]);\n     return sum.map(coord => coord / landmarks.length);\n  }\n  faceLandmarker = await FaceLandmarker.createFromOptions(filesetResolver, {\n    baseOptions: {\n      modelAssetPath: \n      \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task\",\n      delegate: \"GPU\"\n    },\n    outputFaceBlendshapes: true,\n    runningMode,\n    numFaces: 1\n  });\n  const centroid = calculateCentroid(faceLandmarker.detect(img).faceLandmarks[0]);\n  const vcentroid = [centroid[0]*img.width,centroid[1]*img.height];\n  ctx.beginPath();\n  ctx.arc(vcentroid[0], vcentroid[1], 10, 0, 2*Math.PI, true);\n  ctx.fill();\n  const visionLine = 0.5;\n  const distance = visionLine-centroid[0];\n  const relativeDistance = Math.abs(distance)/centroid[0];\n  const threshold = 0.7;\n  const action = relativeDistance >= threshold ? \"NONE\" : distance > 0 ? \"l\" : \"r\";\n  alert(action);\n</script>\n</section>\n"
                    },
                    "index": 3,
                    "lastEditedBy": "f313b510-8ff6-4ef7-8c27-070c2ae45fc1",
                    "_deleted": false
                  }
                }
              }
            ],
            "creator": "pkhexmkwbs",
            "time": 1684303739352.06
          }
        ],
        [
          {
            "body": [
              {
                "ifMatch": {
                  "$set": {
                    "data": {
                      "code": "`\n<section>\n<canvas id=\"canvas\"></canvas>\n<script type=\"module\">\n  const canvas = document.getElementById(\"canvas\");\n  const img = document.getElementById('webcam');\n  const ctx = canvas.getContext('2d');\n  canvas.width = img.width;\n  canvas.height = img.height;\n  ctx.drawImage(img, 0, 0, img.width, img.height);\n  ctx.beginPath();\n  ctx.moveTo(img.width/2, 0);\n  ctx.lineTo(img.width/2, img.height);\n  ctx.stroke();\n  import vision from \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0\";\n  const { FaceLandmarker, FilesetResolver, DrawingUtils } = vision;\n  let faceLandmarker;\n  let runningMode = \"IMAGE\";\n  const filesetResolver = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm\"\n  );\n  function calculateCentroid(landmarks) {\n     const sum = landmarks.reduce((acc, landmark) => {\n        acc[0] = landmark.x+acc[0];\n        acc[1] = landmark.y+acc[1];\n        acc[2] = landmark.z+acc[2];\n        return acc;\n     }, [0,0,0]);\n     return sum.map(coord => coord / landmarks.length);\n  }\n  faceLandmarker = await FaceLandmarker.createFromOptions(filesetResolver, {\n    baseOptions: {\n      modelAssetPath: \n      \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task\",\n      delegate: \"GPU\"\n    },\n    outputFaceBlendshapes: true,\n    runningMode,\n    numFaces: 1\n  });\n  const centroid = calculateCentroid(faceLandmarker.detect(img).faceLandmarks[0]);\n  const vcentroid = [centroid[0]*img.width,centroid[1]*img.height];\n  ctx.beginPath();\n  ctx.arc(vcentroid[0], vcentroid[1], 10, 0, 2*Math.PI, true);\n  ctx.fill();\n  const visionLine = 0.5;\n  const distance = visionLine-centroid[0];\n  const relativeDistance = Math.abs(distance)/centroid[0];\n  const threshold = 0.7;\n  const action = relativeDistance >= threshold ? \"NONE\" : distance > 0 ? \"left\" : \"right\";\n  alert(action);\n</script>\n</section>\n`",
                      "language": "javascript",
                      "output": ""
                    },
                    "index": 3,
                    "lastEditedBy": "f313b510-8ff6-4ef7-8c27-070c2ae45fc1",
                    "_deleted": false
                  }
                }
              }
            ],
            "creator": "pkhexmkwbs",
            "time": 1684303746232.02
          }
        ],
        [
          {
            "body": [
              {
                "ifMatch": {
                  "$set": {
                    "data": {
                      "code": "`\n<section>\n<canvas id=\"canvas\"></canvas>\n<script type=\"module\">\n  const canvas = document.getElementById(\"canvas\");\n  const img = document.getElementById('webcam');\n  const ctx = canvas.getContext('2d');\n  canvas.width = img.width;\n  canvas.height = img.height;\n  ctx.drawImage(img, 0, 0, img.width, img.height);\n  ctx.beginPath();\n  ctx.moveTo(img.width/2, 0);\n  ctx.lineTo(img.width/2, img.height);\n  ctx.stroke();\n  import vision from \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0\";\n  const { FaceLandmarker, FilesetResolver, DrawingUtils } = vision;\n  let faceLandmarker;\n  let runningMode = \"IMAGE\";\n  const filesetResolver = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm\"\n  );\n  function calculateCentroid(landmarks) {\n     const sum = landmarks.reduce((acc, landmark) => {\n        acc[0] = landmark.x+acc[0];\n        acc[1] = landmark.y+acc[1];\n        acc[2] = landmark.z+acc[2];\n        return acc;\n     }, [0,0,0]);\n     return sum.map(coord => coord / landmarks.length);\n  }\n  faceLandmarker = await FaceLandmarker.createFromOptions(filesetResolver, {\n    baseOptions: {\n      modelAssetPath: \n      \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task\",\n      delegate: \"GPU\"\n    },\n    outputFaceBlendshapes: true,\n    runningMode,\n    numFaces: 1\n  });\n  const centroid = calculateCentroid(faceLandmarker.detect(img).faceLandmarks[0]);\n  const vcentroid = [centroid[0]*img.width,centroid[1]*img.height];\n  ctx.beginPath();\n  ctx.arc(vcentroid[0], vcentroid[1], 10, 0, 2*Math.PI, true);\n  ctx.fill();\n  const visionLine = 0.5;\n  const distance = visionLine-centroid[0];\n  const relativeDistance = Math.abs(distance)/centroid[0];\n  const threshold = 0.7;\n  const action = relativeDistance >= threshold ? \"NONE\" : distance > 0 ? \"left\" : \"right\";\n  alert(action);\n</script>\n</section>\n`",
                      "language": "javascript",
                      "output": "\n<section>\n<canvas id=\"canvas\" width=\"1280\" height=\"720\"></canvas>\n<script type=\"module\">\n  const canvas = document.getElementById(\"canvas\");\n  const img = document.getElementById('webcam');\n  const ctx = canvas.getContext('2d');\n  canvas.width = img.width;\n  canvas.height = img.height;\n  ctx.drawImage(img, 0, 0, img.width, img.height);\n  ctx.beginPath();\n  ctx.moveTo(img.width/2, 0);\n  ctx.lineTo(img.width/2, img.height);\n  ctx.stroke();\n  import vision from \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0\";\n  const { FaceLandmarker, FilesetResolver, DrawingUtils } = vision;\n  let faceLandmarker;\n  let runningMode = \"IMAGE\";\n  const filesetResolver = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm\"\n  );\n  function calculateCentroid(landmarks) {\n     const sum = landmarks.reduce((acc, landmark) => {\n        acc[0] = landmark.x+acc[0];\n        acc[1] = landmark.y+acc[1];\n        acc[2] = landmark.z+acc[2];\n        return acc;\n     }, [0,0,0]);\n     return sum.map(coord => coord / landmarks.length);\n  }\n  faceLandmarker = await FaceLandmarker.createFromOptions(filesetResolver, {\n    baseOptions: {\n      modelAssetPath: \n      \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task\",\n      delegate: \"GPU\"\n    },\n    outputFaceBlendshapes: true,\n    runningMode,\n    numFaces: 1\n  });\n  const centroid = calculateCentroid(faceLandmarker.detect(img).faceLandmarks[0]);\n  const vcentroid = [centroid[0]*img.width,centroid[1]*img.height];\n  ctx.beginPath();\n  ctx.arc(vcentroid[0], vcentroid[1], 10, 0, 2*Math.PI, true);\n  ctx.fill();\n  const visionLine = 0.5;\n  const distance = visionLine-centroid[0];\n  const relativeDistance = Math.abs(distance)/centroid[0];\n  const threshold = 0.7;\n  const action = relativeDistance >= threshold ? \"NONE\" : distance > 0 ? \"left\" : \"right\";\n  alert(action);\n</script>\n</section>\n"
                    },
                    "index": 3,
                    "lastEditedBy": "f313b510-8ff6-4ef7-8c27-070c2ae45fc1",
                    "_deleted": false
                  }
                }
              }
            ],
            "creator": "pkhexmkwbs",
            "time": 1684303748050.06
          }
        ],
        [
          {
            "body": [
              {
                "ifMatch": {
                  "$set": {
                    "data": {
                      "code": "`\n<section>\n<canvas id=\"canvas\"></canvas>\n<script type=\"module\">\n  const canvas = document.getElementById(\"canvas\");\n  const img = document.getElementById('webcam');\n  const ctx = canvas.getContext('2d');\n  canvas.width = img.width;\n  canvas.height = img.height;\n  ctx.drawImage(img, 0, 0, img.width, img.height);\n  ctx.beginPath();\n  ctx.moveTo(img.width/2, 0);\n  ctx.lineTo(img.width/2, img.height);\n  ctx.stroke();\n  import vision from \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0\";\n  const { FaceLandmarker, FilesetResolver, DrawingUtils } = vision;\n  let faceLandmarker;\n  let runningMode = \"IMAGE\";\n  const filesetResolver = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm\"\n  );\n  function calculateCentroid(landmarks) {\n     const sum = landmarks.reduce((acc, landmark) => {\n        acc[0] = landmark.x+acc[0];\n        acc[1] = landmark.y+acc[1];\n        acc[2] = landmark.z+acc[2];\n        return acc;\n     }, [0,0,0]);\n     return sum.map(coord => coord / landmarks.length);\n  }\n  faceLandmarker = await FaceLandmarker.createFromOptions(filesetResolver, {\n    baseOptions: {\n      modelAssetPath: \n      \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task\",\n      delegate: \"GPU\"\n    },\n    outputFaceBlendshapes: true,\n    runningMode,\n    numFaces: 1\n  });\n  const centroid = calculateCentroid(faceLandmarker.detect(img).faceLandmarks[0]);\n  const vcentroid = [centroid[0]*img.width,centroid[1]*img.height];\n  ctx.beginPath();\n  ctx.arc(vcentroid[0], vcentroid[1], 10, 0, 2*Math.PI, true);\n  ctx.fill();\n  const visionLine = 0.5;\n  const distance = visionLine-centroid[0];\n  const relativeDistance = Math.abs(distance)/centroid[0];\n  const threshold = 0.7;\n  const action = relativeDistance >= threshold ? \"NONE\" : distance > 0 ? \"right\" : \"right\";\n  alert(action);\n</script>\n</section>\n`",
                      "language": "javascript",
                      "output": "\n<section>\n<canvas id=\"canvas\" width=\"1280\" height=\"720\"></canvas>\n<script type=\"module\">\n  const canvas = document.getElementById(\"canvas\");\n  const img = document.getElementById('webcam');\n  const ctx = canvas.getContext('2d');\n  canvas.width = img.width;\n  canvas.height = img.height;\n  ctx.drawImage(img, 0, 0, img.width, img.height);\n  ctx.beginPath();\n  ctx.moveTo(img.width/2, 0);\n  ctx.lineTo(img.width/2, img.height);\n  ctx.stroke();\n  import vision from \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0\";\n  const { FaceLandmarker, FilesetResolver, DrawingUtils } = vision;\n  let faceLandmarker;\n  let runningMode = \"IMAGE\";\n  const filesetResolver = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm\"\n  );\n  function calculateCentroid(landmarks) {\n     const sum = landmarks.reduce((acc, landmark) => {\n        acc[0] = landmark.x+acc[0];\n        acc[1] = landmark.y+acc[1];\n        acc[2] = landmark.z+acc[2];\n        return acc;\n     }, [0,0,0]);\n     return sum.map(coord => coord / landmarks.length);\n  }\n  faceLandmarker = await FaceLandmarker.createFromOptions(filesetResolver, {\n    baseOptions: {\n      modelAssetPath: \n      \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task\",\n      delegate: \"GPU\"\n    },\n    outputFaceBlendshapes: true,\n    runningMode,\n    numFaces: 1\n  });\n  const centroid = calculateCentroid(faceLandmarker.detect(img).faceLandmarks[0]);\n  const vcentroid = [centroid[0]*img.width,centroid[1]*img.height];\n  ctx.beginPath();\n  ctx.arc(vcentroid[0], vcentroid[1], 10, 0, 2*Math.PI, true);\n  ctx.fill();\n  const visionLine = 0.5;\n  const distance = visionLine-centroid[0];\n  const relativeDistance = Math.abs(distance)/centroid[0];\n  const threshold = 0.7;\n  const action = relativeDistance >= threshold ? \"NONE\" : distance > 0 ? \"left\" : \"right\";\n  alert(action);\n</script>\n</section>\n"
                    },
                    "index": 3,
                    "lastEditedBy": "f313b510-8ff6-4ef7-8c27-070c2ae45fc1",
                    "_deleted": false
                  }
                }
              }
            ],
            "creator": "pkhexmkwbs",
            "time": 1684303755768.06
          }
        ],
        [
          {
            "body": [
              {
                "ifMatch": {
                  "$set": {
                    "data": {
                      "code": "`\n<section>\n<canvas id=\"canvas\"></canvas>\n<script type=\"module\">\n  const canvas = document.getElementById(\"canvas\");\n  const img = document.getElementById('webcam');\n  const ctx = canvas.getContext('2d');\n  canvas.width = img.width;\n  canvas.height = img.height;\n  ctx.drawImage(img, 0, 0, img.width, img.height);\n  ctx.beginPath();\n  ctx.moveTo(img.width/2, 0);\n  ctx.lineTo(img.width/2, img.height);\n  ctx.stroke();\n  import vision from \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0\";\n  const { FaceLandmarker, FilesetResolver, DrawingUtils } = vision;\n  let faceLandmarker;\n  let runningMode = \"IMAGE\";\n  const filesetResolver = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm\"\n  );\n  function calculateCentroid(landmarks) {\n     const sum = landmarks.reduce((acc, landmark) => {\n        acc[0] = landmark.x+acc[0];\n        acc[1] = landmark.y+acc[1];\n        acc[2] = landmark.z+acc[2];\n        return acc;\n     }, [0,0,0]);\n     return sum.map(coord => coord / landmarks.length);\n  }\n  faceLandmarker = await FaceLandmarker.createFromOptions(filesetResolver, {\n    baseOptions: {\n      modelAssetPath: \n      \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task\",\n      delegate: \"GPU\"\n    },\n    outputFaceBlendshapes: true,\n    runningMode,\n    numFaces: 1\n  });\n  const centroid = calculateCentroid(faceLandmarker.detect(img).faceLandmarks[0]);\n  const vcentroid = [centroid[0]*img.width,centroid[1]*img.height];\n  ctx.beginPath();\n  ctx.arc(vcentroid[0], vcentroid[1], 10, 0, 2*Math.PI, true);\n  ctx.fill();\n  const visionLine = 0.5;\n  const distance = visionLine-centroid[0];\n  const relativeDistance = Math.abs(distance)/centroid[0];\n  const threshold = 0.7;\n  const action = relativeDistance >= threshold ? \"NONE\" : distance > 0 ? \"right\" : \"left\";\n  alert(action);\n</script>\n</section>\n`",
                      "language": "javascript",
                      "output": "\n<section>\n<canvas id=\"canvas\" width=\"1280\" height=\"720\"></canvas>\n<script type=\"module\">\n  const canvas = document.getElementById(\"canvas\");\n  const img = document.getElementById('webcam');\n  const ctx = canvas.getContext('2d');\n  canvas.width = img.width;\n  canvas.height = img.height;\n  ctx.drawImage(img, 0, 0, img.width, img.height);\n  ctx.beginPath();\n  ctx.moveTo(img.width/2, 0);\n  ctx.lineTo(img.width/2, img.height);\n  ctx.stroke();\n  import vision from \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0\";\n  const { FaceLandmarker, FilesetResolver, DrawingUtils } = vision;\n  let faceLandmarker;\n  let runningMode = \"IMAGE\";\n  const filesetResolver = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm\"\n  );\n  function calculateCentroid(landmarks) {\n     const sum = landmarks.reduce((acc, landmark) => {\n        acc[0] = landmark.x+acc[0];\n        acc[1] = landmark.y+acc[1];\n        acc[2] = landmark.z+acc[2];\n        return acc;\n     }, [0,0,0]);\n     return sum.map(coord => coord / landmarks.length);\n  }\n  faceLandmarker = await FaceLandmarker.createFromOptions(filesetResolver, {\n    baseOptions: {\n      modelAssetPath: \n      \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task\",\n      delegate: \"GPU\"\n    },\n    outputFaceBlendshapes: true,\n    runningMode,\n    numFaces: 1\n  });\n  const centroid = calculateCentroid(faceLandmarker.detect(img).faceLandmarks[0]);\n  const vcentroid = [centroid[0]*img.width,centroid[1]*img.height];\n  ctx.beginPath();\n  ctx.arc(vcentroid[0], vcentroid[1], 10, 0, 2*Math.PI, true);\n  ctx.fill();\n  const visionLine = 0.5;\n  const distance = visionLine-centroid[0];\n  const relativeDistance = Math.abs(distance)/centroid[0];\n  const threshold = 0.7;\n  const action = relativeDistance >= threshold ? \"NONE\" : distance > 0 ? \"left\" : \"right\";\n  alert(action);\n</script>\n</section>\n"
                    },
                    "index": 3,
                    "lastEditedBy": "f313b510-8ff6-4ef7-8c27-070c2ae45fc1",
                    "_deleted": false
                  }
                }
              }
            ],
            "creator": "pkhexmkwbs",
            "time": 1684303758193.01
          }
        ],
        [
          {
            "body": [
              {
                "ifMatch": {
                  "$set": {
                    "data": {
                      "code": "`\n<section>\n<canvas id=\"canvas\"></canvas>\n<script type=\"module\">\n  const canvas = document.getElementById(\"canvas\");\n  const img = document.getElementById('webcam');\n  const ctx = canvas.getContext('2d');\n  canvas.width = img.width;\n  canvas.height = img.height;\n  ctx.drawImage(img, 0, 0, img.width, img.height);\n  ctx.beginPath();\n  ctx.moveTo(img.width/2, 0);\n  ctx.lineTo(img.width/2, img.height);\n  ctx.stroke();\n  import vision from \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0\";\n  const { FaceLandmarker, FilesetResolver, DrawingUtils } = vision;\n  let faceLandmarker;\n  let runningMode = \"IMAGE\";\n  const filesetResolver = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm\"\n  );\n  function calculateCentroid(landmarks) {\n     const sum = landmarks.reduce((acc, landmark) => {\n        acc[0] = landmark.x+acc[0];\n        acc[1] = landmark.y+acc[1];\n        acc[2] = landmark.z+acc[2];\n        return acc;\n     }, [0,0,0]);\n     return sum.map(coord => coord / landmarks.length);\n  }\n  faceLandmarker = await FaceLandmarker.createFromOptions(filesetResolver, {\n    baseOptions: {\n      modelAssetPath: \n      \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task\",\n      delegate: \"GPU\"\n    },\n    outputFaceBlendshapes: true,\n    runningMode,\n    numFaces: 1\n  });\n  const centroid = calculateCentroid(faceLandmarker.detect(img).faceLandmarks[0]);\n  const vcentroid = [centroid[0]*img.width,centroid[1]*img.height];\n  ctx.beginPath();\n  ctx.arc(vcentroid[0], vcentroid[1], 10, 0, 2*Math.PI, true);\n  ctx.fill();\n  const visionLine = 0.5;\n  const distance = visionLine-centroid[0];\n  const relativeDistance = Math.abs(distance)/centroid[0];\n  const threshold = 0.7;\n  const action = relativeDistance >= threshold ? \"NONE\" : distance > 0 ? \"left\" : \"r\";\n  alert(action);\n</script>\n</section>\n`",
                      "language": "javascript",
                      "output": "\n<section>\n<canvas id=\"canvas\" width=\"1280\" height=\"720\"></canvas>\n<script type=\"module\">\n  const canvas = document.getElementById(\"canvas\");\n  const img = document.getElementById('webcam');\n  const ctx = canvas.getContext('2d');\n  canvas.width = img.width;\n  canvas.height = img.height;\n  ctx.drawImage(img, 0, 0, img.width, img.height);\n  ctx.beginPath();\n  ctx.moveTo(img.width/2, 0);\n  ctx.lineTo(img.width/2, img.height);\n  ctx.stroke();\n  import vision from \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0\";\n  const { FaceLandmarker, FilesetResolver, DrawingUtils } = vision;\n  let faceLandmarker;\n  let runningMode = \"IMAGE\";\n  const filesetResolver = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm\"\n  );\n  function calculateCentroid(landmarks) {\n     const sum = landmarks.reduce((acc, landmark) => {\n        acc[0] = landmark.x+acc[0];\n        acc[1] = landmark.y+acc[1];\n        acc[2] = landmark.z+acc[2];\n        return acc;\n     }, [0,0,0]);\n     return sum.map(coord => coord / landmarks.length);\n  }\n  faceLandmarker = await FaceLandmarker.createFromOptions(filesetResolver, {\n    baseOptions: {\n      modelAssetPath: \n      \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task\",\n      delegate: \"GPU\"\n    },\n    outputFaceBlendshapes: true,\n    runningMode,\n    numFaces: 1\n  });\n  const centroid = calculateCentroid(faceLandmarker.detect(img).faceLandmarks[0]);\n  const vcentroid = [centroid[0]*img.width,centroid[1]*img.height];\n  ctx.beginPath();\n  ctx.arc(vcentroid[0], vcentroid[1], 10, 0, 2*Math.PI, true);\n  ctx.fill();\n  const visionLine = 0.5;\n  const distance = visionLine-centroid[0];\n  const relativeDistance = Math.abs(distance)/centroid[0];\n  const threshold = 0.7;\n  const action = relativeDistance >= threshold ? \"NONE\" : distance > 0 ? \"left\" : \"right\";\n  alert(action);\n</script>\n</section>\n"
                    },
                    "index": 3,
                    "lastEditedBy": "f313b510-8ff6-4ef7-8c27-070c2ae45fc1",
                    "_deleted": false
                  }
                }
              }
            ],
            "creator": "pkhexmkwbs",
            "time": 1684303765112.06
          }
        ],
        [
          {
            "body": [
              {
                "ifMatch": {
                  "$set": {
                    "data": {
                      "code": "`\n<section>\n<canvas id=\"canvas\"></canvas>\n<script type=\"module\">\n  const canvas = document.getElementById(\"canvas\");\n  const img = document.getElementById('webcam');\n  const ctx = canvas.getContext('2d');\n  canvas.width = img.width;\n  canvas.height = img.height;\n  ctx.drawImage(img, 0, 0, img.width, img.height);\n  ctx.beginPath();\n  ctx.moveTo(img.width/2, 0);\n  ctx.lineTo(img.width/2, img.height);\n  ctx.stroke();\n  import vision from \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0\";\n  const { FaceLandmarker, FilesetResolver, DrawingUtils } = vision;\n  let faceLandmarker;\n  let runningMode = \"IMAGE\";\n  const filesetResolver = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm\"\n  );\n  function calculateCentroid(landmarks) {\n     const sum = landmarks.reduce((acc, landmark) => {\n        acc[0] = landmark.x+acc[0];\n        acc[1] = landmark.y+acc[1];\n        acc[2] = landmark.z+acc[2];\n        return acc;\n     }, [0,0,0]);\n     return sum.map(coord => coord / landmarks.length);\n  }\n  faceLandmarker = await FaceLandmarker.createFromOptions(filesetResolver, {\n    baseOptions: {\n      modelAssetPath: \n      \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task\",\n      delegate: \"GPU\"\n    },\n    outputFaceBlendshapes: true,\n    runningMode,\n    numFaces: 1\n  });\n  const centroid = calculateCentroid(faceLandmarker.detect(img).faceLandmarks[0]);\n  const vcentroid = [centroid[0]*img.width,centroid[1]*img.height];\n  ctx.beginPath();\n  ctx.arc(vcentroid[0], vcentroid[1], 10, 0, 2*Math.PI, true);\n  ctx.fill();\n  const visionLine = 0.5;\n  const distance = visionLine-centroid[0];\n  const relativeDistance = Math.abs(distance)/centroid[0];\n  const threshold = 0.7;\n  const action = relativeDistance >= threshold ? \"NONE\" : distance > 0 ? \"left\" : \"right\";\n  alert(action);\n</script>\n</section>\n`",
                      "language": "javascript",
                      "output": "\n<section>\n<canvas id=\"canvas\" width=\"1280\" height=\"720\"></canvas>\n<script type=\"module\">\n  const canvas = document.getElementById(\"canvas\");\n  const img = document.getElementById('webcam');\n  const ctx = canvas.getContext('2d');\n  canvas.width = img.width;\n  canvas.height = img.height;\n  ctx.drawImage(img, 0, 0, img.width, img.height);\n  ctx.beginPath();\n  ctx.moveTo(img.width/2, 0);\n  ctx.lineTo(img.width/2, img.height);\n  ctx.stroke();\n  import vision from \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0\";\n  const { FaceLandmarker, FilesetResolver, DrawingUtils } = vision;\n  let faceLandmarker;\n  let runningMode = \"IMAGE\";\n  const filesetResolver = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm\"\n  );\n  function calculateCentroid(landmarks) {\n     const sum = landmarks.reduce((acc, landmark) => {\n        acc[0] = landmark.x+acc[0];\n        acc[1] = landmark.y+acc[1];\n        acc[2] = landmark.z+acc[2];\n        return acc;\n     }, [0,0,0]);\n     return sum.map(coord => coord / landmarks.length);\n  }\n  faceLandmarker = await FaceLandmarker.createFromOptions(filesetResolver, {\n    baseOptions: {\n      modelAssetPath: \n      \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task\",\n      delegate: \"GPU\"\n    },\n    outputFaceBlendshapes: true,\n    runningMode,\n    numFaces: 1\n  });\n  const centroid = calculateCentroid(faceLandmarker.detect(img).faceLandmarks[0]);\n  const vcentroid = [centroid[0]*img.width,centroid[1]*img.height];\n  ctx.beginPath();\n  ctx.arc(vcentroid[0], vcentroid[1], 10, 0, 2*Math.PI, true);\n  ctx.fill();\n  const visionLine = 0.5;\n  const distance = visionLine-centroid[0];\n  const relativeDistance = Math.abs(distance)/centroid[0];\n  const threshold = 0.7;\n  const action = relativeDistance >= threshold ? \"NONE\" : distance > 0 ? \"left\" : \"right\";\n  alert(action);\n</script>\n</section>\n"
                    },
                    "index": 3,
                    "lastEditedBy": "f313b510-8ff6-4ef7-8c27-070c2ae45fc1",
                    "_deleted": false
                  }
                }
              }
            ],
            "creator": "pkhexmkwbs",
            "time": 1684303766544.06
          }
        ],
        [
          {
            "body": [
              {
                "ifMatch": {
                  "$set": {
                    "data": {
                      "code": "`\n<section>\n<canvas id=\"canvas\"></canvas>\n<script type=\"module\">\n  const canvas = document.getElementById(\"canvas\");\n  const img = document.getElementById('webcam');\n  const ctx = canvas.getContext('2d');\n  canvas.width = img.width;\n  canvas.height = img.height;\n  ctx.drawImage(img, 0, 0, img.width, img.height);\n  ctx.beginPath();\n  ctx.moveTo(img.width/2, 0);\n  ctx.lineTo(img.width/2, img.height);\n  ctx.stroke();\n  import vision from \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0\";\n  const { FaceLandmarker, FilesetResolver, DrawingUtils } = vision;\n  let faceLandmarker;\n  let runningMode = \"IMAGE\";\n  const filesetResolver = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm\"\n  );\n  function calculateCentroid(landmarks) {\n     const sum = landmarks.reduce((acc, landmark) => {\n        acc[0] = landmark.x+acc[0];\n        acc[1] = landmark.y+acc[1];\n        acc[2] = landmark.z+acc[2];\n        return acc;\n     }, [0,0,0]);\n     return sum.map(coord => coord / landmarks.length);\n  }\n  faceLandmarker = await FaceLandmarker.createFromOptions(filesetResolver, {\n    baseOptions: {\n      modelAssetPath: \n      \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task\",\n      delegate: \"GPU\"\n    },\n    outputFaceBlendshapes: true,\n    runningMode,\n    numFaces: 1\n  });\n  const centroid = calculateCentroid(faceLandmarker.detect(img).faceLandmarks[0]);\n  const vcentroid = [centroid[0]*img.width,centroid[1]*img.height];\n  ctx.beginPath();\n  ctx.arc(vcentroid[0], vcentroid[1], 10, 0, 2*Math.PI, true);\n  ctx.fill();\n  const visionLine = 0.5;\n  const distance = visionLine-centroid[0];\n  const relativeDistance = Math.abs(distance)/centroid[0];\n  const threshold = 0.7;\n  const action = relativeDistance >= threshold ? \"NONE\" : distance > 0 ? \"left\" : \"right\";\n  alert(action);\n</script>\n</section>\n`",
                      "language": "javascript",
                      "output": ""
                    },
                    "index": 3,
                    "lastEditedBy": "f313b510-8ff6-4ef7-8c27-070c2ae45fc1",
                    "_deleted": false
                  }
                }
              }
            ],
            "creator": "pkhexmkwbs",
            "time": 1684304061264.02
          }
        ]
      ],
      "hash": "8ede983364afc82b460783a2b020f9d873bfa39798319a215ca2774872a022ee"
    },
    "_meta": {
      "lwt": 1684304061265.01
    },
    "_deleted": false,
    "_attachments": {},
    "_rev": "24-lxgnmepxds"
  },
  {
    "id": "gfjlxIs7RW",
    "type": "toc",
    "data": {
      "items": [
        {
          "id": "xtxzs6rqqt",
          "reference": "wirInDdcHN",
          "text": "Track aliveness human",
          "level": 1
        },
        {
          "id": "q8lztq0you",
          "reference": "XjqJQcINAA",
          "text": "Track aliveness human with MQTT and EVA",
          "level": 1
        }
      ]
    },
    "index": 4,
    "createdBy": "f313b510-8ff6-4ef7-8c27-070c2ae45fc1",
    "lastEditedBy": "f313b510-8ff6-4ef7-8c27-070c2ae45fc1",
    "topic": "c70506cc-aefb-479a-9eee-9f7ef37b9d2c",
    "crdts": {
      "operations": [
        [
          {
            "creator": "pkhexmkwbs",
            "body": [
              {
                "ifMatch": {
                  "$set": {
                    "id": "gfjlxIs7RW",
                    "type": "toc",
                    "data": {
                      "items": [
                        {
                          "id": "xtxzs6rqqt",
                          "reference": "wirInDdcHN",
                          "text": "Track aliveness human",
                          "level": 1
                        },
                        {
                          "id": "q8lztq0you",
                          "reference": "XjqJQcINAA",
                          "text": "Track aliveness human with MQTT and EVA",
                          "level": 1
                        }
                      ]
                    },
                    "index": 0,
                    "createdBy": "f313b510-8ff6-4ef7-8c27-070c2ae45fc1",
                    "lastEditedBy": "f313b510-8ff6-4ef7-8c27-070c2ae45fc1",
                    "topic": "c70506cc-aefb-479a-9eee-9f7ef37b9d2c"
                  }
                }
              }
            ],
            "time": 1684303668149.06
          }
        ]
      ],
      "hash": "c38f034b4211d95d8c7112f3ab63c9bd0449b6514210149d470042b2d931c71d"
    },
    "_meta": {
      "lwt": 1684303701722.02
    },
    "_deleted": false,
    "_attachments": {},
    "_rev": "5-lxgnmepxds"
  },
  {
    "id": "ZR5qhZvEyh",
    "type": "code",
    "data": {
      "code": "import {\n    FaceLandmarker,\n    FilesetResolver,\n    DrawingUtils\n} from \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0\";\n\nconst filesetResolver = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm\"\n);\n\n/* \n   TODO: I think this function introduce a high overhead, so it should be migrated to WASM C.\n*/\nfunction calculateCentroid(landmarks) {\n    const sum = landmarks.reduce((acc, landmark) => {\n        acc[0] = landmark.x + acc[0];\n        acc[1] = landmark.y + acc[1];\n        acc[2] = landmark.z + acc[2];\n        return acc;\n    }, [0, 0, 0]);\n    return sum.map(coord => coord / landmarks.length);\n}\n\nconst faceLandmarker = await FaceLandmarker.createFromOptions(filesetResolver, {\n    baseOptions: {\n        modelAssetPath: \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task\",\n        delegate: \"GPU\"\n    },\n    outputFaceBlendshapes: false,\n    runningMode: \"IMAGE\",\n    numFaces: 1\n});\n\n\nconst visionLine = 0.5;\nconst threshold = 0.2;\n\ncaptureStream().pipe(\n  throttleTime(1000),\n  map(({message: img}) => {\n    const faceLandmarks = faceLandmarker.detect(img).faceLandmarks;\n    if (faceLandmarks.length === 0)\n        return \"c\";\n    const [x,y,z] = calculateCentroid(faceLandmarks[0]);\n    const distance = visionLine-x;\n    const relativeDistance = Math.abs(distance)/x;\n    return relativeDistance <= threshold ? \"NONE\" : distance > 0 ? \"l\" : \"r\";\n  }),\n  rewrite()\n)",
      "language": "javascript",
      "output": "NONE"
    },
    "index": 5,
    "createdBy": "f313b510-8ff6-4ef7-8c27-070c2ae45fc1",
    "lastEditedBy": "f313b510-8ff6-4ef7-8c27-070c2ae45fc1",
    "topic": "c70506cc-aefb-479a-9eee-9f7ef37b9d2c",
    "crdts": {
      "operations": [
        [
          {
            "creator": "pkhexmkwbs",
            "body": [
              {
                "ifMatch": {
                  "$set": {
                    "id": "ZR5qhZvEyh",
                    "type": "code",
                    "data": {
                      "code": "",
                      "language": "javascript",
                      "output": ""
                    },
                    "index": 1,
                    "createdBy": "f313b510-8ff6-4ef7-8c27-070c2ae45fc1",
                    "lastEditedBy": "f313b510-8ff6-4ef7-8c27-070c2ae45fc1",
                    "topic": "c70506cc-aefb-479a-9eee-9f7ef37b9d2c"
                  }
                }
              }
            ],
            "time": 1684302278444.02
          }
        ],
        [
          {
            "body": [
              {
                "ifMatch": {
                  "$set": {
                    "data": {
                      "code": " import vision from \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0\";\n  const { FaceLandmarker, FilesetResolver, DrawingUtils } = vision;\n  let faceLandmarker;\n  let runningMode = \"IMAGE\";\n  const filesetResolver = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm\"\n  );\n  function calculateCentroid(landmarks) {\n     const sum = landmarks.reduce((acc, landmark) => {\n        acc[0] = landmark.x+acc[0];\n        acc[1] = landmark.y+acc[1];\n        acc[2] = landmark.z+acc[2];\n        return acc;\n     }, [0,0,0]);\n     return sum.map(coord => coord / landmarks.length);\n  }\n  faceLandmarker = await FaceLandmarker.createFromOptions(filesetResolver, {\n    baseOptions: {\n      modelAssetPath: \n      \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task\",\n      delegate: \"GPU\"\n    },\n    outputFaceBlendshapes: true,\n    runningMode,\n    numFaces: 1\n  });\n  const centroid = calculateCentroid(faceLandmarker.detect(img).faceLandmarks[0]);",
                      "language": "javascript",
                      "output": ""
                    },
                    "index": 1,
                    "lastEditedBy": "f313b510-8ff6-4ef7-8c27-070c2ae45fc1",
                    "_deleted": false
                  }
                }
              }
            ],
            "creator": "pkhexmkwbs",
            "time": 1684302279078.03
          }
        ],
        [
          {
            "body": [
              {
                "ifMatch": {
                  "$set": {
                    "data": {
                      "code": "import vision from \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0\";\nconst {\n    FaceLandmarker,\n    FilesetResolver,\n    DrawingUtils\n} = vision;\nlet faceLandmarker;\nlet runningMode = \"IMAGE\";\nconst filesetResolver = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm\"\n);\n\nfunction calculateCentroid(landmarks) {\n    const sum = landmarks.reduce((acc, landmark) => {\n        acc[0] = landmark.x + acc[0];\n        acc[1] = landmark.y + acc[1];\n        acc[2] = landmark.z + acc[2];\n        return acc;\n    }, [0, 0, 0]);\n    return sum.map(coord => coord / landmarks.length);\n}\nfaceLandmarker = await FaceLandmarker.createFromOptions(filesetResolver, {\n    baseOptions: {\n        modelAssetPath: \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task\",\n        delegate: \"GPU\"\n    },\n    outputFaceBlendshapes: true,\n    runningMode,\n    numFaces: 1\n});\nconst centroid = calculateCentroid(faceLandmarker.detect(img).faceLandmarks[0]);",
                      "language": "javascript",
                      "output": ""
                    },
                    "index": 1,
                    "lastEditedBy": "f313b510-8ff6-4ef7-8c27-070c2ae45fc1",
                    "_deleted": false
                  }
                }
              }
            ],
            "creator": "pkhexmkwbs",
            "time": 1684302308130.01
          }
        ],
        [
          {
            "body": [
              {
                "ifMatch": {
                  "$set": {
                    "data": {
                      "code": "import vision from \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0\";\nconst {\n    FaceLandmarker,\n    FilesetResolver,\n    DrawingUtils\n} = vision;\nlet faceLandmarker;\n\nlet runningMode = \"IMAGE\";\n\nconst filesetResolver = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm\"\n);\n\nfunction calculateCentroid(landmarks) {\n    const sum = landmarks.reduce((acc, landmark) => {\n        acc[0] = landmark.x + acc[0];\n        acc[1] = landmark.y + acc[1];\n        acc[2] = landmark.z + acc[2];\n        return acc;\n    }, [0, 0, 0]);\n    return sum.map(coord => coord / landmarks.length);\n}\nfaceLandmarker = await FaceLandmarker.createFromOptions(filesetResolver, {\n    baseOptions: {\n        modelAssetPath: \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task\",\n        delegate: \"GPU\"\n    },\n    outputFaceBlendshapes: true,\n    runningMode,\n    numFaces: 1\n});\nconst centroid = calculateCentroid(faceLandmarker.detect(img).faceLandmarks[0]);",
                      "language": "javascript",
                      "output": ""
                    },
                    "index": 1,
                    "lastEditedBy": "f313b510-8ff6-4ef7-8c27-070c2ae45fc1",
                    "_deleted": false
                  }
                }
              }
            ],
            "creator": "pkhexmkwbs",
            "time": 1684302314224.02
          }
        ],
        [
          {
            "body": [
              {
                "ifMatch": {
                  "$set": {
                    "data": {
                      "code": "import vision from \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0\";\nconst {\n    FaceLandmarker,\n    FilesetResolver,\n    DrawingUtils\n} = vision;\n\nlet faceLandmarker;\n\nlet runningMode = \"IMAGE\";\n\nconst filesetResolver = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm\"\n);\n\nfunction calculateCentroid(landmarks) {\n    const sum = landmarks.reduce((acc, landmark) => {\n        acc[0] = landmark.x + acc[0];\n        acc[1] = landmark.y + acc[1];\n        acc[2] = landmark.z + acc[2];\n        return acc;\n    }, [0, 0, 0]);\n    return sum.map(coord => coord / landmarks.length);\n}\nfaceLandmarker = await FaceLandmarker.createFromOptions(filesetResolver, {\n    baseOptions: {\n        modelAssetPath: \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task\",\n        delegate: \"GPU\"\n    },\n    outputFaceBlendshapes: true,\n    runningMode,\n    numFaces: 1\n});\nconst centroid = calculateCentroid(faceLandmarker.detect(img).faceLandmarks[0]);",
                      "language": "javascript",
                      "output": ""
                    },
                    "index": 1,
                    "lastEditedBy": "f313b510-8ff6-4ef7-8c27-070c2ae45fc1",
                    "_deleted": false
                  }
                }
              }
            ],
            "creator": "pkhexmkwbs",
            "time": 1684302317177.01
          }
        ],
        [
          {
            "body": [
              {
                "ifMatch": {
                  "$set": {
                    "data": {
                      "code": "import vision from \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0\";\nconst {\n    FaceLandmarker,\n    FilesetResolver,\n    DrawingUtils\n} = vision;\n\nlet faceLandmarker;\n\nlet runningMode = \"IMAGE\";\n\nconst filesetResolver = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm\"\n);\n\nfunction calculateCentroid(landmarks) {\n    const sum = landmarks.reduce((acc, landmark) => {\n        acc[0] = landmark.x + acc[0];\n        acc[1] = landmark.y + acc[1];\n        acc[2] = landmark.z + acc[2];\n        return acc;\n    }, [0, 0, 0]);\n    return sum.map(coord => coord / landmarks.length);\n}\nconst faceLandmarker = await FaceLandmarker.createFromOptions(filesetResolver, {\n    baseOptions: {\n        modelAssetPath: \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task\",\n        delegate: \"GPU\"\n    },\n    outputFaceBlendshapes: true,\n    runningMode,\n    numFaces: 1\n});\nconst centroid = calculateCentroid(faceLandmarker.detect(img).faceLandmarks[0]);",
                      "language": "javascript",
                      "output": ""
                    },
                    "index": 1,
                    "lastEditedBy": "f313b510-8ff6-4ef7-8c27-070c2ae45fc1",
                    "_deleted": false
                  }
                }
              }
            ],
            "creator": "pkhexmkwbs",
            "time": 1684302338560.02
          }
        ],
        [
          {
            "body": [
              {
                "ifMatch": {
                  "$set": {
                    "data": {
                      "code": "import vision from \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0\";\nconst {\n    FaceLandmarker,\n    FilesetResolver,\n    DrawingUtils\n} = vision;\n\nlet faceLandmarker;\n\nlet runningMode = \"IMAGE\";\n\nconst filesetResolver = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm\"\n);\n\nfunction calculateCentroid(landmarks) {\n    const sum = landmarks.reduce((acc, landmark) => {\n        acc[0] = landmark.x + acc[0];\n        acc[1] = landmark.y + acc[1];\n        acc[2] = landmark.z + acc[2];\n        return acc;\n    }, [0, 0, 0]);\n    return sum.map(coord => coord / landmarks.length);\n}\n\nconst faceLandmarker = await FaceLandmarker.createFromOptions(filesetResolver, {\n    baseOptions: {\n        modelAssetPath: \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task\",\n        delegate: \"GPU\"\n    },\n    outputFaceBlendshapes: true,\n    runningMode,\n    numFaces: 1\n});\nconst centroid = calculateCentroid(faceLandmarker.detect(img).faceLandmarks[0]);",
                      "language": "javascript",
                      "output": ""
                    },
                    "index": 1,
                    "lastEditedBy": "f313b510-8ff6-4ef7-8c27-070c2ae45fc1",
                    "_deleted": false
                  }
                }
              }
            ],
            "creator": "pkhexmkwbs",
            "time": 1684302339640.06
          }
        ],
        [
          {
            "body": [
              {
                "ifMatch": {
                  "$set": {
                    "data": {
                      "code": "import vision from \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0\";\nconst {\n    FaceLandmarker,\n    FilesetResolver,\n    DrawingUtils\n} = vision;\n\nlet faceLandmarker;\n\nlet runningMode = ;\n\nconst filesetResolver = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm\"\n);\n\nfunction calculateCentroid(landmarks) {\n    const sum = landmarks.reduce((acc, landmark) => {\n        acc[0] = landmark.x + acc[0];\n        acc[1] = landmark.y + acc[1];\n        acc[2] = landmark.z + acc[2];\n        return acc;\n    }, [0, 0, 0]);\n    return sum.map(coord => coord / landmarks.length);\n}\n\nconst faceLandmarker = await FaceLandmarker.createFromOptions(filesetResolver, {\n    baseOptions: {\n        modelAssetPath: \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task\",\n        delegate: \"GPU\"\n    },\n    outputFaceBlendshapes: true,\n    runningMode,\n    numFaces: 1\n});\nconst centroid = calculateCentroid(faceLandmarker.detect(img).faceLandmarks[0]);",
                      "language": "javascript",
                      "output": ""
                    },
                    "index": 1,
                    "lastEditedBy": "f313b510-8ff6-4ef7-8c27-070c2ae45fc1",
                    "_deleted": false
                  }
                }
              }
            ],
            "creator": "pkhexmkwbs",
            "time": 1684302343344.02
          }
        ],
        [
          {
            "body": [
              {
                "ifMatch": {
                  "$set": {
                    "data": {
                      "code": "import vision from \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0\";\nconst {\n    FaceLandmarker,\n    FilesetResolver,\n    DrawingUtils\n} = vision;\n\nlet faceLandmarker;\n\nlet runningMode = ;\n\nconst filesetResolver = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm\"\n);\n\nfunction calculateCentroid(landmarks) {\n    const sum = landmarks.reduce((acc, landmark) => {\n        acc[0] = landmark.x + acc[0];\n        acc[1] = landmark.y + acc[1];\n        acc[2] = landmark.z + acc[2];\n        return acc;\n    }, [0, 0, 0]);\n    return sum.map(coord => coord / landmarks.length);\n}\n\nconst faceLandmarker = await FaceLandmarker.createFromOptions(filesetResolver, {\n    baseOptions: {\n        modelAssetPath: \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task\",\n        delegate: \"GPU\"\n    },\n    outputFaceBlendshapes: true,\n    runningMode: \"IMAGE\",\n    numFaces: 1\n});\nconst centroid = calculateCentroid(faceLandmarker.detect(img).faceLandmarks[0]);",
                      "language": "javascript",
                      "output": ""
                    },
                    "index": 1,
                    "lastEditedBy": "f313b510-8ff6-4ef7-8c27-070c2ae45fc1",
                    "_deleted": false
                  }
                }
              }
            ],
            "creator": "pkhexmkwbs",
            "time": 1684302346313.01
          }
        ],
        [
          {
            "body": [
              {
                "ifMatch": {
                  "$set": {
                    "data": {
                      "code": "import vision from \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0\";\nconst {\n    FaceLandmarker,\n    FilesetResolver,\n    DrawingUtils\n} = vision;\n\nconst filesetResolver = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm\"\n);\n\nfunction calculateCentroid(landmarks) {\n    const sum = landmarks.reduce((acc, landmark) => {\n        acc[0] = landmark.x + acc[0];\n        acc[1] = landmark.y + acc[1];\n        acc[2] = landmark.z + acc[2];\n        return acc;\n    }, [0, 0, 0]);\n    return sum.map(coord => coord / landmarks.length);\n}\n\nconst faceLandmarker = await FaceLandmarker.createFromOptions(filesetResolver, {\n    baseOptions: {\n        modelAssetPath: \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task\",\n        delegate: \"GPU\"\n    },\n    outputFaceBlendshapes: true,\n    runningMode: \"IMAGE\",\n    numFaces: 1\n});\nconst centroid = calculateCentroid(faceLandmarker.detect(img).faceLandmarks[0]);",
                      "language": "javascript",
                      "output": ""
                    },
                    "index": 1,
                    "lastEditedBy": "f313b510-8ff6-4ef7-8c27-070c2ae45fc1",
                    "_deleted": false
                  }
                }
              }
            ],
            "creator": "pkhexmkwbs",
            "time": 1684302349560.02
          }
        ],
        [
          {
            "body": [
              {
                "ifMatch": {
                  "$set": {
                    "data": {
                      "code": "import vision from \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0\";\nconst  = vision;\n\nconst filesetResolver = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm\"\n);\n\nfunction calculateCentroid(landmarks) {\n    const sum = landmarks.reduce((acc, landmark) => {\n        acc[0] = landmark.x + acc[0];\n        acc[1] = landmark.y + acc[1];\n        acc[2] = landmark.z + acc[2];\n        return acc;\n    }, [0, 0, 0]);\n    return sum.map(coord => coord / landmarks.length);\n}\n\nconst faceLandmarker = await FaceLandmarker.createFromOptions(filesetResolver, {\n    baseOptions: {\n        modelAssetPath: \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task\",\n        delegate: \"GPU\"\n    },\n    outputFaceBlendshapes: true,\n    runningMode: \"IMAGE\",\n    numFaces: 1\n});\nconst centroid = calculateCentroid(faceLandmarker.detect(img).faceLandmarks[0]);",
                      "language": "javascript",
                      "output": ""
                    },
                    "index": 1,
                    "lastEditedBy": "f313b510-8ff6-4ef7-8c27-070c2ae45fc1",
                    "_deleted": false
                  }
                }
              }
            ],
            "creator": "pkhexmkwbs",
            "time": 1684302356040.02
          }
        ],
        [
          {
            "body": [
              {
                "ifMatch": {
                  "$set": {
                    "data": {
                      "code": "import {\n    FaceLandmarker,\n    FilesetResolver,\n    DrawingUtils\n} from \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0\";\nconst  = vision;\n\nconst filesetResolver = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm\"\n);\n\nfunction calculateCentroid(landmarks) {\n    const sum = landmarks.reduce((acc, landmark) => {\n        acc[0] = landmark.x + acc[0];\n        acc[1] = landmark.y + acc[1];\n        acc[2] = landmark.z + acc[2];\n        return acc;\n    }, [0, 0, 0]);\n    return sum.map(coord => coord / landmarks.length);\n}\n\nconst faceLandmarker = await FaceLandmarker.createFromOptions(filesetResolver, {\n    baseOptions: {\n        modelAssetPath: \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task\",\n        delegate: \"GPU\"\n    },\n    outputFaceBlendshapes: true,\n    runningMode: \"IMAGE\",\n    numFaces: 1\n});\nconst centroid = calculateCentroid(faceLandmarker.detect(img).faceLandmarks[0]);",
                      "language": "javascript",
                      "output": ""
                    },
                    "index": 1,
                    "lastEditedBy": "f313b510-8ff6-4ef7-8c27-070c2ae45fc1",
                    "_deleted": false
                  }
                }
              }
            ],
            "creator": "pkhexmkwbs",
            "time": 1684302356912.06
          }
        ],
        [
          {
            "body": [
              {
                "ifMatch": {
                  "$set": {
                    "data": {
                      "code": "import {\n    FaceLandmarker,\n    FilesetResolver,\n    DrawingUtils\n} from \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0\";\n\nconst filesetResolver = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm\"\n);\n\nfunction calculateCentroid(landmarks) {\n    const sum = landmarks.reduce((acc, landmark) => {\n        acc[0] = landmark.x + acc[0];\n        acc[1] = landmark.y + acc[1];\n        acc[2] = landmark.z + acc[2];\n        return acc;\n    }, [0, 0, 0]);\n    return sum.map(coord => coord / landmarks.length);\n}\n\nconst faceLandmarker = await FaceLandmarker.createFromOptions(filesetResolver, {\n    baseOptions: {\n        modelAssetPath: \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task\",\n        delegate: \"GPU\"\n    },\n    outputFaceBlendshapes: true,\n    runningMode: \"IMAGE\",\n    numFaces: 1\n});\nconst centroid = calculateCentroid(faceLandmarker.detect(img).faceLandmarks[0]);",
                      "language": "javascript",
                      "output": ""
                    },
                    "index": 1,
                    "lastEditedBy": "f313b510-8ff6-4ef7-8c27-070c2ae45fc1",
                    "_deleted": false
                  }
                }
              }
            ],
            "creator": "pkhexmkwbs",
            "time": 1684302359144.02
          }
        ],
        [
          {
            "body": [
              {
                "ifMatch": {
                  "$set": {
                    "data": {
                      "code": "import {\n    FaceLandmarker,\n    FilesetResolver,\n    DrawingUtils\n} from \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0\";\n\nconst filesetResolver = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm\"\n);\n\nfunction calculateCentroid(landmarks) {\n    const sum = landmarks.reduce((acc, landmark) => {\n        acc[0] = landmark.x + acc[0];\n        acc[1] = landmark.y + acc[1];\n        acc[2] = landmark.z + acc[2];\n        return acc;\n    }, [0, 0, 0]);\n    return sum.map(coord => coord / landmarks.length);\n}\n\nconst faceLandmarker = await FaceLandmarker.createFromOptions(filesetResolver, {\n    baseOptions: {\n        modelAssetPath: \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task\",\n        delegate: \"GPU\"\n    },\n    outputFaceBlendshapes: true,\n    runningMode: \"IMAGE\",\n    numFaces: 1\n});\n\nconst centroid = calculateCentroid(faceLandmarker.detect(img).faceLandmarks[0]);",
                      "language": "javascript",
                      "output": ""
                    },
                    "index": 1,
                    "lastEditedBy": "f313b510-8ff6-4ef7-8c27-070c2ae45fc1",
                    "_deleted": false
                  }
                }
              }
            ],
            "creator": "pkhexmkwbs",
            "time": 1684302377832.02
          }
        ],
        [
          {
            "body": [
              {
                "ifMatch": {
                  "$set": {
                    "data": {
                      "code": "import {\n    FaceLandmarker,\n    FilesetResolver,\n    DrawingUtils\n} from \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0\";\n\nconst filesetResolver = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm\"\n);\n\nfunction calculateCentroid(landmarks) {\n    const sum = landmarks.reduce((acc, landmark) => {\n        acc[0] = landmark.x + acc[0];\n        acc[1] = landmark.y + acc[1];\n        acc[2] = landmark.z + acc[2];\n        return acc;\n    }, [0, 0, 0]);\n    return sum.map(coord => coord / landmarks.length);\n}\n\nconst faceLandmarker = await FaceLandmarker.createFromOptions(filesetResolver, {\n    baseOptions: {\n        modelAssetPath: \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task\",\n        delegate: \"GPU\"\n    },\n    outputFaceBlendshapes: true,\n    runningMode: \"IMAGE\",\n    numFaces: 1\n});\n\nimshow",
                      "language": "javascript",
                      "output": ""
                    },
                    "index": 1,
                    "lastEditedBy": "f313b510-8ff6-4ef7-8c27-070c2ae45fc1",
                    "_deleted": false
                  }
                }
              }
            ],
            "creator": "pkhexmkwbs",
            "time": 1684302383520.02
          }
        ],
        [
          {
            "body": [
              {
                "ifMatch": {
                  "$set": {
                    "data": {
                      "code": "import {\n    FaceLandmarker,\n    FilesetResolver,\n    DrawingUtils\n} from \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0\";\n\nconst filesetResolver = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm\"\n);\n\nfunction calculateCentroid(landmarks) {\n    const sum = landmarks.reduce((acc, landmark) => {\n        acc[0] = landmark.x + acc[0];\n        acc[1] = landmark.y + acc[1];\n        acc[2] = landmark.z + acc[2];\n        return acc;\n    }, [0, 0, 0]);\n    return sum.map(coord => coord / landmarks.length);\n}\n\nconst faceLandmarker = await FaceLandmarker.createFromOptions(filesetResolver, {\n    baseOptions: {\n        modelAssetPath: \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task\",\n        delegate: \"GPU\"\n    },\n    outputFaceBlendshapes: true,\n    runningMode: \"IMAGE\",\n    numFaces: 1\n});\n\ncaptureStream().pipe(\n  map(({message}) => ( \n    {\n     message, \n     landmarks:faceLandmarker.detect(message).faceLandmarks[0]\n    }\n   )\n  ),",
                      "language": "javascript",
                      "output": ""
                    },
                    "index": 1,
                    "lastEditedBy": "f313b510-8ff6-4ef7-8c27-070c2ae45fc1",
                    "_deleted": false
                  }
                }
              }
            ],
            "creator": "pkhexmkwbs",
            "time": 1684302397960.02
          }
        ],
        [
          {
            "body": [
              {
                "ifMatch": {
                  "$set": {
                    "data": {
                      "code": "import {\n    FaceLandmarker,\n    FilesetResolver,\n    DrawingUtils\n} from \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0\";\n\nconst filesetResolver = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm\"\n);\n\nfunction calculateCentroid(landmarks) {\n    const sum = landmarks.reduce((acc, landmark) => {\n        acc[0] = landmark.x + acc[0];\n        acc[1] = landmark.y + acc[1];\n        acc[2] = landmark.z + acc[2];\n        return acc;\n    }, [0, 0, 0]);\n    return sum.map(coord => coord / landmarks.length);\n}\n\nconst faceLandmarker = await FaceLandmarker.createFromOptions(filesetResolver, {\n    baseOptions: {\n        modelAssetPath: \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task\",\n        delegate: \"GPU\"\n    },\n    outputFaceBlendshapes: true,\n    runningMode: \"IMAGE\",\n    numFaces: 1\n});\n\ncaptureStream().pipe(\n  map(({message}) => ( \n    {\n     message, \n     landmarks:faceLandmarker.detect(message).faceLandmarks[0]\n    }\n   )\n  )",
                      "language": "javascript",
                      "output": ""
                    },
                    "index": 1,
                    "lastEditedBy": "f313b510-8ff6-4ef7-8c27-070c2ae45fc1",
                    "_deleted": false
                  }
                }
              }
            ],
            "creator": "pkhexmkwbs",
            "time": 1684302399352.02
          }
        ],
        [
          {
            "body": [
              {
                "ifMatch": {
                  "$set": {
                    "data": {
                      "code": "import {\n    FaceLandmarker,\n    FilesetResolver,\n    DrawingUtils\n} from \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0\";\n\nconst filesetResolver = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm\"\n);\n\nfunction calculateCentroid(landmarks) {\n    const sum = landmarks.reduce((acc, landmark) => {\n        acc[0] = landmark.x + acc[0];\n        acc[1] = landmark.y + acc[1];\n        acc[2] = landmark.z + acc[2];\n        return acc;\n    }, [0, 0, 0]);\n    return sum.map(coord => coord / landmarks.length);\n}\n\nconst faceLandmarker = await FaceLandmarker.createFromOptions(filesetResolver, {\n    baseOptions: {\n        modelAssetPath: \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task\",\n        delegate: \"GPU\"\n    },\n    outputFaceBlendshapes: true,\n    runningMode: \"IMAGE\",\n    numFaces: 1\n});\n\ncaptureStream().pipe(\n  map(({message}) => ( \n    {\n     message, \n     landmarks:faceLandmarker.detect(message).faceLandmarks[0]\n    }\n   )\n  )\n)",
                      "language": "javascript",
                      "output": ""
                    },
                    "index": 1,
                    "lastEditedBy": "f313b510-8ff6-4ef7-8c27-070c2ae45fc1",
                    "_deleted": false
                  }
                }
              }
            ],
            "creator": "pkhexmkwbs",
            "time": 1684302400568.06
          }
        ],
        [
          {
            "body": [
              {
                "ifMatch": {
                  "$set": {
                    "data": {
                      "code": "import {\n    FaceLandmarker,\n    FilesetResolver,\n    DrawingUtils\n} from \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0\";\n\nconst filesetResolver = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm\"\n);\n\nfunction calculateCentroid(landmarks) {\n    const sum = landmarks.reduce((acc, landmark) => {\n        acc[0] = landmark.x + acc[0];\n        acc[1] = landmark.y + acc[1];\n        acc[2] = landmark.z + acc[2];\n        return acc;\n    }, [0, 0, 0]);\n    return sum.map(coord => coord / landmarks.length);\n}\n\nconst faceLandmarker = await FaceLandmarker.createFromOptions(filesetResolver, {\n    baseOptions: {\n        modelAssetPath: \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task\",\n        delegate: \"GPU\"\n    },\n    outputFaceBlendshapes: true,\n    runningMode: \"IMAGE\",\n    numFaces: 1\n});\n\ncaptureStream().pipe(\n  map(({message}) => ( \n    {\n     message, \n     landmarks:faceLandmarker.detect(message).faceLandmarks[0]\n    }\n   )\n  ),\n  rewrite()\n)",
                      "language": "javascript",
                      "output": ""
                    },
                    "index": 1,
                    "lastEditedBy": "f313b510-8ff6-4ef7-8c27-070c2ae45fc1",
                    "_deleted": false
                  }
                }
              }
            ],
            "creator": "pkhexmkwbs",
            "time": 1684302404128.02
          }
        ],
        [
          {
            "body": [
              {
                "ifMatch": {
                  "$set": {
                    "data": {
                      "code": "import {\n    FaceLandmarker,\n    FilesetResolver,\n    DrawingUtils\n} from \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0\";\n\nconst filesetResolver = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm\"\n);\n\nfunction calculateCentroid(landmarks) {\n    const sum = landmarks.reduce((acc, landmark) => {\n        acc[0] = landmark.x + acc[0];\n        acc[1] = landmark.y + acc[1];\n        acc[2] = landmark.z + acc[2];\n        return acc;\n    }, [0, 0, 0]);\n    return sum.map(coord => coord / landmarks.length);\n}\n\nconst faceLandmarker = await FaceLandmarker.createFromOptions(filesetResolver, {\n    baseOptions: {\n        modelAssetPath: \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task\",\n        delegate: \"GPU\"\n    },\n    outputFaceBlendshapes: true,\n    runningMode: \"IMAGE\",\n    numFaces: 1\n});\n\ncaptureStream().pipe(\n  map(({message}) => ( \n    {\n     landmarks:faceLandmarker.detect(message).faceLandmarks[0]\n    }\n   )\n  ),\n  rewrite()\n)",
                      "language": "javascript",
                      "output": ""
                    },
                    "index": 1,
                    "lastEditedBy": "f313b510-8ff6-4ef7-8c27-070c2ae45fc1",
                    "_deleted": false
                  }
                }
              }
            ],
            "creator": "pkhexmkwbs",
            "time": 1684302408216.02
          }
        ],
        [
          {
            "body": [
              {
                "ifMatch": {
                  "$set": {
                    "data": {
                      "code": "import {\n    FaceLandmarker,\n    FilesetResolver,\n    DrawingUtils\n} from \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0\";\n\nconst filesetResolver = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm\"\n);\n\nfunction calculateCentroid(landmarks) {\n    const sum = landmarks.reduce((acc, landmark) => {\n        acc[0] = landmark.x + acc[0];\n        acc[1] = landmark.y + acc[1];\n        acc[2] = landmark.z + acc[2];\n        return acc;\n    }, [0, 0, 0]);\n    return sum.map(coord => coord / landmarks.length);\n}\n\nconst faceLandmarker = await FaceLandmarker.createFromOptions(filesetResolver, {\n    baseOptions: {\n        modelAssetPath: \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task\",\n        delegate: \"GPU\"\n    },\n    outputFaceBlendshapes: true,\n    runningMode: \"IMAGE\",\n    numFaces: 1\n});\n\ncaptureStream().pipe(\n  map(({message}) => ( \n    {\n     faceLandmarker.detect(message).faceLandmarks[0]\n    }\n   )\n  ),\n  rewrite()\n)",
                      "language": "javascript",
                      "output": ""
                    },
                    "index": 1,
                    "lastEditedBy": "f313b510-8ff6-4ef7-8c27-070c2ae45fc1",
                    "_deleted": false
                  }
                }
              }
            ],
            "creator": "pkhexmkwbs",
            "time": 1684302411473.05
          }
        ],
        [
          {
            "body": [
              {
                "ifMatch": {
                  "$set": {
                    "data": {
                      "code": "import {\n    FaceLandmarker,\n    FilesetResolver,\n    DrawingUtils\n} from \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0\";\n\nconst filesetResolver = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm\"\n);\n\nfunction calculateCentroid(landmarks) {\n    const sum = landmarks.reduce((acc, landmark) => {\n        acc[0] = landmark.x + acc[0];\n        acc[1] = landmark.y + acc[1];\n        acc[2] = landmark.z + acc[2];\n        return acc;\n    }, [0, 0, 0]);\n    return sum.map(coord => coord / landmarks.length);\n}\n\nconst faceLandmarker = await FaceLandmarker.createFromOptions(filesetResolver, {\n    baseOptions: {\n        modelAssetPath: \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task\",\n        delegate: \"GPU\"\n    },\n    outputFaceBlendshapes: true,\n    runningMode: \"IMAGE\",\n    numFaces: 1\n});\n\ncaptureStream().pipe(\n  map(({message}) => ( \n    {\n     faceLandmarker.detect(message).faceLandmarks[0]\n    \n   )\n  ),\n  rewrite()\n)",
                      "language": "javascript",
                      "output": ""
                    },
                    "index": 1,
                    "lastEditedBy": "f313b510-8ff6-4ef7-8c27-070c2ae45fc1",
                    "_deleted": false
                  }
                }
              }
            ],
            "creator": "pkhexmkwbs",
            "time": 1684302412728.06
          }
        ],
        [
          {
            "body": [
              {
                "ifMatch": {
                  "$set": {
                    "data": {
                      "code": "import {\n    FaceLandmarker,\n    FilesetResolver,\n    DrawingUtils\n} from \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0\";\n\nconst filesetResolver = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm\"\n);\n\nfunction calculateCentroid(landmarks) {\n    const sum = landmarks.reduce((acc, landmark) => {\n        acc[0] = landmark.x + acc[0];\n        acc[1] = landmark.y + acc[1];\n        acc[2] = landmark.z + acc[2];\n        return acc;\n    }, [0, 0, 0]);\n    return sum.map(coord => coord / landmarks.length);\n}\n\nconst faceLandmarker = await FaceLandmarker.createFromOptions(filesetResolver, {\n    baseOptions: {\n        modelAssetPath: \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task\",\n        delegate: \"GPU\"\n    },\n    outputFaceBlendshapes: true,\n    runningMode: \"IMAGE\",\n    numFaces: 1\n});\n\ncaptureStream().pipe(\n  map(({message}) => ( \n    \n     faceLandmarker.detect(message).faceLandmarks[0]\n    \n   )\n  ),\n  rewrite()\n)",
                      "language": "javascript",
                      "output": ""
                    },
                    "index": 1,
                    "lastEditedBy": "f313b510-8ff6-4ef7-8c27-070c2ae45fc1",
                    "_deleted": false
                  }
                }
              }
            ],
            "creator": "pkhexmkwbs",
            "time": 1684302413313.05
          }
        ],
        [
          {
            "body": [
              {
                "ifMatch": {
                  "$set": {
                    "data": {
                      "code": "import {\n    FaceLandmarker,\n    FilesetResolver,\n    DrawingUtils\n} from \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0\";\n\nconst filesetResolver = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm\"\n);\n\nfunction calculateCentroid(landmarks) {\n    const sum = landmarks.reduce((acc, landmark) => {\n        acc[0] = landmark.x + acc[0];\n        acc[1] = landmark.y + acc[1];\n        acc[2] = landmark.z + acc[2];\n        return acc;\n    }, [0, 0, 0]);\n    return sum.map(coord => coord / landmarks.length);\n}\n\nconst faceLandmarker = await FaceLandmarker.createFromOptions(filesetResolver, {\n    baseOptions: {\n        modelAssetPath: \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task\",\n        delegate: \"GPU\"\n    },\n    outputFaceBlendshapes: true,\n    runningMode: \"IMAGE\",\n    numFaces: 1\n});\n\ncaptureStream().pipe(\n  map(({message}) => ( \n    faceLandmarker.detect(message).faceLandmarks[0]\n    \n   )\n  ),\n  rewrite()\n)",
                      "language": "javascript",
                      "output": ""
                    },
                    "index": 1,
                    "lastEditedBy": "f313b510-8ff6-4ef7-8c27-070c2ae45fc1",
                    "_deleted": false
                  }
                }
              }
            ],
            "creator": "pkhexmkwbs",
            "time": 1684302415153.01
          }
        ],
        [
          {
            "body": [
              {
                "ifMatch": {
                  "$set": {
                    "data": {
                      "code": "import {\n    FaceLandmarker,\n    FilesetResolver,\n    DrawingUtils\n} from \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0\";\n\nconst filesetResolver = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm\"\n);\n\nfunction calculateCentroid(landmarks) {\n    const sum = landmarks.reduce((acc, landmark) => {\n        acc[0] = landmark.x + acc[0];\n        acc[1] = landmark.y + acc[1];\n        acc[2] = landmark.z + acc[2];\n        return acc;\n    }, [0, 0, 0]);\n    return sum.map(coord => coord / landmarks.length);\n}\n\nconst faceLandmarker = await FaceLandmarker.createFromOptions(filesetResolver, {\n    baseOptions: {\n        modelAssetPath: \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task\",\n        delegate: \"GPU\"\n    },\n    outputFaceBlendshapes: true,\n    runningMode: \"IMAGE\",\n    numFaces: 1\n});\n\ncaptureStream().pipe(\n  map(({message}) => ( faceLandmarker.detect(message).faceLandmarks[0]\n   )\n  ),\n  rewrite()\n)",
                      "language": "javascript",
                      "output": ""
                    },
                    "index": 1,
                    "lastEditedBy": "f313b510-8ff6-4ef7-8c27-070c2ae45fc1",
                    "_deleted": false
                  }
                }
              }
            ],
            "creator": "pkhexmkwbs",
            "time": 1684302418976.06
          }
        ],
        [
          {
            "body": [
              {
                "ifMatch": {
                  "$set": {
                    "data": {
                      "code": "import {\n    FaceLandmarker,\n    FilesetResolver,\n    DrawingUtils\n} from \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0\";\n\nconst filesetResolver = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm\"\n);\n\nfunction calculateCentroid(landmarks) {\n    const sum = landmarks.reduce((acc, landmark) => {\n        acc[0] = landmark.x + acc[0];\n        acc[1] = landmark.y + acc[1];\n        acc[2] = landmark.z + acc[2];\n        return acc;\n    }, [0, 0, 0]);\n    return sum.map(coord => coord / landmarks.length);\n}\n\nconst faceLandmarker = await FaceLandmarker.createFromOptions(filesetResolver, {\n    baseOptions: {\n        modelAssetPath: \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task\",\n        delegate: \"GPU\"\n    },\n    outputFaceBlendshapes: true,\n    runningMode: \"IMAGE\",\n    numFaces: 1\n});\n\ncaptureStream().pipe(\n  map(({message}) => ( faceLandmarker.detect(message).faceLandmarks[0]),\n  rewrite()\n)",
                      "language": "javascript",
                      "output": ""
                    },
                    "index": 1,
                    "lastEditedBy": "f313b510-8ff6-4ef7-8c27-070c2ae45fc1",
                    "_deleted": false
                  }
                }
              }
            ],
            "creator": "pkhexmkwbs",
            "time": 1684302421056.06
          }
        ],
        [
          {
            "body": [
              {
                "ifMatch": {
                  "$set": {
                    "data": {
                      "code": "import {\n    FaceLandmarker,\n    FilesetResolver,\n    DrawingUtils\n} from \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0\";\n\nconst filesetResolver = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm\"\n);\n\nfunction calculateCentroid(landmarks) {\n    const sum = landmarks.reduce((acc, landmark) => {\n        acc[0] = landmark.x + acc[0];\n        acc[1] = landmark.y + acc[1];\n        acc[2] = landmark.z + acc[2];\n        return acc;\n    }, [0, 0, 0]);\n    return sum.map(coord => coord / landmarks.length);\n}\n\nconst faceLandmarker = await FaceLandmarker.createFromOptions(filesetResolver, {\n    baseOptions: {\n        modelAssetPath: \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task\",\n        delegate: \"GPU\"\n    },\n    outputFaceBlendshapes: true,\n    runningMode: \"IMAGE\",\n    numFaces: 1\n});\n\ncaptureStream().pipe(\n  map(({message}) => ( faceLandmarker.detect(message).faceLandmarks[0])\n  ),\n  rewrite()\n)",
                      "language": "javascript",
                      "output": ""
                    },
                    "index": 1,
                    "lastEditedBy": "f313b510-8ff6-4ef7-8c27-070c2ae45fc1",
                    "_deleted": false
                  }
                }
              }
            ],
            "creator": "pkhexmkwbs",
            "time": 1684302421888.06
          }
        ],
        [
          {
            "body": [
              {
                "ifMatch": {
                  "$set": {
                    "data": {
                      "code": "import {\n    FaceLandmarker,\n    FilesetResolver,\n    DrawingUtils\n} from \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0\";\n\nconst filesetResolver = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm\"\n);\n\nfunction calculateCentroid(landmarks) {\n    const sum = landmarks.reduce((acc, landmark) => {\n        acc[0] = landmark.x + acc[0];\n        acc[1] = landmark.y + acc[1];\n        acc[2] = landmark.z + acc[2];\n        return acc;\n    }, [0, 0, 0]);\n    return sum.map(coord => coord / landmarks.length);\n}\n\nconst faceLandmarker = await FaceLandmarker.createFromOptions(filesetResolver, {\n    baseOptions: {\n        modelAssetPath: \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task\",\n        delegate: \"GPU\"\n    },\n    outputFaceBlendshapes: true,\n    runningMode: \"IMAGE\",\n    numFaces: 1\n});\n\ncaptureStream().pipe(\n  map(({message}) => ( faceLandmarker.detect(message).faceLandmarks[0])),\n  rewrite()\n)",
                      "language": "javascript",
                      "output": ""
                    },
                    "index": 1,
                    "lastEditedBy": "f313b510-8ff6-4ef7-8c27-070c2ae45fc1",
                    "_deleted": false
                  }
                }
              }
            ],
            "creator": "pkhexmkwbs",
            "time": 1684302424316.01
          }
        ],
        [
          {
            "body": [
              {
                "ifMatch": {
                  "$set": {
                    "data": {
                      "code": "import {\n    FaceLandmarker,\n    FilesetResolver,\n    DrawingUtils\n} from \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0\";\n\nconst filesetResolver = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm\"\n);\n\nfunction calculateCentroid(landmarks) {\n    const sum = landmarks.reduce((acc, landmark) => {\n        acc[0] = landmark.x + acc[0];\n        acc[1] = landmark.y + acc[1];\n        acc[2] = landmark.z + acc[2];\n        return acc;\n    }, [0, 0, 0]);\n    return sum.map(coord => coord / landmarks.length);\n}\n\nconst faceLandmarker = await FaceLandmarker.createFromOptions(filesetResolver, {\n    baseOptions: {\n        modelAssetPath: \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task\",\n        delegate: \"GPU\"\n    },\n    outputFaceBlendshapes: true,\n    runningMode: \"IMAGE\",\n    numFaces: 1\n});\n\ncaptureStream().pipe(\n  map(({message}) => (faceLandmarker.detect(message).faceLandmarks[0])),\n  rewrite()\n)",
                      "language": "javascript",
                      "output": ""
                    },
                    "index": 1,
                    "lastEditedBy": "f313b510-8ff6-4ef7-8c27-070c2ae45fc1",
                    "_deleted": false
                  }
                }
              }
            ],
            "creator": "pkhexmkwbs",
            "time": 1684302425496.06
          }
        ],
        [
          {
            "body": [
              {
                "ifMatch": {
                  "$set": {
                    "data": {
                      "code": "import {\n    FaceLandmarker,\n    FilesetResolver,\n    DrawingUtils\n} from \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0\";\n\nconst filesetResolver = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm\"\n);\n\nfunction calculateCentroid(landmarks) {\n    const sum = landmarks.reduce((acc, landmark) => {\n        acc[0] = landmark.x + acc[0];\n        acc[1] = landmark.y + acc[1];\n        acc[2] = landmark.z + acc[2];\n        return acc;\n    }, [0, 0, 0]);\n    return sum.map(coord => coord / landmarks.length);\n}\n\nconst faceLandmarker = await FaceLandmarker.createFromOptions(filesetResolver, {\n    baseOptions: {\n        modelAssetPath: \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task\",\n        delegate: \"GPU\"\n    },\n    outputFaceBlendshapes: true,\n    runningMode: \"IMAGE\",\n    numFaces: 1\n});\n\ncaptureStream().pipe(\n  map(({message}) => faceLandmarker.detect(message).faceLandmarks[0])),\n  rewrite()\n)",
                      "language": "javascript",
                      "output": ""
                    },
                    "index": 1,
                    "lastEditedBy": "f313b510-8ff6-4ef7-8c27-070c2ae45fc1",
                    "_deleted": false
                  }
                }
              }
            ],
            "creator": "pkhexmkwbs",
            "time": 1684302426288.06
          }
        ],
        [
          {
            "body": [
              {
                "ifMatch": {
                  "$set": {
                    "data": {
                      "code": "import {\n    FaceLandmarker,\n    FilesetResolver,\n    DrawingUtils\n} from \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0\";\n\nconst filesetResolver = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm\"\n);\n\nfunction calculateCentroid(landmarks) {\n    const sum = landmarks.reduce((acc, landmark) => {\n        acc[0] = landmark.x + acc[0];\n        acc[1] = landmark.y + acc[1];\n        acc[2] = landmark.z + acc[2];\n        return acc;\n    }, [0, 0, 0]);\n    return sum.map(coord => coord / landmarks.length);\n}\n\nconst faceLandmarker = await FaceLandmarker.createFromOptions(filesetResolver, {\n    baseOptions: {\n        modelAssetPath: \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task\",\n        delegate: \"GPU\"\n    },\n    outputFaceBlendshapes: true,\n    runningMode: \"IMAGE\",\n    numFaces: 1\n});\n\ncaptureStream().pipe(\n  map(({message}) => faceLandmarker.detect(message).faceLandmarks[0]),\n  rewrite()\n)",
                      "language": "javascript",
                      "output": ""
                    },
                    "index": 1,
                    "lastEditedBy": "f313b510-8ff6-4ef7-8c27-070c2ae45fc1",
                    "_deleted": false
                  }
                }
              }
            ],
            "creator": "pkhexmkwbs",
            "time": 1684302427305.01
          }
        ],
        [
          {
            "body": [
              {
                "ifMatch": {
                  "$set": {
                    "data": {
                      "code": "import {\n    FaceLandmarker,\n    FilesetResolver,\n    DrawingUtils\n} from \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0\";\n\nconst filesetResolver = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm\"\n);\n\nfunction calculateCentroid(landmarks) {\n    const sum = landmarks.reduce((acc, landmark) => {\n        acc[0] = landmark.x + acc[0];\n        acc[1] = landmark.y + acc[1];\n        acc[2] = landmark.z + acc[2];\n        return acc;\n    }, [0, 0, 0]);\n    return sum.map(coord => coord / landmarks.length);\n}\n\nconst faceLandmarker = await FaceLandmarker.createFromOptions(filesetResolver, {\n    baseOptions: {\n        modelAssetPath: \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task\",\n        delegate: \"GPU\"\n    },\n    outputFaceBlendshapes: true,\n    runningMode: \"IMAGE\",\n    numFaces: 1\n});\n\ncaptureStream().pipe(\n  map(({message: }) => faceLandmarker.detect(message).faceLandmarks[0]),\n  rewrite()\n)",
                      "language": "javascript",
                      "output": ""
                    },
                    "index": 1,
                    "lastEditedBy": "f313b510-8ff6-4ef7-8c27-070c2ae45fc1",
                    "_deleted": false
                  }
                }
              }
            ],
            "creator": "pkhexmkwbs",
            "time": 1684302429913.01
          }
        ],
        [
          {
            "body": [
              {
                "ifMatch": {
                  "$set": {
                    "data": {
                      "code": "import {\n    FaceLandmarker,\n    FilesetResolver,\n    DrawingUtils\n} from \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0\";\n\nconst filesetResolver = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm\"\n);\n\nfunction calculateCentroid(landmarks) {\n    const sum = landmarks.reduce((acc, landmark) => {\n        acc[0] = landmark.x + acc[0];\n        acc[1] = landmark.y + acc[1];\n        acc[2] = landmark.z + acc[2];\n        return acc;\n    }, [0, 0, 0]);\n    return sum.map(coord => coord / landmarks.length);\n}\n\nconst faceLandmarker = await FaceLandmarker.createFromOptions(filesetResolver, {\n    baseOptions: {\n        modelAssetPath: \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task\",\n        delegate: \"GPU\"\n    },\n    outputFaceBlendshapes: true,\n    runningMode: \"IMAGE\",\n    numFaces: 1\n});\n\ncaptureStream().pipe(\n  map(({message: img}) => faceLandmarker.detect(message).faceLandmarks[0]),\n  rewrite()\n)",
                      "language": "javascript",
                      "output": ""
                    },
                    "index": 1,
                    "lastEditedBy": "f313b510-8ff6-4ef7-8c27-070c2ae45fc1",
                    "_deleted": false
                  }
                }
              }
            ],
            "creator": "pkhexmkwbs",
            "time": 1684302431632.02
          }
        ],
        [
          {
            "body": [
              {
                "ifMatch": {
                  "$set": {
                    "data": {
                      "code": "import {\n    FaceLandmarker,\n    FilesetResolver,\n    DrawingUtils\n} from \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0\";\n\nconst filesetResolver = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm\"\n);\n\nfunction calculateCentroid(landmarks) {\n    const sum = landmarks.reduce((acc, landmark) => {\n        acc[0] = landmark.x + acc[0];\n        acc[1] = landmark.y + acc[1];\n        acc[2] = landmark.z + acc[2];\n        return acc;\n    }, [0, 0, 0]);\n    return sum.map(coord => coord / landmarks.length);\n}\n\nconst faceLandmarker = await FaceLandmarker.createFromOptions(filesetResolver, {\n    baseOptions: {\n        modelAssetPath: \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task\",\n        delegate: \"GPU\"\n    },\n    outputFaceBlendshapes: true,\n    runningMode: \"IMAGE\",\n    numFaces: 1\n});\n\ncaptureStream().pipe(\n  map(({message: img}) => faceLandmarker.detect(img).faceLandmarks[0]),\n  rewrite()\n)",
                      "language": "javascript",
                      "output": ""
                    },
                    "index": 1,
                    "lastEditedBy": "f313b510-8ff6-4ef7-8c27-070c2ae45fc1",
                    "_deleted": false
                  }
                }
              }
            ],
            "creator": "pkhexmkwbs",
            "time": 1684302435352.02
          }
        ],
        [
          {
            "body": [
              {
                "ifMatch": {
                  "$set": {
                    "data": {
                      "code": "import {\n    FaceLandmarker,\n    FilesetResolver,\n    DrawingUtils\n} from \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0\";\n\nconst filesetResolver = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm\"\n);\n\nfunction calculateCentroid(landmarks) {\n    const sum = landmarks.reduce((acc, landmark) => {\n        acc[0] = landmark.x + acc[0];\n        acc[1] = landmark.y + acc[1];\n        acc[2] = landmark.z + acc[2];\n        return acc;\n    }, [0, 0, 0]);\n    return sum.map(coord => coord / landmarks.length);\n}\n\nconst faceLandmarker = await FaceLandmarker.createFromOptions(filesetResolver, {\n    baseOptions: {\n        modelAssetPath: \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task\",\n        delegate: \"GPU\"\n    },\n    outputFaceBlendshapes: true,\n    runningMode: \"IMAGE\",\n    numFaces: 1\n});\n\nconst visionLine = 0.5;\n  const distance = visionLine-centroid[0];\n  const relativeDistance = Math.abs(distance)/centroid[0];\n  const threshold = 0.7;\n  const action = relativeDistance >= threshold ? \"NONE\" : distance > 0 ? \"l\" : \"r\";\n\ncaptureStream().pipe(\n  map(({message: img}) => faceLandmarker.detect(img).faceLandmarks[0]),\n  rewrite()\n)",
                      "language": "javascript",
                      "output": ""
                    },
                    "index": 1,
                    "lastEditedBy": "f313b510-8ff6-4ef7-8c27-070c2ae45fc1",
                    "_deleted": false
                  }
                }
              }
            ],
            "creator": "pkhexmkwbs",
            "time": 1684302452608.02
          }
        ],
        [
          {
            "body": [
              {
                "ifMatch": {
                  "$set": {
                    "data": {
                      "code": "import {\n    FaceLandmarker,\n    FilesetResolver,\n    DrawingUtils\n} from \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0\";\n\nconst filesetResolver = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm\"\n);\n\nfunction calculateCentroid(landmarks) {\n    const sum = landmarks.reduce((acc, landmark) => {\n        acc[0] = landmark.x + acc[0];\n        acc[1] = landmark.y + acc[1];\n        acc[2] = landmark.z + acc[2];\n        return acc;\n    }, [0, 0, 0]);\n    return sum.map(coord => coord / landmarks.length);\n}\n\nconst faceLandmarker = await FaceLandmarker.createFromOptions(filesetResolver, {\n    baseOptions: {\n        modelAssetPath: \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task\",\n        delegate: \"GPU\"\n    },\n    outputFaceBlendshapes: true,\n    runningMode: \"IMAGE\",\n    numFaces: 1\n});\nconst visionLine = 0.5;\n  const distance = visionLine-centroid[0];\n  const relativeDistance = Math.abs(distance)/centroid[0];\n  const threshold = 0.7;\n  const action = relativeDistance >= threshold ? \"NONE\" : distance > 0 ? \"l\" : \"r\";\n\ncaptureStream().pipe(\n  map(({message: img}) => faceLandmarker.detect(img).faceLandmarks[0]),\n  rewrite()\n)",
                      "language": "javascript",
                      "output": ""
                    },
                    "index": 1,
                    "lastEditedBy": "f313b510-8ff6-4ef7-8c27-070c2ae45fc1",
                    "_deleted": false
                  }
                }
              }
            ],
            "creator": "pkhexmkwbs",
            "time": 1684302453144.06
          }
        ],
        [
          {
            "body": [
              {
                "ifMatch": {
                  "$set": {
                    "data": {
                      "code": "import {\n    FaceLandmarker,\n    FilesetResolver,\n    DrawingUtils\n} from \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0\";\n\nconst filesetResolver = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm\"\n);\n\nfunction calculateCentroid(landmarks) {\n    const sum = landmarks.reduce((acc, landmark) => {\n        acc[0] = landmark.x + acc[0];\n        acc[1] = landmark.y + acc[1];\n        acc[2] = landmark.z + acc[2];\n        return acc;\n    }, [0, 0, 0]);\n    return sum.map(coord => coord / landmarks.length);\n}\n\nconst faceLandmarker = await FaceLandmarker.createFromOptions(filesetResolver, {\n    baseOptions: {\n        modelAssetPath: \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task\",\n        delegate: \"GPU\"\n    },\n    outputFaceBlendshapes: true,\n    runningMode: \"IMAGE\",\n    numFaces: 1\n});\n\n\nconst visionLine = 0.5;\n  const distance = visionLine-centroid[0];\n  const relativeDistance = Math.abs(distance)/centroid[0];\n  const threshold = 0.7;\n  const action = relativeDistance >= threshold ? \"NONE\" : distance > 0 ? \"l\" : \"r\";\n\ncaptureStream().pipe(\n  map(({message: img}) => faceLandmarker.detect(img).faceLandmarks[0]),\n  rewrite()\n)",
                      "language": "javascript",
                      "output": ""
                    },
                    "index": 1,
                    "lastEditedBy": "f313b510-8ff6-4ef7-8c27-070c2ae45fc1",
                    "_deleted": false
                  }
                }
              }
            ],
            "creator": "pkhexmkwbs",
            "time": 1684302454976.06
          }
        ],
        [
          {
            "body": [
              {
                "ifMatch": {
                  "$set": {
                    "data": {
                      "code": "import {\n    FaceLandmarker,\n    FilesetResolver,\n    DrawingUtils\n} from \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0\";\n\nconst filesetResolver = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm\"\n);\n\nfunction calculateCentroid(landmarks) {\n    const sum = landmarks.reduce((acc, landmark) => {\n        acc[0] = landmark.x + acc[0];\n        acc[1] = landmark.y + acc[1];\n        acc[2] = landmark.z + acc[2];\n        return acc;\n    }, [0, 0, 0]);\n    return sum.map(coord => coord / landmarks.length);\n}\n\nconst faceLandmarker = await FaceLandmarker.createFromOptions(filesetResolver, {\n    baseOptions: {\n        modelAssetPath: \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task\",\n        delegate: \"GPU\"\n    },\n    outputFaceBlendshapes: true,\n    runningMode: \"IMAGE\",\n    numFaces: 1\n});\n\n\nconst visionLine = 0.5;\nconst distance = visionLine-centroid[0];\n  const relativeDistance = Math.abs(distance)/centroid[0];\n  const threshold = 0.7;\n  const action = relativeDistance >= threshold ? \"NONE\" : distance > 0 ? \"l\" : \"r\";\n\ncaptureStream().pipe(\n  map(({message: img}) => faceLandmarker.detect(img).faceLandmarks[0]),\n  rewrite()\n)",
                      "language": "javascript",
                      "output": ""
                    },
                    "index": 1,
                    "lastEditedBy": "f313b510-8ff6-4ef7-8c27-070c2ae45fc1",
                    "_deleted": false
                  }
                }
              }
            ],
            "creator": "pkhexmkwbs",
            "time": 1684302455529.01
          }
        ],
        [
          {
            "body": [
              {
                "ifMatch": {
                  "$set": {
                    "data": {
                      "code": "import {\n    FaceLandmarker,\n    FilesetResolver,\n    DrawingUtils\n} from \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0\";\n\nconst filesetResolver = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm\"\n);\n\nfunction calculateCentroid(landmarks) {\n    const sum = landmarks.reduce((acc, landmark) => {\n        acc[0] = landmark.x + acc[0];\n        acc[1] = landmark.y + acc[1];\n        acc[2] = landmark.z + acc[2];\n        return acc;\n    }, [0, 0, 0]);\n    return sum.map(coord => coord / landmarks.length);\n}\n\nconst faceLandmarker = await FaceLandmarker.createFromOptions(filesetResolver, {\n    baseOptions: {\n        modelAssetPath: \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task\",\n        delegate: \"GPU\"\n    },\n    outputFaceBlendshapes: true,\n    runningMode: \"IMAGE\",\n    numFaces: 1\n});\n\n\nconst visionLine = 0.5;\nconst distance = visionLine-centroid[0];\nconst relativeDistance = Math.abs(distance)/centroid[0];\n  const threshold = 0.7;\n  const action = relativeDistance >= threshold ? \"NONE\" : distance > 0 ? \"l\" : \"r\";\n\ncaptureStream().pipe(\n  map(({message: img}) => faceLandmarker.detect(img).faceLandmarks[0]),\n  rewrite()\n)",
                      "language": "javascript",
                      "output": ""
                    },
                    "index": 1,
                    "lastEditedBy": "f313b510-8ff6-4ef7-8c27-070c2ae45fc1",
                    "_deleted": false
                  }
                }
              }
            ],
            "creator": "pkhexmkwbs",
            "time": 1684302456720.02
          }
        ],
        [
          {
            "body": [
              {
                "ifMatch": {
                  "$set": {
                    "data": {
                      "code": "import {\n    FaceLandmarker,\n    FilesetResolver,\n    DrawingUtils\n} from \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0\";\n\nconst filesetResolver = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm\"\n);\n\nfunction calculateCentroid(landmarks) {\n    const sum = landmarks.reduce((acc, landmark) => {\n        acc[0] = landmark.x + acc[0];\n        acc[1] = landmark.y + acc[1];\n        acc[2] = landmark.z + acc[2];\n        return acc;\n    }, [0, 0, 0]);\n    return sum.map(coord => coord / landmarks.length);\n}\n\nconst faceLandmarker = await FaceLandmarker.createFromOptions(filesetResolver, {\n    baseOptions: {\n        modelAssetPath: \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task\",\n        delegate: \"GPU\"\n    },\n    outputFaceBlendshapes: true,\n    runningMode: \"IMAGE\",\n    numFaces: 1\n});\n\n\nconst visionLine = 0.5;\nconst distance = visionLine-centroid[0];\nconst relativeDistance = Math.abs(distance)/centroid[0];\nconst threshold = 0.7;\n  const action = relativeDistance >= threshold ? \"NONE\" : distance > 0 ? \"l\" : \"r\";\n\ncaptureStream().pipe(\n  map(({message: img}) => faceLandmarker.detect(img).faceLandmarks[0]),\n  rewrite()\n)",
                      "language": "javascript",
                      "output": ""
                    },
                    "index": 1,
                    "lastEditedBy": "f313b510-8ff6-4ef7-8c27-070c2ae45fc1",
                    "_deleted": false
                  }
                }
              }
            ],
            "creator": "pkhexmkwbs",
            "time": 1684302458192.02
          }
        ],
        [
          {
            "body": [
              {
                "ifMatch": {
                  "$set": {
                    "data": {
                      "code": "import {\n    FaceLandmarker,\n    FilesetResolver,\n    DrawingUtils\n} from \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0\";\n\nconst filesetResolver = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm\"\n);\n\nfunction calculateCentroid(landmarks) {\n    const sum = landmarks.reduce((acc, landmark) => {\n        acc[0] = landmark.x + acc[0];\n        acc[1] = landmark.y + acc[1];\n        acc[2] = landmark.z + acc[2];\n        return acc;\n    }, [0, 0, 0]);\n    return sum.map(coord => coord / landmarks.length);\n}\n\nconst faceLandmarker = await FaceLandmarker.createFromOptions(filesetResolver, {\n    baseOptions: {\n        modelAssetPath: \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task\",\n        delegate: \"GPU\"\n    },\n    outputFaceBlendshapes: true,\n    runningMode: \"IMAGE\",\n    numFaces: 1\n});\n\n\nconst visionLine = 0.5;\nconst distance = visionLine-centroid[0];\nconst relativeDistance = Math.abs(distance)/centroid[0];\nconst threshold = 0.7;\nconst action = relativeDistance >= threshold ? \"NONE\" : distance > 0 ? \"l\" : \"r\";\n\ncaptureStream().pipe(\n  map(({message: img}) => faceLandmarker.detect(img).faceLandmarks[0]),\n  rewrite()\n)",
                      "language": "javascript",
                      "output": ""
                    },
                    "index": 1,
                    "lastEditedBy": "f313b510-8ff6-4ef7-8c27-070c2ae45fc1",
                    "_deleted": false
                  }
                }
              }
            ],
            "creator": "pkhexmkwbs",
            "time": 1684302459776.02
          }
        ],
        [
          {
            "body": [
              {
                "ifMatch": {
                  "$set": {
                    "data": {
                      "code": "import {\n    FaceLandmarker,\n    FilesetResolver,\n    DrawingUtils\n} from \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0\";\n\nconst filesetResolver = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm\"\n);\n\nfunction calculateCentroid(landmarks) {\n    const sum = landmarks.reduce((acc, landmark) => {\n        acc[0] = landmark.x + acc[0];\n        acc[1] = landmark.y + acc[1];\n        acc[2] = landmark.z + acc[2];\n        return acc;\n    }, [0, 0, 0]);\n    return sum.map(coord => coord / landmarks.length);\n}\n\nconst faceLandmarker = await FaceLandmarker.createFromOptions(filesetResolver, {\n    baseOptions: {\n        modelAssetPath: \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task\",\n        delegate: \"GPU\"\n    },\n    outputFaceBlendshapes: true,\n    runningMode: \"IMAGE\",\n    numFaces: 1\n});\n\n\nconst visionLine = 0.5;\nconst distance = visionLine-centroid[0];\nconst relativeDistance = Math.abs(distance)/centroid[0];\nconst threshold = 0.7;\nconst action = relativeDistance >= threshold ? \"NONE\" : distance > 0 ? \"l\" : \"r\";\n\ncaptureStream().pipe(\n  map(({message: img}) => {faceLandmarker.detect(img).faceLandmarks[0]),\n  rewrite()\n)",
                      "language": "javascript",
                      "output": ""
                    },
                    "index": 1,
                    "lastEditedBy": "f313b510-8ff6-4ef7-8c27-070c2ae45fc1",
                    "_deleted": false
                  }
                }
              }
            ],
            "creator": "pkhexmkwbs",
            "time": 1684302491232.02
          }
        ],
        [
          {
            "body": [
              {
                "ifMatch": {
                  "$set": {
                    "data": {
                      "code": "import {\n    FaceLandmarker,\n    FilesetResolver,\n    DrawingUtils\n} from \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0\";\n\nconst filesetResolver = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm\"\n);\n\nfunction calculateCentroid(landmarks) {\n    const sum = landmarks.reduce((acc, landmark) => {\n        acc[0] = landmark.x + acc[0];\n        acc[1] = landmark.y + acc[1];\n        acc[2] = landmark.z + acc[2];\n        return acc;\n    }, [0, 0, 0]);\n    return sum.map(coord => coord / landmarks.length);\n}\n\nconst faceLandmarker = await FaceLandmarker.createFromOptions(filesetResolver, {\n    baseOptions: {\n        modelAssetPath: \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task\",\n        delegate: \"GPU\"\n    },\n    outputFaceBlendshapes: true,\n    runningMode: \"IMAGE\",\n    numFaces: 1\n});\n\n\nconst visionLine = 0.5;\nconst distance = visionLine-centroid[0];\nconst relativeDistance = Math.abs(distance)/centroid[0];\nconst threshold = 0.7;\nconst action = relativeDistance >= threshold ? \"NONE\" : distance > 0 ? \"l\" : \"r\";\n\ncaptureStream().pipe(\n  map(({message: img}) => {\n    faceLandmarker.detect(img).faceLandmarks[0]),\n  rewrite()\n)",
                      "language": "javascript",
                      "output": ""
                    },
                    "index": 1,
                    "lastEditedBy": "f313b510-8ff6-4ef7-8c27-070c2ae45fc1",
                    "_deleted": false
                  }
                }
              }
            ],
            "creator": "pkhexmkwbs",
            "time": 1684302491768.06
          }
        ],
        [
          {
            "body": [
              {
                "ifMatch": {
                  "$set": {
                    "data": {
                      "code": "import {\n    FaceLandmarker,\n    FilesetResolver,\n    DrawingUtils\n} from \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0\";\n\nconst filesetResolver = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm\"\n);\n\nfunction calculateCentroid(landmarks) {\n    const sum = landmarks.reduce((acc, landmark) => {\n        acc[0] = landmark.x + acc[0];\n        acc[1] = landmark.y + acc[1];\n        acc[2] = landmark.z + acc[2];\n        return acc;\n    }, [0, 0, 0]);\n    return sum.map(coord => coord / landmarks.length);\n}\n\nconst faceLandmarker = await FaceLandmarker.createFromOptions(filesetResolver, {\n    baseOptions: {\n        modelAssetPath: \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task\",\n        delegate: \"GPU\"\n    },\n    outputFaceBlendshapes: true,\n    runningMode: \"IMAGE\",\n    numFaces: 1\n});\n\n\nconst visionLine = 0.5;\nconst distance = visionLine-centroid[0];\nconst relativeDistance = Math.abs(distance)/centroid[0];\nconst threshold = 0.7;\nconst action = relativeDistance >= threshold ? \"NONE\" : distance > 0 ? \"l\" : \"r\";\n\ncaptureStream().pipe(\n  map(({message: img}) => {\n    faceLandmarker.detect(img).faceLandmarks[0]\n  }),\n  rewrite()\n)",
                      "language": "javascript",
                      "output": ""
                    },
                    "index": 1,
                    "lastEditedBy": "f313b510-8ff6-4ef7-8c27-070c2ae45fc1",
                    "_deleted": false
                  }
                }
              }
            ],
            "creator": "pkhexmkwbs",
            "time": 1684302493248.02
          }
        ],
        [
          {
            "body": [
              {
                "ifMatch": {
                  "$set": {
                    "data": {
                      "code": "import {\n    FaceLandmarker,\n    FilesetResolver,\n    DrawingUtils\n} from \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0\";\n\nconst filesetResolver = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm\"\n);\n\nfunction calculateCentroid(landmarks) {\n    const sum = landmarks.reduce((acc, landmark) => {\n        acc[0] = landmark.x + acc[0];\n        acc[1] = landmark.y + acc[1];\n        acc[2] = landmark.z + acc[2];\n        return acc;\n    }, [0, 0, 0]);\n    return sum.map(coord => coord / landmarks.length);\n}\n\nconst faceLandmarker = await FaceLandmarker.createFromOptions(filesetResolver, {\n    baseOptions: {\n        modelAssetPath: \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task\",\n        delegate: \"GPU\"\n    },\n    outputFaceBlendshapes: true,\n    runningMode: \"IMAGE\",\n    numFaces: 1\n});\n\n\nconst visionLine = 0.5;\nconst distance = visionLine-centroid[0];\nconst relativeDistance = Math.abs(distance)/centroid[0];\nconst threshold = 0.7;\nconst action = relativeDistance >= threshold ? \"NONE\" : distance > 0 ? \"l\" : \"r\";\n\ncaptureStream().pipe(\n  map(({message: img}) => {\n    faceLandmarker.detect(img).faceLandmarks[0];\n  }),\n  rewrite()\n)",
                      "language": "javascript",
                      "output": ""
                    },
                    "index": 1,
                    "lastEditedBy": "f313b510-8ff6-4ef7-8c27-070c2ae45fc1",
                    "_deleted": false
                  }
                }
              }
            ],
            "creator": "pkhexmkwbs",
            "time": 1684302495040.02
          }
        ],
        [
          {
            "body": [
              {
                "ifMatch": {
                  "$set": {
                    "data": {
                      "code": "import {\n    FaceLandmarker,\n    FilesetResolver,\n    DrawingUtils\n} from \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0\";\n\nconst filesetResolver = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm\"\n);\n\nfunction calculateCentroid(landmarks) {\n    const sum = landmarks.reduce((acc, landmark) => {\n        acc[0] = landmark.x + acc[0];\n        acc[1] = landmark.y + acc[1];\n        acc[2] = landmark.z + acc[2];\n        return acc;\n    }, [0, 0, 0]);\n    return sum.map(coord => coord / landmarks.length);\n}\n\nconst faceLandmarker = await FaceLandmarker.createFromOptions(filesetResolver, {\n    baseOptions: {\n        modelAssetPath: \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task\",\n        delegate: \"GPU\"\n    },\n    outputFaceBlendshapes: true,\n    runningMode: \"IMAGE\",\n    numFaces: 1\n});\n\n\nconst visionLine = 0.5;\nconst distance = visionLine-centroid[0];\nconst relativeDistance = Math.abs(distance)/centroid[0];\nconst threshold = 0.7;\nconst action = relativeDistance >= threshold ? \"NONE\" : distance > 0 ? \"l\" : \"r\";\n\ncaptureStream().pipe(\n  map(({message: img}) => {\n    const lanfaceLandmarker.detect(img).faceLandmarks[0];\n  }),\n  rewrite()\n)",
                      "language": "javascript",
                      "output": ""
                    },
                    "index": 1,
                    "lastEditedBy": "f313b510-8ff6-4ef7-8c27-070c2ae45fc1",
                    "_deleted": false
                  }
                }
              }
            ],
            "creator": "pkhexmkwbs",
            "time": 1684302498648.06
          }
        ],
        [
          {
            "body": [
              {
                "ifMatch": {
                  "$set": {
                    "data": {
                      "code": "import {\n    FaceLandmarker,\n    FilesetResolver,\n    DrawingUtils\n} from \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0\";\n\nconst filesetResolver = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm\"\n);\n\nfunction calculateCentroid(landmarks) {\n    const sum = landmarks.reduce((acc, landmark) => {\n        acc[0] = landmark.x + acc[0];\n        acc[1] = landmark.y + acc[1];\n        acc[2] = landmark.z + acc[2];\n        return acc;\n    }, [0, 0, 0]);\n    return sum.map(coord => coord / landmarks.length);\n}\n\nconst faceLandmarker = await FaceLandmarker.createFromOptions(filesetResolver, {\n    baseOptions: {\n        modelAssetPath: \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task\",\n        delegate: \"GPU\"\n    },\n    outputFaceBlendshapes: true,\n    runningMode: \"IMAGE\",\n    numFaces: 1\n});\n\n\nconst visionLine = 0.5;\nconst distance = visionLine-centroid[0];\nconst relativeDistance = Math.abs(distance)/centroid[0];\nconst threshold = 0.7;\nconst action = relativeDistance >= threshold ? \"NONE\" : distance > 0 ? \"l\" : \"r\";\n\ncaptureStream().pipe(\n  map(({message: img}) => {\n    const landmarks = faceLandmarker.detect(img).faceLandmarks[0];\n  }),\n  rewrite()\n)",
                      "language": "javascript",
                      "output": ""
                    },
                    "index": 1,
                    "lastEditedBy": "f313b510-8ff6-4ef7-8c27-070c2ae45fc1",
                    "_deleted": false
                  }
                }
              }
            ],
            "creator": "pkhexmkwbs",
            "time": 1684302500600.06
          }
        ],
        [
          {
            "body": [
              {
                "ifMatch": {
                  "$set": {
                    "data": {
                      "code": "import {\n    FaceLandmarker,\n    FilesetResolver,\n    DrawingUtils\n} from \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0\";\n\nconst filesetResolver = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm\"\n);\n\nfunction calculateCentroid(landmarks) {\n    const sum = landmarks.reduce((acc, landmark) => {\n        acc[0] = landmark.x + acc[0];\n        acc[1] = landmark.y + acc[1];\n        acc[2] = landmark.z + acc[2];\n        return acc;\n    }, [0, 0, 0]);\n    return sum.map(coord => coord / landmarks.length);\n}\n\nconst faceLandmarker = await FaceLandmarker.createFromOptions(filesetResolver, {\n    baseOptions: {\n        modelAssetPath: \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task\",\n        delegate: \"GPU\"\n    },\n    outputFaceBlendshapes: true,\n    runningMode: \"IMAGE\",\n    numFaces: 1\n});\n\n\nconst visionLine = 0.5;\nconst distance = visionLine-centroid[0];\nconst relativeDistance = Math.abs(distance)/centroid[0];\nconst threshold = 0.7;\nconst action = relativeDistance >= threshold ? \"NONE\" : distance > 0 ? \"l\" : \"r\";\n\ncaptureStream().pipe(\n  map(({message: img}) => {\n    const landmarks = faceLandmarker.detect(img).faceLandmarks[0];\n    \n  }),\n  rewrite()\n)",
                      "language": "javascript",
                      "output": ""
                    },
                    "index": 1,
                    "lastEditedBy": "f313b510-8ff6-4ef7-8c27-070c2ae45fc1",
                    "_deleted": false
                  }
                }
              }
            ],
            "creator": "pkhexmkwbs",
            "time": 1684302502610.01
          }
        ],
        [
          {
            "body": [
              {
                "ifMatch": {
                  "$set": {
                    "data": {
                      "code": "import {\n    FaceLandmarker,\n    FilesetResolver,\n    DrawingUtils\n} from \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0\";\n\nconst filesetResolver = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm\"\n);\n\nfunction calculateCentroid(landmarks) {\n    const sum = landmarks.reduce((acc, landmark) => {\n        acc[0] = landmark.x + acc[0];\n        acc[1] = landmark.y + acc[1];\n        acc[2] = landmark.z + acc[2];\n        return acc;\n    }, [0, 0, 0]);\n    return sum.map(coord => coord / landmarks.length);\n}\n\nconst faceLandmarker = await FaceLandmarker.createFromOptions(filesetResolver, {\n    baseOptions: {\n        modelAssetPath: \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task\",\n        delegate: \"GPU\"\n    },\n    outputFaceBlendshapes: true,\n    runningMode: \"IMAGE\",\n    numFaces: 1\n});\n\n\nconst visionLine = 0.5;\nconst distance = visionLine-centroid[0];\nconst relativeDistance = Math.abs(distance)/centroid[0];\nconst threshold = 0.7;\nconst action = relativeDistance >= threshold ? \"NONE\" : distance > 0 ? \"l\" : \"r\";\n\ncaptureStream().pipe(\n  map(({message: img}) => {\n    const landmarks = calculateCentroid(faceLandmarker.detect(img).faceLandmarks[0]);\n    \n  }),\n  rewrite()\n)",
                      "language": "javascript",
                      "output": ""
                    },
                    "index": 1,
                    "lastEditedBy": "f313b510-8ff6-4ef7-8c27-070c2ae45fc1",
                    "_deleted": false
                  }
                }
              }
            ],
            "creator": "pkhexmkwbs",
            "time": 1684302511034.02
          }
        ],
        [
          {
            "body": [
              {
                "ifMatch": {
                  "$set": {
                    "data": {
                      "code": "import {\n    FaceLandmarker,\n    FilesetResolver,\n    DrawingUtils\n} from \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0\";\n\nconst filesetResolver = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm\"\n);\n\nfunction calculateCentroid(landmarks) {\n    const sum = landmarks.reduce((acc, landmark) => {\n        acc[0] = landmark.x + acc[0];\n        acc[1] = landmark.y + acc[1];\n        acc[2] = landmark.z + acc[2];\n        return acc;\n    }, [0, 0, 0]);\n    return sum.map(coord => coord / landmarks.length);\n}\n\nconst faceLandmarker = await FaceLandmarker.createFromOptions(filesetResolver, {\n    baseOptions: {\n        modelAssetPath: \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task\",\n        delegate: \"GPU\"\n    },\n    outputFaceBlendshapes: true,\n    runningMode: \"IMAGE\",\n    numFaces: 1\n});\n\n\nconst visionLine = 0.5;\nconst distance = visionLine-centroid[0];\nconst relativeDistance = Math.abs(distance)/centroid[0];\nconst threshold = 0.7;\nconst action = relativeDistance >= threshold ? \"NONE\" : distance > 0 ? \"l\" : \"r\";\n\ncaptureStream().pipe(\n  map(({message: img}) => {\n    const landmark = calculateCentroid(faceLandmarker.detect(img).faceLandmarks[0]);\n    \n  }),\n  rewrite()\n)",
                      "language": "javascript",
                      "output": ""
                    },
                    "index": 1,
                    "lastEditedBy": "f313b510-8ff6-4ef7-8c27-070c2ae45fc1",
                    "_deleted": false
                  }
                }
              }
            ],
            "creator": "pkhexmkwbs",
            "time": 1684302512080.06
          }
        ],
        [
          {
            "body": [
              {
                "ifMatch": {
                  "$set": {
                    "data": {
                      "code": "import {\n    FaceLandmarker,\n    FilesetResolver,\n    DrawingUtils\n} from \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0\";\n\nconst filesetResolver = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm\"\n);\n\nfunction calculateCentroid(landmarks) {\n    const sum = landmarks.reduce((acc, landmark) => {\n        acc[0] = landmark.x + acc[0];\n        acc[1] = landmark.y + acc[1];\n        acc[2] = landmark.z + acc[2];\n        return acc;\n    }, [0, 0, 0]);\n    return sum.map(coord => coord / landmarks.length);\n}\n\nconst faceLandmarker = await FaceLandmarker.createFromOptions(filesetResolver, {\n    baseOptions: {\n        modelAssetPath: \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task\",\n        delegate: \"GPU\"\n    },\n    outputFaceBlendshapes: true,\n    runningMode: \"IMAGE\",\n    numFaces: 1\n});\n\n\nconst visionLine = 0.5;\nconst distance = visionLine-centroid[0];\nconst relativeDistance = Math.abs(distance)/centroid[0];\nconst threshold = 0.7;\nconst action = relativeDistance >= threshold ? \"NONE\" : distance > 0 ? \"l\" : \"r\";\n\ncaptureStream().pipe(\n  map(({message: img}) => {\n    const centroid = calculateCentroid(faceLandmarker.detect(img).faceLandmarks[0]);\n    \n  }),\n  rewrite()\n)",
                      "language": "javascript",
                      "output": ""
                    },
                    "index": 1,
                    "lastEditedBy": "f313b510-8ff6-4ef7-8c27-070c2ae45fc1",
                    "_deleted": false
                  }
                }
              }
            ],
            "creator": "pkhexmkwbs",
            "time": 1684302514016.06
          }
        ],
        [
          {
            "body": [
              {
                "ifMatch": {
                  "$set": {
                    "data": {
                      "code": "import {\n    FaceLandmarker,\n    FilesetResolver,\n    DrawingUtils\n} from \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0\";\n\nconst filesetResolver = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm\"\n);\n\nfunction calculateCentroid(landmarks) {\n    const sum = landmarks.reduce((acc, landmark) => {\n        acc[0] = landmark.x + acc[0];\n        acc[1] = landmark.y + acc[1];\n        acc[2] = landmark.z + acc[2];\n        return acc;\n    }, [0, 0, 0]);\n    return sum.map(coord => coord / landmarks.length);\n}\n\nconst faceLandmarker = await FaceLandmarker.createFromOptions(filesetResolver, {\n    baseOptions: {\n        modelAssetPath: \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task\",\n        delegate: \"GPU\"\n    },\n    outputFaceBlendshapes: true,\n    runningMode: \"IMAGE\",\n    numFaces: 1\n});\n\n\nconst visionLine = 0.5;\nconst distance = visionLine-centroid[0];\nconst relativeDistance = Math.abs(distance)/centroid[0];\nconst threshold = 0.7;\nconst action = relativeDistance >= threshold ? \"NONE\" : distance > 0 ? \"l\" : \"r\";\n\ncaptureStream().pipe(\n  map(({message: img}) => {\n    const [x] = calculateCentroid(faceLandmarker.detect(img).faceLandmarks[0]);\n    \n  }),\n  rewrite()\n)",
                      "language": "javascript",
                      "output": ""
                    },
                    "index": 1,
                    "lastEditedBy": "f313b510-8ff6-4ef7-8c27-070c2ae45fc1",
                    "_deleted": false
                  }
                }
              }
            ],
            "creator": "pkhexmkwbs",
            "time": 1684302541457.01
          }
        ],
        [
          {
            "body": [
              {
                "ifMatch": {
                  "$set": {
                    "data": {
                      "code": "import {\n    FaceLandmarker,\n    FilesetResolver,\n    DrawingUtils\n} from \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0\";\n\nconst filesetResolver = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm\"\n);\n\nfunction calculateCentroid(landmarks) {\n    const sum = landmarks.reduce((acc, landmark) => {\n        acc[0] = landmark.x + acc[0];\n        acc[1] = landmark.y + acc[1];\n        acc[2] = landmark.z + acc[2];\n        return acc;\n    }, [0, 0, 0]);\n    return sum.map(coord => coord / landmarks.length);\n}\n\nconst faceLandmarker = await FaceLandmarker.createFromOptions(filesetResolver, {\n    baseOptions: {\n        modelAssetPath: \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task\",\n        delegate: \"GPU\"\n    },\n    outputFaceBlendshapes: true,\n    runningMode: \"IMAGE\",\n    numFaces: 1\n});\n\n\nconst visionLine = 0.5;\nconst distance = visionLine-centroid[0];\nconst relativeDistance = Math.abs(distance)/centroid[0];\nconst threshold = 0.7;\nconst action = relativeDistance >= threshold ? \"NONE\" : distance > 0 ? \"l\" : \"r\";\n\ncaptureStream().pipe(\n  map(({message: img}) => {\n    const [x,_,_] = calculateCentroid(faceLandmarker.detect(img).faceLandmarks[0]);\n    \n  }),\n  rewrite()\n)",
                      "language": "javascript",
                      "output": ""
                    },
                    "index": 1,
                    "lastEditedBy": "f313b510-8ff6-4ef7-8c27-070c2ae45fc1",
                    "_deleted": false
                  }
                }
              }
            ],
            "creator": "pkhexmkwbs",
            "time": 1684302543024.06
          }
        ],
        [
          {
            "body": [
              {
                "ifMatch": {
                  "$set": {
                    "data": {
                      "code": "import {\n    FaceLandmarker,\n    FilesetResolver,\n    DrawingUtils\n} from \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0\";\n\nconst filesetResolver = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm\"\n);\n\nfunction calculateCentroid(landmarks) {\n    const sum = landmarks.reduce((acc, landmark) => {\n        acc[0] = landmark.x + acc[0];\n        acc[1] = landmark.y + acc[1];\n        acc[2] = landmark.z + acc[2];\n        return acc;\n    }, [0, 0, 0]);\n    return sum.map(coord => coord / landmarks.length);\n}\n\nconst faceLandmarker = await FaceLandmarker.createFromOptions(filesetResolver, {\n    baseOptions: {\n        modelAssetPath: \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task\",\n        delegate: \"GPU\"\n    },\n    outputFaceBlendshapes: true,\n    runningMode: \"IMAGE\",\n    numFaces: 1\n});\n\n\nconst visionLine = 0.5;\nconst distance = visionLine-centroid[0];\nconst relativeDistance = Math.abs(distance)/centroid[0];\nconst threshold = 0.7;\nconst action = relativeDistance >= threshold ? \"NONE\" : distance > 0 ? \"l\" : \"r\";\n\ncaptureStream().pipe(\n  map(({message: img}) => {\n    const [x,_,_] = calculateCentroid(faceLandmarker.detect(img).faceLandmarks[0]);\n    \n    \n  }),\n  rewrite()\n)",
                      "language": "javascript",
                      "output": ""
                    },
                    "index": 1,
                    "lastEditedBy": "f313b510-8ff6-4ef7-8c27-070c2ae45fc1",
                    "_deleted": false
                  }
                }
              }
            ],
            "creator": "pkhexmkwbs",
            "time": 1684302544000.06
          }
        ],
        [
          {
            "body": [
              {
                "ifMatch": {
                  "$set": {
                    "data": {
                      "code": "import {\n    FaceLandmarker,\n    FilesetResolver,\n    DrawingUtils\n} from \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0\";\n\nconst filesetResolver = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm\"\n);\n\nfunction calculateCentroid(landmarks) {\n    const sum = landmarks.reduce((acc, landmark) => {\n        acc[0] = landmark.x + acc[0];\n        acc[1] = landmark.y + acc[1];\n        acc[2] = landmark.z + acc[2];\n        return acc;\n    }, [0, 0, 0]);\n    return sum.map(coord => coord / landmarks.length);\n}\n\nconst faceLandmarker = await FaceLandmarker.createFromOptions(filesetResolver, {\n    baseOptions: {\n        modelAssetPath: \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task\",\n        delegate: \"GPU\"\n    },\n    outputFaceBlendshapes: true,\n    runningMode: \"IMAGE\",\n    numFaces: 1\n});\n\n\nconst visionLine = 0.5;\nconst distance = visionLine-centroid[0];\nconst relativeDistance = Math.abs(distance)/centroid[0];\nconst threshold = 0.7;\nconst action = relativeDistance >= threshold ? \"NONE\" : distance > 0 ? \"l\" : \"r\";\n\ncaptureStream().pipe(\n  map(({message: img}) => {\n    const [x,_,] = calculateCentroid(faceLandmarker.detect(img).faceLandmarks[0]);\n    \n    \n  }),\n  rewrite()\n)",
                      "language": "javascript",
                      "output": ""
                    },
                    "index": 1,
                    "lastEditedBy": "f313b510-8ff6-4ef7-8c27-070c2ae45fc1",
                    "_deleted": false
                  }
                }
              }
            ],
            "creator": "pkhexmkwbs",
            "time": 1684302549264.02
          }
        ],
        [
          {
            "body": [
              {
                "ifMatch": {
                  "$set": {
                    "data": {
                      "code": "import {\n    FaceLandmarker,\n    FilesetResolver,\n    DrawingUtils\n} from \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0\";\n\nconst filesetResolver = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm\"\n);\n\nfunction calculateCentroid(landmarks) {\n    const sum = landmarks.reduce((acc, landmark) => {\n        acc[0] = landmark.x + acc[0];\n        acc[1] = landmark.y + acc[1];\n        acc[2] = landmark.z + acc[2];\n        return acc;\n    }, [0, 0, 0]);\n    return sum.map(coord => coord / landmarks.length);\n}\n\nconst faceLandmarker = await FaceLandmarker.createFromOptions(filesetResolver, {\n    baseOptions: {\n        modelAssetPath: \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task\",\n        delegate: \"GPU\"\n    },\n    outputFaceBlendshapes: true,\n    runningMode: \"IMAGE\",\n    numFaces: 1\n});\n\n\nconst visionLine = 0.5;\nconst distance = visionLine-centroid[0];\nconst relativeDistance = Math.abs(distance)/centroid[0];\nconst threshold = 0.7;\nconst action = relativeDistance >= threshold ? \"NONE\" : distance > 0 ? \"l\" : \"r\";\n\ncaptureStream().pipe(\n  map(({message: img}) => {\n    const [x,,] = calculateCentroid(faceLandmarker.detect(img).faceLandmarks[0]);\n    \n    \n  }),\n  rewrite()\n)",
                      "language": "javascript",
                      "output": ""
                    },
                    "index": 1,
                    "lastEditedBy": "f313b510-8ff6-4ef7-8c27-070c2ae45fc1",
                    "_deleted": false
                  }
                }
              }
            ],
            "creator": "pkhexmkwbs",
            "time": 1684302550800.02
          }
        ],
        [
          {
            "body": [
              {
                "ifMatch": {
                  "$set": {
                    "data": {
                      "code": "import {\n    FaceLandmarker,\n    FilesetResolver,\n    DrawingUtils\n} from \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0\";\n\nconst filesetResolver = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm\"\n);\n\nfunction calculateCentroid(landmarks) {\n    const sum = landmarks.reduce((acc, landmark) => {\n        acc[0] = landmark.x + acc[0];\n        acc[1] = landmark.y + acc[1];\n        acc[2] = landmark.z + acc[2];\n        return acc;\n    }, [0, 0, 0]);\n    return sum.map(coord => coord / landmarks.length);\n}\n\nconst faceLandmarker = await FaceLandmarker.createFromOptions(filesetResolver, {\n    baseOptions: {\n        modelAssetPath: \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task\",\n        delegate: \"GPU\"\n    },\n    outputFaceBlendshapes: true,\n    runningMode: \"IMAGE\",\n    numFaces: 1\n});\n\n\nconst visionLine = 0.5;\nconst distance = visionLine-centroid[0];\nconst relativeDistance = Math.abs(distance)/centroid[0];\nconst threshold = 0.7;\nconst action = relativeDistance >= threshold ? \"NONE\" : distance > 0 ? \"l\" : \"r\";\n\ncaptureStream().pipe(\n  map(({message: img}) => {\n    const [x,y,z] = calculateCentroid(faceLandmarker.detect(img).faceLandmarks[0]);\n    \n    \n  }),\n  rewrite()\n)",
                      "language": "javascript",
                      "output": ""
                    },
                    "index": 1,
                    "lastEditedBy": "f313b510-8ff6-4ef7-8c27-070c2ae45fc1",
                    "_deleted": false
                  }
                }
              }
            ],
            "creator": "pkhexmkwbs",
            "time": 1684302552432.06
          }
        ],
        [
          {
            "body": [
              {
                "ifMatch": {
                  "$set": {
                    "data": {
                      "code": "import {\n    FaceLandmarker,\n    FilesetResolver,\n    DrawingUtils\n} from \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0\";\n\nconst filesetResolver = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm\"\n);\n\nfunction calculateCentroid(landmarks) {\n    const sum = landmarks.reduce((acc, landmark) => {\n        acc[0] = landmark.x + acc[0];\n        acc[1] = landmark.y + acc[1];\n        acc[2] = landmark.z + acc[2];\n        return acc;\n    }, [0, 0, 0]);\n    return sum.map(coord => coord / landmarks.length);\n}\n\nconst faceLandmarker = await FaceLandmarker.createFromOptions(filesetResolver, {\n    baseOptions: {\n        modelAssetPath: \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task\",\n        delegate: \"GPU\"\n    },\n    outputFaceBlendshapes: true,\n    runningMode: \"IMAGE\",\n    numFaces: 1\n});\n\n\nconst visionLine = 0.5;\nconst threshold = 0.7;\nconst action = relativeDistance >= threshold ? \"NONE\" : distance > 0 ? \"l\" : \"r\";\n\ncaptureStream().pipe(\n  map(({message: img}) => {\n    const [x,y,z] = calculateCentroid(faceLandmarker.detect(img).faceLandmarks[0]);\n    \n    \n  }),\n  rewrite()\n)",
                      "language": "javascript",
                      "output": ""
                    },
                    "index": 1,
                    "lastEditedBy": "f313b510-8ff6-4ef7-8c27-070c2ae45fc1",
                    "_deleted": false
                  }
                }
              }
            ],
            "creator": "pkhexmkwbs",
            "time": 1684302563440.02
          }
        ],
        [
          {
            "body": [
              {
                "ifMatch": {
                  "$set": {
                    "data": {
                      "code": "import {\n    FaceLandmarker,\n    FilesetResolver,\n    DrawingUtils\n} from \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0\";\n\nconst filesetResolver = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm\"\n);\n\nfunction calculateCentroid(landmarks) {\n    const sum = landmarks.reduce((acc, landmark) => {\n        acc[0] = landmark.x + acc[0];\n        acc[1] = landmark.y + acc[1];\n        acc[2] = landmark.z + acc[2];\n        return acc;\n    }, [0, 0, 0]);\n    return sum.map(coord => coord / landmarks.length);\n}\n\nconst faceLandmarker = await FaceLandmarker.createFromOptions(filesetResolver, {\n    baseOptions: {\n        modelAssetPath: \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task\",\n        delegate: \"GPU\"\n    },\n    outputFaceBlendshapes: true,\n    runningMode: \"IMAGE\",\n    numFaces: 1\n});\n\n\nconst visionLine = 0.5;\nconst threshold = 0.7;\nconst action = relativeDistance >= threshold ? \"NONE\" : distance > 0 ? \"l\" : \"r\";\n\ncaptureStream().pipe(\n  map(({message: img}) => {\n    const [x,y,z] = calculateCentroid(faceLandmarker.detect(img).faceLandmarks[0]);\n    const distance = visionLine-centroid[0];\nconst relativeDistance = Math.abs(distance)/centroid[0];\n    \n  }),\n  rewrite()\n)",
                      "language": "javascript",
                      "output": ""
                    },
                    "index": 1,
                    "lastEditedBy": "f313b510-8ff6-4ef7-8c27-070c2ae45fc1",
                    "_deleted": false
                  }
                }
              }
            ],
            "creator": "pkhexmkwbs",
            "time": 1684302566032.06
          }
        ],
        [
          {
            "body": [
              {
                "ifMatch": {
                  "$set": {
                    "data": {
                      "code": "import {\n    FaceLandmarker,\n    FilesetResolver,\n    DrawingUtils\n} from \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0\";\n\nconst filesetResolver = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm\"\n);\n\nfunction calculateCentroid(landmarks) {\n    const sum = landmarks.reduce((acc, landmark) => {\n        acc[0] = landmark.x + acc[0];\n        acc[1] = landmark.y + acc[1];\n        acc[2] = landmark.z + acc[2];\n        return acc;\n    }, [0, 0, 0]);\n    return sum.map(coord => coord / landmarks.length);\n}\n\nconst faceLandmarker = await FaceLandmarker.createFromOptions(filesetResolver, {\n    baseOptions: {\n        modelAssetPath: \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task\",\n        delegate: \"GPU\"\n    },\n    outputFaceBlendshapes: true,\n    runningMode: \"IMAGE\",\n    numFaces: 1\n});\n\n\nconst visionLine = 0.5;\nconst threshold = 0.7;\nconst action = relativeDistance >= threshold ? \"NONE\" : distance > 0 ? \"l\" : \"r\";\n\ncaptureStream().pipe(\n  map(({message: img}) => {\n    const [x,y,z] = calculateCentroid(faceLandmarker.detect(img).faceLandmarks[0]);\n    const distance = visionLine-centroid[0];\n    const relativeDistance = Math.abs(distance)/centroid[0];\n    \n  }),\n  rewrite()\n)",
                      "language": "javascript",
                      "output": ""
                    },
                    "index": 1,
                    "lastEditedBy": "f313b510-8ff6-4ef7-8c27-070c2ae45fc1",
                    "_deleted": false
                  }
                }
              }
            ],
            "creator": "pkhexmkwbs",
            "time": 1684302568857.05
          }
        ],
        [
          {
            "body": [
              {
                "ifMatch": {
                  "$set": {
                    "data": {
                      "code": "import {\n    FaceLandmarker,\n    FilesetResolver,\n    DrawingUtils\n} from \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0\";\n\nconst filesetResolver = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm\"\n);\n\nfunction calculateCentroid(landmarks) {\n    const sum = landmarks.reduce((acc, landmark) => {\n        acc[0] = landmark.x + acc[0];\n        acc[1] = landmark.y + acc[1];\n        acc[2] = landmark.z + acc[2];\n        return acc;\n    }, [0, 0, 0]);\n    return sum.map(coord => coord / landmarks.length);\n}\n\nconst faceLandmarker = await FaceLandmarker.createFromOptions(filesetResolver, {\n    baseOptions: {\n        modelAssetPath: \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task\",\n        delegate: \"GPU\"\n    },\n    outputFaceBlendshapes: true,\n    runningMode: \"IMAGE\",\n    numFaces: 1\n});\n\n\nconst visionLine = 0.5;\nconst threshold = 0.7;\n\ncaptureStream().pipe(\n  map(({message: img}) => {\n    const [x,y,z] = calculateCentroid(faceLandmarker.detect(img).faceLandmarks[0]);\n    const distance = visionLine-centroid[0];\n    const relativeDistance = Math.abs(distance)/centroid[0];\n    const action = relativeDistance >= threshold ? \"NONE\" : distance > 0 ? \"l\" : \"r\";\n  }),\n  rewrite()\n)",
                      "language": "javascript",
                      "output": ""
                    },
                    "index": 1,
                    "lastEditedBy": "f313b510-8ff6-4ef7-8c27-070c2ae45fc1",
                    "_deleted": false
                  }
                }
              }
            ],
            "creator": "pkhexmkwbs",
            "time": 1684302572233.01
          }
        ],
        [
          {
            "body": [
              {
                "ifMatch": {
                  "$set": {
                    "data": {
                      "code": "import {\n    FaceLandmarker,\n    FilesetResolver,\n    DrawingUtils\n} from \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0\";\n\nconst filesetResolver = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm\"\n);\n\nfunction calculateCentroid(landmarks) {\n    const sum = landmarks.reduce((acc, landmark) => {\n        acc[0] = landmark.x + acc[0];\n        acc[1] = landmark.y + acc[1];\n        acc[2] = landmark.z + acc[2];\n        return acc;\n    }, [0, 0, 0]);\n    return sum.map(coord => coord / landmarks.length);\n}\n\nconst faceLandmarker = await FaceLandmarker.createFromOptions(filesetResolver, {\n    baseOptions: {\n        modelAssetPath: \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task\",\n        delegate: \"GPU\"\n    },\n    outputFaceBlendshapes: true,\n    runningMode: \"IMAGE\",\n    numFaces: 1\n});\n\n\nconst visionLine = 0.5;\nconst threshold = 0.7;\n\ncaptureStream().pipe(\n  map(({message: img}) => {\n    const [x,y,z] = calculateCentroid(faceLandmarker.detect(img).faceLandmarks[0]);\n    const distance = visionLine-centroid[0];\n    const relativeDistance = Math.abs(distance)/centroid[0];\n    return relativeDistance >= threshold ? \"NONE\" : distance > 0 ? \"l\" : \"r\";\n  }),\n  rewrite()\n)",
                      "language": "javascript",
                      "output": ""
                    },
                    "index": 1,
                    "lastEditedBy": "f313b510-8ff6-4ef7-8c27-070c2ae45fc1",
                    "_deleted": false
                  }
                }
              }
            ],
            "creator": "pkhexmkwbs",
            "time": 1684302575480.06
          }
        ],
        [
          {
            "body": [
              {
                "ifMatch": {
                  "$set": {
                    "data": {
                      "code": "import {\n    FaceLandmarker,\n    FilesetResolver,\n    DrawingUtils\n} from \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0\";\n\nconst filesetResolver = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm\"\n);\n\nfunction calculateCentroid(landmarks) {\n    const sum = landmarks.reduce((acc, landmark) => {\n        acc[0] = landmark.x + acc[0];\n        acc[1] = landmark.y + acc[1];\n        acc[2] = landmark.z + acc[2];\n        return acc;\n    }, [0, 0, 0]);\n    return sum.map(coord => coord / landmarks.length);\n}\n\nconst faceLandmarker = await FaceLandmarker.createFromOptions(filesetResolver, {\n    baseOptions: {\n        modelAssetPath: \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task\",\n        delegate: \"GPU\"\n    },\n    outputFaceBlendshapes: true,\n    runningMode: \"IMAGE\",\n    numFaces: 1\n});\n\n\nconst visionLine = 0.5;\nconst threshold = 0.7;\n\ncaptureStream().pipe(\n  \n  map(({message: img}) => {\n    const [x,y,z] = calculateCentroid(faceLandmarker.detect(img).faceLandmarks[0]);\n    const distance = visionLine-centroid[0];\n    const relativeDistance = Math.abs(distance)/centroid[0];\n    return relativeDistance >= threshold ? \"NONE\" : distance > 0 ? \"l\" : \"r\";\n  }),\n  rewrite()\n)",
                      "language": "javascript",
                      "output": ""
                    },
                    "index": 1,
                    "lastEditedBy": "f313b510-8ff6-4ef7-8c27-070c2ae45fc1",
                    "_deleted": false
                  }
                }
              }
            ],
            "creator": "pkhexmkwbs",
            "time": 1684302586936.02
          }
        ],
        [
          {
            "body": [
              {
                "ifMatch": {
                  "$set": {
                    "data": {
                      "code": "import {\n    FaceLandmarker,\n    FilesetResolver,\n    DrawingUtils\n} from \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0\";\n\nconst filesetResolver = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm\"\n);\n\nfunction calculateCentroid(landmarks) {\n    const sum = landmarks.reduce((acc, landmark) => {\n        acc[0] = landmark.x + acc[0];\n        acc[1] = landmark.y + acc[1];\n        acc[2] = landmark.z + acc[2];\n        return acc;\n    }, [0, 0, 0]);\n    return sum.map(coord => coord / landmarks.length);\n}\n\nconst faceLandmarker = await FaceLandmarker.createFromOptions(filesetResolver, {\n    baseOptions: {\n        modelAssetPath: \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task\",\n        delegate: \"GPU\"\n    },\n    outputFaceBlendshapes: true,\n    runningMode: \"IMAGE\",\n    numFaces: 1\n});\n\n\nconst visionLine = 0.5;\nconst threshold = 0.7;\n\ncaptureStream().pipe(\n  th\n  map(({message: img}) => {\n    const [x,y,z] = calculateCentroid(faceLandmarker.detect(img).faceLandmarks[0]);\n    const distance = visionLine-centroid[0];\n    const relativeDistance = Math.abs(distance)/centroid[0];\n    return relativeDistance >= threshold ? \"NONE\" : distance > 0 ? \"l\" : \"r\";\n  }),\n  rewrite()\n)",
                      "language": "javascript",
                      "output": ""
                    },
                    "index": 1,
                    "lastEditedBy": "f313b510-8ff6-4ef7-8c27-070c2ae45fc1",
                    "_deleted": false
                  }
                }
              }
            ],
            "creator": "pkhexmkwbs",
            "time": 1684302588048.06
          }
        ],
        [
          {
            "body": [
              {
                "ifMatch": {
                  "$set": {
                    "data": {
                      "code": "import {\n    FaceLandmarker,\n    FilesetResolver,\n    DrawingUtils\n} from \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0\";\n\nconst filesetResolver = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm\"\n);\n\nfunction calculateCentroid(landmarks) {\n    const sum = landmarks.reduce((acc, landmark) => {\n        acc[0] = landmark.x + acc[0];\n        acc[1] = landmark.y + acc[1];\n        acc[2] = landmark.z + acc[2];\n        return acc;\n    }, [0, 0, 0]);\n    return sum.map(coord => coord / landmarks.length);\n}\n\nconst faceLandmarker = await FaceLandmarker.createFromOptions(filesetResolver, {\n    baseOptions: {\n        modelAssetPath: \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task\",\n        delegate: \"GPU\"\n    },\n    outputFaceBlendshapes: true,\n    runningMode: \"IMAGE\",\n    numFaces: 1\n});\n\n\nconst visionLine = 0.5;\nconst threshold = 0.7;\n\ncaptureStream().pipe(\n  thottotleTime()\n  map(({message: img}) => {\n    const [x,y,z] = calculateCentroid(faceLandmarker.detect(img).faceLandmarks[0]);\n    const distance = visionLine-centroid[0];\n    const relativeDistance = Math.abs(distance)/centroid[0];\n    return relativeDistance >= threshold ? \"NONE\" : distance > 0 ? \"l\" : \"r\";\n  }),\n  rewrite()\n)",
                      "language": "javascript",
                      "output": ""
                    },
                    "index": 1,
                    "lastEditedBy": "f313b510-8ff6-4ef7-8c27-070c2ae45fc1",
                    "_deleted": false
                  }
                }
              }
            ],
            "creator": "pkhexmkwbs",
            "time": 1684302592625.01
          }
        ],
        [
          {
            "body": [
              {
                "ifMatch": {
                  "$set": {
                    "data": {
                      "code": "import {\n    FaceLandmarker,\n    FilesetResolver,\n    DrawingUtils\n} from \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0\";\n\nconst filesetResolver = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm\"\n);\n\nfunction calculateCentroid(landmarks) {\n    const sum = landmarks.reduce((acc, landmark) => {\n        acc[0] = landmark.x + acc[0];\n        acc[1] = landmark.y + acc[1];\n        acc[2] = landmark.z + acc[2];\n        return acc;\n    }, [0, 0, 0]);\n    return sum.map(coord => coord / landmarks.length);\n}\n\nconst faceLandmarker = await FaceLandmarker.createFromOptions(filesetResolver, {\n    baseOptions: {\n        modelAssetPath: \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task\",\n        delegate: \"GPU\"\n    },\n    outputFaceBlendshapes: true,\n    runningMode: \"IMAGE\",\n    numFaces: 1\n});\n\n\nconst visionLine = 0.5;\nconst threshold = 0.7;\n\ncaptureStream().pipe(\n  thottotleTime(100)\n  map(({message: img}) => {\n    const [x,y,z] = calculateCentroid(faceLandmarker.detect(img).faceLandmarks[0]);\n    const distance = visionLine-centroid[0];\n    const relativeDistance = Math.abs(distance)/centroid[0];\n    return relativeDistance >= threshold ? \"NONE\" : distance > 0 ? \"l\" : \"r\";\n  }),\n  rewrite()\n)",
                      "language": "javascript",
                      "output": ""
                    },
                    "index": 1,
                    "lastEditedBy": "f313b510-8ff6-4ef7-8c27-070c2ae45fc1",
                    "_deleted": false
                  }
                }
              }
            ],
            "creator": "pkhexmkwbs",
            "time": 1684302593560.06
          }
        ],
        [
          {
            "body": [
              {
                "ifMatch": {
                  "$set": {
                    "data": {
                      "code": "import {\n    FaceLandmarker,\n    FilesetResolver,\n    DrawingUtils\n} from \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0\";\n\nconst filesetResolver = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm\"\n);\n\nfunction calculateCentroid(landmarks) {\n    const sum = landmarks.reduce((acc, landmark) => {\n        acc[0] = landmark.x + acc[0];\n        acc[1] = landmark.y + acc[1];\n        acc[2] = landmark.z + acc[2];\n        return acc;\n    }, [0, 0, 0]);\n    return sum.map(coord => coord / landmarks.length);\n}\n\nconst faceLandmarker = await FaceLandmarker.createFromOptions(filesetResolver, {\n    baseOptions: {\n        modelAssetPath: \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task\",\n        delegate: \"GPU\"\n    },\n    outputFaceBlendshapes: true,\n    runningMode: \"IMAGE\",\n    numFaces: 1\n});\n\n\nconst visionLine = 0.5;\nconst threshold = 0.7;\n\ncaptureStream().pipe(\n  thottotleTime()\n  map(({message: img}) => {\n    const [x,y,z] = calculateCentroid(faceLandmarker.detect(img).faceLandmarks[0]);\n    const distance = visionLine-centroid[0];\n    const relativeDistance = Math.abs(distance)/centroid[0];\n    return relativeDistance >= threshold ? \"NONE\" : distance > 0 ? \"l\" : \"r\";\n  }),\n  rewrite()\n)",
                      "language": "javascript",
                      "output": ""
                    },
                    "index": 1,
                    "lastEditedBy": "f313b510-8ff6-4ef7-8c27-070c2ae45fc1",
                    "_deleted": false
                  }
                }
              }
            ],
            "creator": "pkhexmkwbs",
            "time": 1684302594504.06
          }
        ],
        [
          {
            "body": [
              {
                "ifMatch": {
                  "$set": {
                    "data": {
                      "code": "import {\n    FaceLandmarker,\n    FilesetResolver,\n    DrawingUtils\n} from \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0\";\n\nconst filesetResolver = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm\"\n);\n\nfunction calculateCentroid(landmarks) {\n    const sum = landmarks.reduce((acc, landmark) => {\n        acc[0] = landmark.x + acc[0];\n        acc[1] = landmark.y + acc[1];\n        acc[2] = landmark.z + acc[2];\n        return acc;\n    }, [0, 0, 0]);\n    return sum.map(coord => coord / landmarks.length);\n}\n\nconst faceLandmarker = await FaceLandmarker.createFromOptions(filesetResolver, {\n    baseOptions: {\n        modelAssetPath: \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task\",\n        delegate: \"GPU\"\n    },\n    outputFaceBlendshapes: true,\n    runningMode: \"IMAGE\",\n    numFaces: 1\n});\n\n\nconst visionLine = 0.5;\nconst threshold = 0.7;\n\ncaptureStream().pipe(\n  thottotleTime(1000)\n  map(({message: img}) => {\n    const [x,y,z] = calculateCentroid(faceLandmarker.detect(img).faceLandmarks[0]);\n    const distance = visionLine-centroid[0];\n    const relativeDistance = Math.abs(distance)/centroid[0];\n    return relativeDistance >= threshold ? \"NONE\" : distance > 0 ? \"l\" : \"r\";\n  }),\n  rewrite()\n)",
                      "language": "javascript",
                      "output": ""
                    },
                    "index": 1,
                    "lastEditedBy": "f313b510-8ff6-4ef7-8c27-070c2ae45fc1",
                    "_deleted": false
                  }
                }
              }
            ],
            "creator": "pkhexmkwbs",
            "time": 1684302599273.01
          }
        ],
        [
          {
            "body": [
              {
                "ifMatch": {
                  "$set": {
                    "data": {
                      "code": "import {\n    FaceLandmarker,\n    FilesetResolver,\n    DrawingUtils\n} from \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0\";\n\nconst filesetResolver = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm\"\n);\n\nfunction calculateCentroid(landmarks) {\n    const sum = landmarks.reduce((acc, landmark) => {\n        acc[0] = landmark.x + acc[0];\n        acc[1] = landmark.y + acc[1];\n        acc[2] = landmark.z + acc[2];\n        return acc;\n    }, [0, 0, 0]);\n    return sum.map(coord => coord / landmarks.length);\n}\n\nconst faceLandmarker = await FaceLandmarker.createFromOptions(filesetResolver, {\n    baseOptions: {\n        modelAssetPath: \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task\",\n        delegate: \"GPU\"\n    },\n    outputFaceBlendshapes: true,\n    runningMode: \"IMAGE\",\n    numFaces: 1\n});\n\n\nconst visionLine = 0.5;\nconst threshold = 0.7;\n\ncaptureStream().pipe(\n  thottotleTime(1000),\n  map(({message: img}) => {\n    const [x,y,z] = calculateCentroid(faceLandmarker.detect(img).faceLandmarks[0]);\n    const distance = visionLine-centroid[0];\n    const relativeDistance = Math.abs(distance)/centroid[0];\n    return relativeDistance >= threshold ? \"NONE\" : distance > 0 ? \"l\" : \"r\";\n  }),\n  rewrite()\n)",
                      "language": "javascript",
                      "output": ""
                    },
                    "index": 1,
                    "lastEditedBy": "f313b510-8ff6-4ef7-8c27-070c2ae45fc1",
                    "_deleted": false
                  }
                }
              }
            ],
            "creator": "pkhexmkwbs",
            "time": 1684302599905.01
          }
        ],
        [
          {
            "body": [
              {
                "ifMatch": {
                  "$set": {
                    "data": {
                      "code": "import {\n    FaceLandmarker,\n    FilesetResolver,\n    DrawingUtils\n} from \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0\";\n\nconst filesetResolver = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm\"\n);\n\nfunction calculateCentroid(landmarks) {\n    const sum = landmarks.reduce((acc, landmark) => {\n        acc[0] = landmark.x + acc[0];\n        acc[1] = landmark.y + acc[1];\n        acc[2] = landmark.z + acc[2];\n        return acc;\n    }, [0, 0, 0]);\n    return sum.map(coord => coord / landmarks.length);\n}\n\nconst faceLandmarker = await FaceLandmarker.createFromOptions(filesetResolver, {\n    baseOptions: {\n        modelAssetPath: \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task\",\n        delegate: \"GPU\"\n    },\n    outputFaceBlendshapes: true,\n    runningMode: \"IMAGE\",\n    numFaces: 1\n});\n\n\nconst visionLine = 0.5;\nconst threshold = 0.7;\n\ncaptureStream().pipe(\n  throttleTime(1000),\n  map(({message: img}) => {\n    const [x,y,z] = calculateCentroid(faceLandmarker.detect(img).faceLandmarks[0]);\n    const distance = visionLine-centroid[0];\n    const relativeDistance = Math.abs(distance)/centroid[0];\n    return relativeDistance >= threshold ? \"NONE\" : distance > 0 ? \"l\" : \"r\";\n  }),\n  rewrite()\n)",
                      "language": "javascript",
                      "output": ""
                    },
                    "index": 1,
                    "lastEditedBy": "f313b510-8ff6-4ef7-8c27-070c2ae45fc1",
                    "_deleted": false
                  }
                }
              }
            ],
            "creator": "pkhexmkwbs",
            "time": 1684302612576.02
          }
        ],
        [
          {
            "body": [
              {
                "ifMatch": {
                  "$set": {
                    "data": {
                      "code": "import {\n    FaceLandmarker,\n    FilesetResolver,\n    DrawingUtils\n} from \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0\";\n\nconst filesetResolver = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm\"\n);\n\nfunction calculateCentroid(landmarks) {\n    const sum = landmarks.reduce((acc, landmark) => {\n        acc[0] = landmark.x + acc[0];\n        acc[1] = landmark.y + acc[1];\n        acc[2] = landmark.z + acc[2];\n        return acc;\n    }, [0, 0, 0]);\n    return sum.map(coord => coord / landmarks.length);\n}\n\nconst faceLandmarker = await FaceLandmarker.createFromOptions(filesetResolver, {\n    baseOptions: {\n        modelAssetPath: \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task\",\n        delegate: \"GPU\"\n    },\n    outputFaceBlendshapes: true,\n    runningMode: \"IMAGE\",\n    numFaces: 1\n});\n\n\nconst visionLine = 0.5;\nconst threshold = 0.7;\n\ncaptureStream().pipe(\n  throttleTime(1000),\n  map(({message: img}) => {\n    const [x,y,z] = calculateCentroid(faceLandmarker.detect(img).faceLandmarks[0]);\n    const distance = visionLine-x;\n    const relativeDistance = Math.abs(distance)/centroid[0];\n    return relativeDistance >= threshold ? \"NONE\" : distance > 0 ? \"l\" : \"r\";\n  }),\n  rewrite()\n)",
                      "language": "javascript",
                      "output": ""
                    },
                    "index": 1,
                    "lastEditedBy": "f313b510-8ff6-4ef7-8c27-070c2ae45fc1",
                    "_deleted": false
                  }
                }
              }
            ],
            "creator": "pkhexmkwbs",
            "time": 1684302622713.01
          }
        ],
        [
          {
            "body": [
              {
                "ifMatch": {
                  "$set": {
                    "data": {
                      "code": "import {\n    FaceLandmarker,\n    FilesetResolver,\n    DrawingUtils\n} from \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0\";\n\nconst filesetResolver = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm\"\n);\n\nfunction calculateCentroid(landmarks) {\n    const sum = landmarks.reduce((acc, landmark) => {\n        acc[0] = landmark.x + acc[0];\n        acc[1] = landmark.y + acc[1];\n        acc[2] = landmark.z + acc[2];\n        return acc;\n    }, [0, 0, 0]);\n    return sum.map(coord => coord / landmarks.length);\n}\n\nconst faceLandmarker = await FaceLandmarker.createFromOptions(filesetResolver, {\n    baseOptions: {\n        modelAssetPath: \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task\",\n        delegate: \"GPU\"\n    },\n    outputFaceBlendshapes: true,\n    runningMode: \"IMAGE\",\n    numFaces: 1\n});\n\n\nconst visionLine = 0.5;\nconst threshold = 0.7;\n\ncaptureStream().pipe(\n  throttleTime(1000),\n  map(({message: img}) => {\n    const [x,y,z] = calculateCentroid(faceLandmarker.detect(img).faceLandmarks[0]);\n    const distance = visionLine-x;\n    const relativeDistance = Math.abs(distance)/centroid[0;\n    return relativeDistance >= threshold ? \"NONE\" : distance > 0 ? \"l\" : \"r\";\n  }),\n  rewrite()\n)",
                      "language": "javascript",
                      "output": ""
                    },
                    "index": 1,
                    "lastEditedBy": "f313b510-8ff6-4ef7-8c27-070c2ae45fc1",
                    "_deleted": false
                  }
                }
              }
            ],
            "creator": "pkhexmkwbs",
            "time": 1684302624608.02
          }
        ],
        [
          {
            "body": [
              {
                "ifMatch": {
                  "$set": {
                    "data": {
                      "code": "import {\n    FaceLandmarker,\n    FilesetResolver,\n    DrawingUtils\n} from \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0\";\n\nconst filesetResolver = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm\"\n);\n\nfunction calculateCentroid(landmarks) {\n    const sum = landmarks.reduce((acc, landmark) => {\n        acc[0] = landmark.x + acc[0];\n        acc[1] = landmark.y + acc[1];\n        acc[2] = landmark.z + acc[2];\n        return acc;\n    }, [0, 0, 0]);\n    return sum.map(coord => coord / landmarks.length);\n}\n\nconst faceLandmarker = await FaceLandmarker.createFromOptions(filesetResolver, {\n    baseOptions: {\n        modelAssetPath: \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task\",\n        delegate: \"GPU\"\n    },\n    outputFaceBlendshapes: true,\n    runningMode: \"IMAGE\",\n    numFaces: 1\n});\n\n\nconst visionLine = 0.5;\nconst threshold = 0.7;\n\ncaptureStream().pipe(\n  throttleTime(1000),\n  map(({message: img}) => {\n    const [x,y,z] = calculateCentroid(faceLandmarker.detect(img).faceLandmarks[0]);\n    const distance = visionLine-x;\n    const relativeDistance = Math.abs(distance)/x;\n    return relativeDistance >= threshold ? \"NONE\" : distance > 0 ? \"l\" : \"r\";\n  }),\n  rewrite()\n)",
                      "language": "javascript",
                      "output": ""
                    },
                    "index": 1,
                    "lastEditedBy": "f313b510-8ff6-4ef7-8c27-070c2ae45fc1",
                    "_deleted": false
                  }
                }
              }
            ],
            "creator": "pkhexmkwbs",
            "time": 1684302626225.01
          }
        ],
        [
          {
            "body": [
              {
                "ifMatch": {
                  "$set": {
                    "data": {
                      "code": "import {\n    FaceLandmarker,\n    FilesetResolver,\n    DrawingUtils\n} from \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0\";\n\nconst filesetResolver = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm\"\n);\n\nfunction calculateCentroid(landmarks) {\n    const sum = landmarks.reduce((acc, landmark) => {\n        acc[0] = landmark.x + acc[0];\n        acc[1] = landmark.y + acc[1];\n        acc[2] = landmark.z + acc[2];\n        return acc;\n    }, [0, 0, 0]);\n    return sum.map(coord => coord / landmarks.length);\n}\n\nconst faceLandmarker = await FaceLandmarker.createFromOptions(filesetResolver, {\n    baseOptions: {\n        modelAssetPath: \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task\",\n        delegate: \"GPU\"\n    },\n    outputFaceBlendshapes: true,\n    runningMode: \"IMAGE\",\n    numFaces: 1\n});\n\n\nconst visionLine = 0.5;\nconst threshold = 0.7;\n\ncaptureStream().pipe(\n  throttleTime(1000),\n  map(({message: img}) => {\n    const [x,y,z] = calculateCentroid(faceLandmarker.detect(img).faceLandmarks[0]);\n    const distance = visionLine-x;\n    const relativeDistance = Math.abs(distance)/x;\n    return relativeDistance >= threshold ? \"NONE\" : distance > 0 ? \"l\" : \"r\";\n  }),\n  rewrite()\n)",
                      "language": "javascript",
                      "output": "r"
                    },
                    "index": 1,
                    "lastEditedBy": "f313b510-8ff6-4ef7-8c27-070c2ae45fc1",
                    "_deleted": false
                  }
                }
              }
            ],
            "creator": "pkhexmkwbs",
            "time": 1684302725680.02
          }
        ],
        [
          {
            "body": [
              {
                "ifMatch": {
                  "$set": {
                    "data": {
                      "code": "import {\n    FaceLandmarker,\n    FilesetResolver,\n    DrawingUtils\n} from \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0\";\n\nconst filesetResolver = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm\"\n);\n\nfunction calculateCentroid(landmarks) {\n    const sum = landmarks.reduce((acc, landmark) => {\n        acc[0] = landmark.x + acc[0];\n        acc[1] = landmark.y + acc[1];\n        acc[2] = landmark.z + acc[2];\n        return acc;\n    }, [0, 0, 0]);\n    return sum.map(coord => coord / landmarks.length);\n}\n\nconst faceLandmarker = await FaceLandmarker.createFromOptions(filesetResolver, {\n    baseOptions: {\n        modelAssetPath: \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task\",\n        delegate: \"GPU\"\n    },\n    outputFaceBlendshapes: true,\n    runningMode: \"IMAGE\",\n    numFaces: 1\n});\n\n\nconst visionLine = 0.5;\nconst threshold = 0.7;\n\ncaptureStream().pipe(\n  throttleTime(1000),\n  map(({message: img}) => {\n    const [x,y,z] = calculateCentroid(faceLandmarker.detect(img).faceLandmarks[0]);\n    const distance = visionLine-x;\n    const relativeDistance = Math.abs(distance)/x;\n    return relativeDistance >= threshold ? \"NONE\" : distance > 0 ? \"l\" : \"r\";\n  }),\n  rewrite()\n)",
                      "language": "javascript",
                      "output": "l"
                    },
                    "index": 1,
                    "lastEditedBy": "f313b510-8ff6-4ef7-8c27-070c2ae45fc1",
                    "_deleted": false
                  }
                }
              }
            ],
            "creator": "pkhexmkwbs",
            "time": 1684302728840.02
          }
        ],
        [
          {
            "body": [
              {
                "ifMatch": {
                  "$set": {
                    "data": {
                      "code": "import {\n    FaceLandmarker,\n    FilesetResolver,\n    DrawingUtils\n} from \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0\";\n\nconst filesetResolver = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm\"\n);\n\nfunction calculateCentroid(landmarks) {\n    const sum = landmarks.reduce((acc, landmark) => {\n        acc[0] = landmark.x + acc[0];\n        acc[1] = landmark.y + acc[1];\n        acc[2] = landmark.z + acc[2];\n        return acc;\n    }, [0, 0, 0]);\n    return sum.map(coord => coord / landmarks.length);\n}\n\nconst faceLandmarker = await FaceLandmarker.createFromOptions(filesetResolver, {\n    baseOptions: {\n        modelAssetPath: \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task\",\n        delegate: \"GPU\"\n    },\n    outputFaceBlendshapes: true,\n    runningMode: \"IMAGE\",\n    numFaces: 1\n});\n\n\nconst visionLine = 0.5;\nconst threshold = 0.7;\n\ncaptureStream().pipe(\n  throttleTime(1000),\n  map(({message: img}) => {\n    const [x,y,z] = calculateCentroid(faceLandmarker.detect(img).faceLandmarks[0]);\n    const distance = visionLine-x;\n    const relativeDistance = Math.abs(distance)/x;\n    return relativeDistance >= threshold ? \"NONE\" : distance > 0 ? \"l\" : \"r\";\n  }),\n  rewrite()\n)",
                      "language": "javascript",
                      "output": "r"
                    },
                    "index": 1,
                    "lastEditedBy": "f313b510-8ff6-4ef7-8c27-070c2ae45fc1",
                    "_deleted": false
                  }
                }
              }
            ],
            "creator": "pkhexmkwbs",
            "time": 1684302743602.01
          }
        ],
        [
          {
            "body": [
              {
                "ifMatch": {
                  "$set": {
                    "data": {
                      "code": "import {\n    FaceLandmarker,\n    FilesetResolver,\n    DrawingUtils\n} from \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0\";\n\nconst filesetResolver = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm\"\n);\n\nfunction calculateCentroid(landmarks) {\n    const sum = landmarks.reduce((acc, landmark) => {\n        acc[0] = landmark.x + acc[0];\n        acc[1] = landmark.y + acc[1];\n        acc[2] = landmark.z + acc[2];\n        return acc;\n    }, [0, 0, 0]);\n    return sum.map(coord => coord / landmarks.length);\n}\n\nconst faceLandmarker = await FaceLandmarker.createFromOptions(filesetResolver, {\n    baseOptions: {\n        modelAssetPath: \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task\",\n        delegate: \"GPU\"\n    },\n    outputFaceBlendshapes: true,\n    runningMode: \"IMAGE\",\n    numFaces: 1\n});\n\n\nconst visionLine = 0.5;\nconst threshold = 0.7;\n\ncaptureStream().pipe(\n  throttleTime(1000),\n  map(({message: img}) => {\n    const [x,y,z] = calculateCentroid(faceLandmarker.detect(img).faceLandmarks[0]);\n    const distance = visionLine-x;\n    const relativeDistance = Math.abs(distance)/x;\n    return relativeDistance >= threshold ? \"NONE\" : distance > 0 ? \"l\" : \"r\";\n  }),\n  rewrite()\n)",
                      "language": "javascript",
                      "output": "l"
                    },
                    "index": 1,
                    "lastEditedBy": "f313b510-8ff6-4ef7-8c27-070c2ae45fc1",
                    "_deleted": false
                  }
                }
              }
            ],
            "creator": "pkhexmkwbs",
            "time": 1684302755240.02
          }
        ],
        [
          {
            "body": [
              {
                "ifMatch": {
                  "$set": {
                    "data": {
                      "code": "import {\n    FaceLandmarker,\n    FilesetResolver,\n    DrawingUtils\n} from \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0\";\n\nconst filesetResolver = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm\"\n);\n\nfunction calculateCentroid(landmarks) {\n    const sum = landmarks.reduce((acc, landmark) => {\n        acc[0] = landmark.x + acc[0];\n        acc[1] = landmark.y + acc[1];\n        acc[2] = landmark.z + acc[2];\n        return acc;\n    }, [0, 0, 0]);\n    return sum.map(coord => coord / landmarks.length);\n}\n\nconst faceLandmarker = await FaceLandmarker.createFromOptions(filesetResolver, {\n    baseOptions: {\n        modelAssetPath: \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task\",\n        delegate: \"GPU\"\n    },\n    outputFaceBlendshapes: true,\n    runningMode: \"IMAGE\",\n    numFaces: 1\n});\n\n\nconst visionLine = 0.5;\nconst threshold = 0.7;\n\ncaptureStream().pipe(\n  throttleTime(1000),\n  map(({message: img}) => {\n    const [x,y,z] = calculateCentroid(faceLandmarker.detect(img).faceLandmarks[0]);\n    const distance = visionLine-x;\n    const relativeDistance = Math.abs(distance)/x;\n    return relativeDistance >= threshold ? \"NONE\" : distance > 0 ? \"l\" : \"r\";\n  }),\n  rewrite()\n)",
                      "language": "javascript",
                      "output": "r"
                    },
                    "index": 1,
                    "lastEditedBy": "f313b510-8ff6-4ef7-8c27-070c2ae45fc1",
                    "_deleted": false
                  }
                }
              }
            ],
            "creator": "pkhexmkwbs",
            "time": 1684302764841.02
          }
        ],
        [
          {
            "body": [
              {
                "ifMatch": {
                  "$set": {
                    "data": {
                      "code": "import {\n    FaceLandmarker,\n    FilesetResolver,\n    DrawingUtils\n} from \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0\";\n\nconst filesetResolver = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm\"\n);\n\nfunction calculateCentroid(landmarks) {\n    const sum = landmarks.reduce((acc, landmark) => {\n        acc[0] = landmark.x + acc[0];\n        acc[1] = landmark.y + acc[1];\n        acc[2] = landmark.z + acc[2];\n        return acc;\n    }, [0, 0, 0]);\n    return sum.map(coord => coord / landmarks.length);\n}\n\nconst faceLandmarker = await FaceLandmarker.createFromOptions(filesetResolver, {\n    baseOptions: {\n        modelAssetPath: \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task\",\n        delegate: \"GPU\"\n    },\n    outputFaceBlendshapes: true,\n    runningMode: \"IMAGE\",\n    numFaces: 1\n});\n\n\nconst visionLine = 0.5;\nconst threshold = 0.7;\n\ncaptureStream().pipe(\n  throttleTime(1000),\n  map(({message: img}) => {\n    const [x,y,z] = calculateCentroid(faceLandmarker.detect(img).faceLandmarks[0]);\n    const distance = visionLine-x;\n    const relativeDistance = Math.abs(distance)/x;\n    return relativeDistance >= threshold ? \"NONE\" : distance > 0 ? \"l\" : \"r\";\n  }),\n  rewrite()\n)",
                      "language": "javascript",
                      "output": "l"
                    },
                    "index": 1,
                    "lastEditedBy": "f313b510-8ff6-4ef7-8c27-070c2ae45fc1",
                    "_deleted": false
                  }
                }
              }
            ],
            "creator": "pkhexmkwbs",
            "time": 1684302765904.06
          }
        ],
        [
          {
            "body": [
              {
                "ifMatch": {
                  "$set": {
                    "data": {
                      "code": "import {\n    FaceLandmarker,\n    FilesetResolver,\n    DrawingUtils\n} from \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0\";\n\nconst filesetResolver = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm\"\n);\n\nfunction calculateCentroid(landmarks) {\n    const sum = landmarks.reduce((acc, landmark) => {\n        acc[0] = landmark.x + acc[0];\n        acc[1] = landmark.y + acc[1];\n        acc[2] = landmark.z + acc[2];\n        return acc;\n    }, [0, 0, 0]);\n    return sum.map(coord => coord / landmarks.length);\n}\n\nconst faceLandmarker = await FaceLandmarker.createFromOptions(filesetResolver, {\n    baseOptions: {\n        modelAssetPath: \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task\",\n        delegate: \"GPU\"\n    },\n    outputFaceBlendshapes: true,\n    runningMode: \"IMAGE\",\n    numFaces: 1\n});\n\n\nconst visionLine = 0.5;\nconst threshold = 0.7;\n\ncaptureStream().pipe(\n  throttleTime(1000),\n  map(({message: img}) => {\n    const [x,y,z] = calculateCentroid(faceLandmarker.detect(img).faceLandmarks[0]);\n    const distance = visionLine-x;\n    const relativeDistance = Math.abs(distance)/x;\n    return relativeDistance >= threshold ? \"NONE\" : distance > 0 ? \"l\" : \"r\";\n  }),\n  rewrite()\n)",
                      "language": "javascript",
                      "output": "r"
                    },
                    "index": 1,
                    "lastEditedBy": "f313b510-8ff6-4ef7-8c27-070c2ae45fc1",
                    "_deleted": false
                  }
                }
              }
            ],
            "creator": "pkhexmkwbs",
            "time": 1684302770144.02
          }
        ],
        [
          {
            "body": [
              {
                "ifMatch": {
                  "$set": {
                    "data": {
                      "code": "import {\n    FaceLandmarker,\n    FilesetResolver,\n    DrawingUtils\n} from \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0\";\n\nconst filesetResolver = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm\"\n);\n\nfunction calculateCentroid(landmarks) {\n    const sum = landmarks.reduce((acc, landmark) => {\n        acc[0] = landmark.x + acc[0];\n        acc[1] = landmark.y + acc[1];\n        acc[2] = landmark.z + acc[2];\n        return acc;\n    }, [0, 0, 0]);\n    return sum.map(coord => coord / landmarks.length);\n}\n\nconst faceLandmarker = await FaceLandmarker.createFromOptions(filesetResolver, {\n    baseOptions: {\n        modelAssetPath: \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task\",\n        delegate: \"GPU\"\n    },\n    outputFaceBlendshapes: true,\n    runningMode: \"IMAGE\",\n    numFaces: 1\n});\n\n\nconst visionLine = 0.5;\nconst threshold = 0.5;\n\ncaptureStream().pipe(\n  throttleTime(1000),\n  map(({message: img}) => {\n    const [x,y,z] = calculateCentroid(faceLandmarker.detect(img).faceLandmarks[0]);\n    const distance = visionLine-x;\n    const relativeDistance = Math.abs(distance)/x;\n    return relativeDistance >= threshold ? \"NONE\" : distance > 0 ? \"l\" : \"r\";\n  }),\n  rewrite()\n)",
                      "language": "javascript",
                      "output": "r"
                    },
                    "index": 1,
                    "lastEditedBy": "f313b510-8ff6-4ef7-8c27-070c2ae45fc1",
                    "_deleted": false
                  }
                }
              }
            ],
            "creator": "pkhexmkwbs",
            "time": 1684302792489.01
          }
        ],
        [
          {
            "body": [
              {
                "ifMatch": {
                  "$set": {
                    "data": {
                      "code": "import {\n    FaceLandmarker,\n    FilesetResolver,\n    DrawingUtils\n} from \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0\";\n\nconst filesetResolver = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm\"\n);\n\nfunction calculateCentroid(landmarks) {\n    const sum = landmarks.reduce((acc, landmark) => {\n        acc[0] = landmark.x + acc[0];\n        acc[1] = landmark.y + acc[1];\n        acc[2] = landmark.z + acc[2];\n        return acc;\n    }, [0, 0, 0]);\n    return sum.map(coord => coord / landmarks.length);\n}\n\nconst faceLandmarker = await FaceLandmarker.createFromOptions(filesetResolver, {\n    baseOptions: {\n        modelAssetPath: \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task\",\n        delegate: \"GPU\"\n    },\n    outputFaceBlendshapes: true,\n    runningMode: \"IMAGE\",\n    numFaces: 1\n});\n\n\nconst visionLine = 0.5;\nconst threshold = 0.6;\n\ncaptureStream().pipe(\n  throttleTime(1000),\n  map(({message: img}) => {\n    const [x,y,z] = calculateCentroid(faceLandmarker.detect(img).faceLandmarks[0]);\n    const distance = visionLine-x;\n    const relativeDistance = Math.abs(distance)/x;\n    return relativeDistance >= threshold ? \"NONE\" : distance > 0 ? \"l\" : \"r\";\n  }),\n  rewrite()\n)",
                      "language": "javascript",
                      "output": "r"
                    },
                    "index": 1,
                    "lastEditedBy": "f313b510-8ff6-4ef7-8c27-070c2ae45fc1",
                    "_deleted": false
                  }
                }
              }
            ],
            "creator": "pkhexmkwbs",
            "time": 1684302793761.01
          }
        ],
        [
          {
            "body": [
              {
                "ifMatch": {
                  "$set": {
                    "data": {
                      "code": "import {\n    FaceLandmarker,\n    FilesetResolver,\n    DrawingUtils\n} from \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0\";\n\nconst filesetResolver = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm\"\n);\n\nfunction calculateCentroid(landmarks) {\n    const sum = landmarks.reduce((acc, landmark) => {\n        acc[0] = landmark.x + acc[0];\n        acc[1] = landmark.y + acc[1];\n        acc[2] = landmark.z + acc[2];\n        return acc;\n    }, [0, 0, 0]);\n    return sum.map(coord => coord / landmarks.length);\n}\n\nconst faceLandmarker = await FaceLandmarker.createFromOptions(filesetResolver, {\n    baseOptions: {\n        modelAssetPath: \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task\",\n        delegate: \"GPU\"\n    },\n    outputFaceBlendshapes: true,\n    runningMode: \"IMAGE\",\n    numFaces: 1\n});\n\n\nconst visionLine = 0.5;\nconst threshold = 0.6;\n\ncaptureStream().pipe(\n  throttleTime(1000),\n  map(({message: img}) => {\n    const [x,y,z] = calculateCentroid(faceLandmarker.detect(img).faceLandmarks[0]);\n    const distance = visionLine-x;\n    const relativeDistance = Math.abs(distance)/x;\n    return relativeDistance >= threshold ? \"NONE\" : distance > 0 ? \"l\" : \"r\";\n  }),\n  rewrite()\n)",
                      "language": "javascript",
                      "output": ""
                    },
                    "index": 1,
                    "lastEditedBy": "f313b510-8ff6-4ef7-8c27-070c2ae45fc1",
                    "_deleted": false
                  }
                }
              }
            ],
            "creator": "pkhexmkwbs",
            "time": 1684302800723.01
          }
        ],
        [
          {
            "body": [
              {
                "ifMatch": {
                  "$set": {
                    "data": {
                      "code": "import {\n    FaceLandmarker,\n    FilesetResolver,\n    DrawingUtils\n} from \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0\";\n\nconst filesetResolver = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm\"\n);\n\nfunction calculateCentroid(landmarks) {\n    const sum = landmarks.reduce((acc, landmark) => {\n        acc[0] = landmark.x + acc[0];\n        acc[1] = landmark.y + acc[1];\n        acc[2] = landmark.z + acc[2];\n        return acc;\n    }, [0, 0, 0]);\n    return sum.map(coord => coord / landmarks.length);\n}\n\nconst faceLandmarker = await FaceLandmarker.createFromOptions(filesetResolver, {\n    baseOptions: {\n        modelAssetPath: \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task\",\n        delegate: \"GPU\"\n    },\n    outputFaceBlendshapes: true,\n    runningMode: \"IMAGE\",\n    numFaces: 1\n});\n\n\nconst visionLine = 0.5;\nconst threshold = 0.6;\n\ncaptureStream().pipe(\n  throttleTime(1000),\n  map(({message: img}) => {\n    const [x,y,z] = calculateCentroid(faceLandmarker.detect(img).faceLandmarks[0]);\n    const distance = visionLine-x;\n    const relativeDistance = Math.abs(distance)/x;\n    return relativeDistance >= threshold ? \"NONE\" : distance > 0 ? \"l\" : \"r\";\n  }),\n  rewrite()\n)",
                      "language": "javascript",
                      "output": "r"
                    },
                    "index": 1,
                    "lastEditedBy": "f313b510-8ff6-4ef7-8c27-070c2ae45fc1",
                    "_deleted": false
                  }
                }
              }
            ],
            "creator": "pkhexmkwbs",
            "time": 1684302802123.06
          }
        ],
        [
          {
            "body": [
              {
                "ifMatch": {
                  "$set": {
                    "data": {
                      "code": "import {\n    FaceLandmarker,\n    FilesetResolver,\n    DrawingUtils\n} from \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0\";\n\nconst filesetResolver = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm\"\n);\n\nfunction calculateCentroid(landmarks) {\n    const sum = landmarks.reduce((acc, landmark) => {\n        acc[0] = landmark.x + acc[0];\n        acc[1] = landmark.y + acc[1];\n        acc[2] = landmark.z + acc[2];\n        return acc;\n    }, [0, 0, 0]);\n    return sum.map(coord => coord / landmarks.length);\n}\n\nconst faceLandmarker = await FaceLandmarker.createFromOptions(filesetResolver, {\n    baseOptions: {\n        modelAssetPath: \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task\",\n        delegate: \"GPU\"\n    },\n    outputFaceBlendshapes: true,\n    runningMode: \"IMAGE\",\n    numFaces: 1\n});\n\n\nconst visionLine = 0.5;\nconst threshold = 0.6;\n\ncaptureStream().pipe(\n  throttleTime(1000),\n  map(({message: img}) => {\n    const [x,y,z] = calculateCentroid(faceLandmarker.detect(img).faceLandmarks[0]);\n    const distance = visionLine-x;\n    const relativeDistance = Math.abs(distance)/x;\n    console.log(relativeDistance)\n    return relativeDistance >= threshold ? \"NONE\" : distance > 0 ? \"l\" : \"r\";\n  }),\n  rewrite()\n)",
                      "language": "javascript",
                      "output": "r"
                    },
                    "index": 1,
                    "lastEditedBy": "f313b510-8ff6-4ef7-8c27-070c2ae45fc1",
                    "_deleted": false
                  }
                }
              }
            ],
            "creator": "pkhexmkwbs",
            "time": 1684302818208.02
          }
        ],
        [
          {
            "body": [
              {
                "ifMatch": {
                  "$set": {
                    "data": {
                      "code": "import {\n    FaceLandmarker,\n    FilesetResolver,\n    DrawingUtils\n} from \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0\";\n\nconst filesetResolver = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm\"\n);\n\nfunction calculateCentroid(landmarks) {\n    const sum = landmarks.reduce((acc, landmark) => {\n        acc[0] = landmark.x + acc[0];\n        acc[1] = landmark.y + acc[1];\n        acc[2] = landmark.z + acc[2];\n        return acc;\n    }, [0, 0, 0]);\n    return sum.map(coord => coord / landmarks.length);\n}\n\nconst faceLandmarker = await FaceLandmarker.createFromOptions(filesetResolver, {\n    baseOptions: {\n        modelAssetPath: \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task\",\n        delegate: \"GPU\"\n    },\n    outputFaceBlendshapes: true,\n    runningMode: \"IMAGE\",\n    numFaces: 1\n});\n\n\nconst visionLine = 0.5;\nconst threshold = 0.6;\n\ncaptureStream().pipe(\n  throttleTime(1000),\n  map(({message: img}) => {\n    const [x,y,z] = calculateCentroid(faceLandmarker.detect(img).faceLandmarks[0]);\n    const distance = visionLine-x;\n    const relativeDistance = Math.abs(distance)/x;\n    console.log(relativeDistance);\n    return relativeDistance >= threshold ? \"NONE\" : distance > 0 ? \"l\" : \"r\";\n  }),\n  rewrite()\n)",
                      "language": "javascript",
                      "output": "r"
                    },
                    "index": 1,
                    "lastEditedBy": "f313b510-8ff6-4ef7-8c27-070c2ae45fc1",
                    "_deleted": false
                  }
                }
              }
            ],
            "creator": "pkhexmkwbs",
            "time": 1684302818893.06
          }
        ],
        [
          {
            "body": [
              {
                "ifMatch": {
                  "$set": {
                    "data": {
                      "code": "import {\n    FaceLandmarker,\n    FilesetResolver,\n    DrawingUtils\n} from \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0\";\n\nconst filesetResolver = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm\"\n);\n\nfunction calculateCentroid(landmarks) {\n    const sum = landmarks.reduce((acc, landmark) => {\n        acc[0] = landmark.x + acc[0];\n        acc[1] = landmark.y + acc[1];\n        acc[2] = landmark.z + acc[2];\n        return acc;\n    }, [0, 0, 0]);\n    return sum.map(coord => coord / landmarks.length);\n}\n\nconst faceLandmarker = await FaceLandmarker.createFromOptions(filesetResolver, {\n    baseOptions: {\n        modelAssetPath: \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task\",\n        delegate: \"GPU\"\n    },\n    outputFaceBlendshapes: true,\n    runningMode: \"IMAGE\",\n    numFaces: 1\n});\n\n\nconst visionLine = 0.5;\nconst threshold = 0.6;\n\ncaptureStream().pipe(\n  throttleTime(1000),\n  map(({message: img}) => {\n    const [x,y,z] = calculateCentroid(faceLandmarker.detect(img).faceLandmarks[0]);\n    const distance = visionLine-x;\n    const relativeDistance = Math.abs(distance)/x;\n    console.log(relativeDistance);\n    return relativeDistance >= threshold ? \"NONE\" : distance > 0 ? \"l\" : \"r\";\n  }),\n  rewrite()\n)",
                      "language": "javascript",
                      "output": ""
                    },
                    "index": 1,
                    "lastEditedBy": "f313b510-8ff6-4ef7-8c27-070c2ae45fc1",
                    "_deleted": false
                  }
                }
              }
            ],
            "creator": "pkhexmkwbs",
            "time": 1684302824694.01
          }
        ],
        [
          {
            "body": [
              {
                "ifMatch": {
                  "$set": {
                    "data": {
                      "code": "import {\n    FaceLandmarker,\n    FilesetResolver,\n    DrawingUtils\n} from \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0\";\n\nconst filesetResolver = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm\"\n);\n\nfunction calculateCentroid(landmarks) {\n    const sum = landmarks.reduce((acc, landmark) => {\n        acc[0] = landmark.x + acc[0];\n        acc[1] = landmark.y + acc[1];\n        acc[2] = landmark.z + acc[2];\n        return acc;\n    }, [0, 0, 0]);\n    return sum.map(coord => coord / landmarks.length);\n}\n\nconst faceLandmarker = await FaceLandmarker.createFromOptions(filesetResolver, {\n    baseOptions: {\n        modelAssetPath: \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task\",\n        delegate: \"GPU\"\n    },\n    outputFaceBlendshapes: true,\n    runningMode: \"IMAGE\",\n    numFaces: 1\n});\n\n\nconst visionLine = 0.5;\nconst threshold = 0.6;\n\ncaptureStream().pipe(\n  throttleTime(1000),\n  map(({message: img}) => {\n    const [x,y,z] = calculateCentroid(faceLandmarker.detect(img).faceLandmarks[0]);\n    const distance = visionLine-x;\n    const relativeDistance = Math.abs(distance)/x;\n    console.log(relativeDistance);\n    return relativeDistance >= threshold ? \"NONE\" : distance > 0 ? \"l\" : \"r\";\n  }),\n  rewrite()\n)",
                      "language": "javascript",
                      "output": "r"
                    },
                    "index": 1,
                    "lastEditedBy": "f313b510-8ff6-4ef7-8c27-070c2ae45fc1",
                    "_deleted": false
                  }
                }
              }
            ],
            "creator": "pkhexmkwbs",
            "time": 1684302826498.06
          }
        ],
        [
          {
            "body": [
              {
                "ifMatch": {
                  "$set": {
                    "data": {
                      "code": "import {\n    FaceLandmarker,\n    FilesetResolver,\n    DrawingUtils\n} from \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0\";\n\nconst filesetResolver = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm\"\n);\n\nfunction calculateCentroid(landmarks) {\n    const sum = landmarks.reduce((acc, landmark) => {\n        acc[0] = landmark.x + acc[0];\n        acc[1] = landmark.y + acc[1];\n        acc[2] = landmark.z + acc[2];\n        return acc;\n    }, [0, 0, 0]);\n    return sum.map(coord => coord / landmarks.length);\n}\n\nconst faceLandmarker = await FaceLandmarker.createFromOptions(filesetResolver, {\n    baseOptions: {\n        modelAssetPath: \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task\",\n        delegate: \"GPU\"\n    },\n    outputFaceBlendshapes: true,\n    runningMode: \"IMAGE\",\n    numFaces: 1\n});\n\n\nconst visionLine = 0.5;\nconst threshold = 0.6;\n\ncaptureStream().pipe(\n  throttleTime(1000),\n  map(({message: img}) => {\n    const [x,y,z] = calculateCentroid(faceLandmarker.detect(img).faceLandmarks[0]);\n    const distance = visionLine-x;\n    const relativeDistance = Math.abs(distance)/x;\n    console.log(relativeDistance);\n    return relativeDistance >= threshold ? \"NONE\" : distance > 0 ? \"l\" : \"r\";\n  }),\n  rewrite()\n)",
                      "language": "javascript",
                      "output": "l"
                    },
                    "index": 1,
                    "lastEditedBy": "f313b510-8ff6-4ef7-8c27-070c2ae45fc1",
                    "_deleted": false
                  }
                }
              }
            ],
            "creator": "pkhexmkwbs",
            "time": 1684302854139.01
          }
        ],
        [
          {
            "body": [
              {
                "ifMatch": {
                  "$set": {
                    "data": {
                      "code": "import {\n    FaceLandmarker,\n    FilesetResolver,\n    DrawingUtils\n} from \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0\";\n\nconst filesetResolver = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm\"\n);\n\nfunction calculateCentroid(landmarks) {\n    const sum = landmarks.reduce((acc, landmark) => {\n        acc[0] = landmark.x + acc[0];\n        acc[1] = landmark.y + acc[1];\n        acc[2] = landmark.z + acc[2];\n        return acc;\n    }, [0, 0, 0]);\n    return sum.map(coord => coord / landmarks.length);\n}\n\nconst faceLandmarker = await FaceLandmarker.createFromOptions(filesetResolver, {\n    baseOptions: {\n        modelAssetPath: \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task\",\n        delegate: \"GPU\"\n    },\n    outputFaceBlendshapes: true,\n    runningMode: \"IMAGE\",\n    numFaces: 1\n});\n\n\nconst visionLine = 0.5;\nconst threshold = 0.6;\n\ncaptureStream().pipe(\n  throttleTime(1000),\n  map(({message: img}) => {\n    const [x,y,z] = calculateCentroid(faceLandmarker.detect(img).faceLandmarks[0]);\n    const distance = visionLine-x;\n    const relativeDistance = Math.abs(distance)/x;\n    console.log(relativeDistance);\n    return relativeDistance >= threshold ? \"NONE\" : distance > 0 ? \"l\" : \"r\";\n  }),\n  rewrite()\n)",
                      "language": "javascript",
                      "output": "lUncaught TypeError: Cannot read properties of undefined (reading 'reduce')\n"
                    },
                    "index": 1,
                    "lastEditedBy": "f313b510-8ff6-4ef7-8c27-070c2ae45fc1",
                    "_deleted": false
                  }
                }
              }
            ],
            "creator": "pkhexmkwbs",
            "time": 1684302855163.01
          }
        ],
        [
          {
            "body": [
              {
                "ifMatch": {
                  "$set": {
                    "data": {
                      "code": "import {\n    FaceLandmarker,\n    FilesetResolver,\n    DrawingUtils\n} from \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0\";\n\nconst filesetResolver = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm\"\n);\n\nfunction calculateCentroid(landmarks) {\n    const sum = landmarks.reduce((acc, landmark) => {\n        acc[0] = landmark.x + acc[0];\n        acc[1] = landmark.y + acc[1];\n        acc[2] = landmark.z + acc[2];\n        return acc;\n    }, [0, 0, 0]);\n    return sum.map(coord => coord / landmarks.length);\n}\n\nconst faceLandmarker = await FaceLandmarker.createFromOptions(filesetResolver, {\n    baseOptions: {\n        modelAssetPath: \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task\",\n        delegate: \"GPU\"\n    },\n    outputFaceBlendshapes: true,\n    runningMode: \"IMAGE\",\n    numFaces: 1\n});\n\n\nconst visionLine = 0.5;\nconst threshold = 0.6;\n\ncaptureStream().pipe(\n  throttleTime(1000),\n  map(({message: img}) => {\n    const [x,y,z] = calculateCentroid(faceLandmarker.detect(img).faceLandmarks[0]);\n    const distance = visionLine-x;\n    const relativeDistance = Math.abs(distance)/x;\n    console.log(relativeDistanc);\n    return relativeDistance >= threshold ? \"NONE\" : distance > 0 ? \"l\" : \"r\";\n  }),\n  rewrite()\n)",
                      "language": "javascript",
                      "output": "lUncaught TypeError: Cannot read properties of undefined (reading 'reduce')\n"
                    },
                    "index": 1,
                    "lastEditedBy": "f313b510-8ff6-4ef7-8c27-070c2ae45fc1",
                    "_deleted": false
                  }
                }
              }
            ],
            "creator": "pkhexmkwbs",
            "time": 1684302869307.01
          }
        ],
        [
          {
            "body": [
              {
                "ifMatch": {
                  "$set": {
                    "data": {
                      "code": "import {\n    FaceLandmarker,\n    FilesetResolver,\n    DrawingUtils\n} from \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0\";\n\nconst filesetResolver = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm\"\n);\n\nfunction calculateCentroid(landmarks) {\n    const sum = landmarks.reduce((acc, landmark) => {\n        acc[0] = landmark.x + acc[0];\n        acc[1] = landmark.y + acc[1];\n        acc[2] = landmark.z + acc[2];\n        return acc;\n    }, [0, 0, 0]);\n    return sum.map(coord => coord / landmarks.length);\n}\n\nconst faceLandmarker = await FaceLandmarker.createFromOptions(filesetResolver, {\n    baseOptions: {\n        modelAssetPath: \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task\",\n        delegate: \"GPU\"\n    },\n    outputFaceBlendshapes: true,\n    runningMode: \"IMAGE\",\n    numFaces: 1\n});\n\n\nconst visionLine = 0.5;\nconst threshold = 0.6;\n\ncaptureStream().pipe(\n  throttleTime(1000),\n  map(({message: img}) => {\n    const [x,y,z] = calculateCentroid(faceLandmarker.detect(img).faceLandmarks[0]);\n    const distance = visionLine-x;\n    const relativeDistance = Math.abs(distance)/x;\n    console.log(dista);\n    return relativeDistance >= threshold ? \"NONE\" : distance > 0 ? \"l\" : \"r\";\n  }),\n  rewrite()\n)",
                      "language": "javascript",
                      "output": "lUncaught TypeError: Cannot read properties of undefined (reading 'reduce')\n"
                    },
                    "index": 1,
                    "lastEditedBy": "f313b510-8ff6-4ef7-8c27-070c2ae45fc1",
                    "_deleted": false
                  }
                }
              }
            ],
            "creator": "pkhexmkwbs",
            "time": 1684302871916.01
          }
        ],
        [
          {
            "body": [
              {
                "ifMatch": {
                  "$set": {
                    "data": {
                      "code": "import {\n    FaceLandmarker,\n    FilesetResolver,\n    DrawingUtils\n} from \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0\";\n\nconst filesetResolver = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm\"\n);\n\nfunction calculateCentroid(landmarks) {\n    const sum = landmarks.reduce((acc, landmark) => {\n        acc[0] = landmark.x + acc[0];\n        acc[1] = landmark.y + acc[1];\n        acc[2] = landmark.z + acc[2];\n        return acc;\n    }, [0, 0, 0]);\n    return sum.map(coord => coord / landmarks.length);\n}\n\nconst faceLandmarker = await FaceLandmarker.createFromOptions(filesetResolver, {\n    baseOptions: {\n        modelAssetPath: \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task\",\n        delegate: \"GPU\"\n    },\n    outputFaceBlendshapes: true,\n    runningMode: \"IMAGE\",\n    numFaces: 1\n});\n\n\nconst visionLine = 0.5;\nconst threshold = 0.6;\n\ncaptureStream().pipe(\n  throttleTime(1000),\n  map(({message: img}) => {\n    const [x,y,z] = calculateCentroid(faceLandmarker.detect(img).faceLandmarks[0]);\n    const distance = visionLine-x;\n    const relativeDistance = Math.abs(distance)/x;\n    console.log(distance);\n    return relativeDistance >= threshold ? \"NONE\" : distance > 0 ? \"l\" : \"r\";\n  }),\n  rewrite()\n)",
                      "language": "javascript",
                      "output": "lUncaught TypeError: Cannot read properties of undefined (reading 'reduce')\n"
                    },
                    "index": 1,
                    "lastEditedBy": "f313b510-8ff6-4ef7-8c27-070c2ae45fc1",
                    "_deleted": false
                  }
                }
              }
            ],
            "creator": "pkhexmkwbs",
            "time": 1684302872463.01
          }
        ],
        [
          {
            "body": [
              {
                "ifMatch": {
                  "$set": {
                    "data": {
                      "code": "import {\n    FaceLandmarker,\n    FilesetResolver,\n    DrawingUtils\n} from \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0\";\n\nconst filesetResolver = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm\"\n);\n\nfunction calculateCentroid(landmarks) {\n    const sum = landmarks.reduce((acc, landmark) => {\n        acc[0] = landmark.x + acc[0];\n        acc[1] = landmark.y + acc[1];\n        acc[2] = landmark.z + acc[2];\n        return acc;\n    }, [0, 0, 0]);\n    return sum.map(coord => coord / landmarks.length);\n}\n\nconst faceLandmarker = await FaceLandmarker.createFromOptions(filesetResolver, {\n    baseOptions: {\n        modelAssetPath: \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task\",\n        delegate: \"GPU\"\n    },\n    outputFaceBlendshapes: true,\n    runningMode: \"IMAGE\",\n    numFaces: 1\n});\n\n\nconst visionLine = 0.5;\nconst threshold = 0.6;\n\ncaptureStream().pipe(\n  throttleTime(1000),\n  map(({message: img}) => {\n    const [x,y,z] = calculateCentroid(faceLandmarker.detect(img).faceLandmarks[0]);\n    const distance = visionLine-x;\n    const relativeDistance = Math.abs(distance)/x;\n    console.log(relativeDistanc);\n    return relativeDistance >= threshold ? \"NONE\" : distance > 0 ? \"l\" : \"r\";\n  }),\n  rewrite()\n)",
                      "language": "javascript",
                      "output": "lUncaught TypeError: Cannot read properties of undefined (reading 'reduce')\n"
                    },
                    "index": 1,
                    "lastEditedBy": "f313b510-8ff6-4ef7-8c27-070c2ae45fc1",
                    "_deleted": false
                  }
                }
              }
            ],
            "creator": "pkhexmkwbs",
            "time": 1684302874712.06
          }
        ],
        [
          {
            "body": [
              {
                "ifMatch": {
                  "$set": {
                    "data": {
                      "code": "import {\n    FaceLandmarker,\n    FilesetResolver,\n    DrawingUtils\n} from \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0\";\n\nconst filesetResolver = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm\"\n);\n\nfunction calculateCentroid(landmarks) {\n    const sum = landmarks.reduce((acc, landmark) => {\n        acc[0] = landmark.x + acc[0];\n        acc[1] = landmark.y + acc[1];\n        acc[2] = landmark.z + acc[2];\n        return acc;\n    }, [0, 0, 0]);\n    return sum.map(coord => coord / landmarks.length);\n}\n\nconst faceLandmarker = await FaceLandmarker.createFromOptions(filesetResolver, {\n    baseOptions: {\n        modelAssetPath: \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task\",\n        delegate: \"GPU\"\n    },\n    outputFaceBlendshapes: true,\n    runningMode: \"IMAGE\",\n    numFaces: 1\n});\n\n\nconst visionLine = 0.5;\nconst threshold = 0.6;\n\ncaptureStream().pipe(\n  throttleTime(1000),\n  map(({message: img}) => {\n    const [x,y,z] = calculateCentroid(faceLandmarker.detect(img).faceLandmarks[0]);\n    const distance = visionLine-x;\n    const relativeDistance = Math.abs(distance)/x;\n    console.log(relativeDistanc);\n    return relativeDistance > threshold ? \"NONE\" : distance > 0 ? \"l\" : \"r\";\n  }),\n  rewrite()\n)",
                      "language": "javascript",
                      "output": "lUncaught TypeError: Cannot read properties of undefined (reading 'reduce')\n"
                    },
                    "index": 1,
                    "lastEditedBy": "f313b510-8ff6-4ef7-8c27-070c2ae45fc1",
                    "_deleted": false
                  }
                }
              }
            ],
            "creator": "pkhexmkwbs",
            "time": 1684302905901.01
          }
        ],
        [
          {
            "body": [
              {
                "ifMatch": {
                  "$set": {
                    "data": {
                      "code": "import {\n    FaceLandmarker,\n    FilesetResolver,\n    DrawingUtils\n} from \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0\";\n\nconst filesetResolver = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm\"\n);\n\nfunction calculateCentroid(landmarks) {\n    const sum = landmarks.reduce((acc, landmark) => {\n        acc[0] = landmark.x + acc[0];\n        acc[1] = landmark.y + acc[1];\n        acc[2] = landmark.z + acc[2];\n        return acc;\n    }, [0, 0, 0]);\n    return sum.map(coord => coord / landmarks.length);\n}\n\nconst faceLandmarker = await FaceLandmarker.createFromOptions(filesetResolver, {\n    baseOptions: {\n        modelAssetPath: \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task\",\n        delegate: \"GPU\"\n    },\n    outputFaceBlendshapes: true,\n    runningMode: \"IMAGE\",\n    numFaces: 1\n});\n\n\nconst visionLine = 0.5;\nconst threshold = 0.6;\n\ncaptureStream().pipe(\n  throttleTime(1000),\n  map(({message: img}) => {\n    const [x,y,z] = calculateCentroid(faceLandmarker.detect(img).faceLandmarks[0]);\n    const distance = visionLine-x;\n    const relativeDistance = Math.abs(distance)/x;\n    console.log(relativeDistanc);\n    return relativeDistance <= threshold ? \"NONE\" : distance > 0 ? \"l\" : \"r\";\n  }),\n  rewrite()\n)",
                      "language": "javascript",
                      "output": "lUncaught TypeError: Cannot read properties of undefined (reading 'reduce')\n"
                    },
                    "index": 1,
                    "lastEditedBy": "f313b510-8ff6-4ef7-8c27-070c2ae45fc1",
                    "_deleted": false
                  }
                }
              }
            ],
            "creator": "pkhexmkwbs",
            "time": 1684302907040.06
          }
        ],
        [
          {
            "body": [
              {
                "ifMatch": {
                  "$set": {
                    "data": {
                      "code": "import {\n    FaceLandmarker,\n    FilesetResolver,\n    DrawingUtils\n} from \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0\";\n\nconst filesetResolver = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm\"\n);\n\nfunction calculateCentroid(landmarks) {\n    const sum = landmarks.reduce((acc, landmark) => {\n        acc[0] = landmark.x + acc[0];\n        acc[1] = landmark.y + acc[1];\n        acc[2] = landmark.z + acc[2];\n        return acc;\n    }, [0, 0, 0]);\n    return sum.map(coord => coord / landmarks.length);\n}\n\nconst faceLandmarker = await FaceLandmarker.createFromOptions(filesetResolver, {\n    baseOptions: {\n        modelAssetPath: \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task\",\n        delegate: \"GPU\"\n    },\n    outputFaceBlendshapes: true,\n    runningMode: \"IMAGE\",\n    numFaces: 1\n});\n\n\nconst visionLine = 0.5;\nconst threshold = 0.2;\n\ncaptureStream().pipe(\n  throttleTime(1000),\n  map(({message: img}) => {\n    const [x,y,z] = calculateCentroid(faceLandmarker.detect(img).faceLandmarks[0]);\n    const distance = visionLine-x;\n    const relativeDistance = Math.abs(distance)/x;\n    console.log(relativeDistanc);\n    return relativeDistance <= threshold ? \"NONE\" : distance > 0 ? \"l\" : \"r\";\n  }),\n  rewrite()\n)",
                      "language": "javascript",
                      "output": "lUncaught TypeError: Cannot read properties of undefined (reading 'reduce')\n"
                    },
                    "index": 1,
                    "lastEditedBy": "f313b510-8ff6-4ef7-8c27-070c2ae45fc1",
                    "_deleted": false
                  }
                }
              }
            ],
            "creator": "pkhexmkwbs",
            "time": 1684302910868.02
          }
        ],
        [
          {
            "body": [
              {
                "ifMatch": {
                  "$set": {
                    "data": {
                      "code": "import {\n    FaceLandmarker,\n    FilesetResolver,\n    DrawingUtils\n} from \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0\";\n\nconst filesetResolver = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm\"\n);\n\nfunction calculateCentroid(landmarks) {\n    const sum = landmarks.reduce((acc, landmark) => {\n        acc[0] = landmark.x + acc[0];\n        acc[1] = landmark.y + acc[1];\n        acc[2] = landmark.z + acc[2];\n        return acc;\n    }, [0, 0, 0]);\n    return sum.map(coord => coord / landmarks.length);\n}\n\nconst faceLandmarker = await FaceLandmarker.createFromOptions(filesetResolver, {\n    baseOptions: {\n        modelAssetPath: \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task\",\n        delegate: \"GPU\"\n    },\n    outputFaceBlendshapes: true,\n    runningMode: \"IMAGE\",\n    numFaces: 1\n});\n\n\nconst visionLine = 0.5;\nconst threshold = 0.2;\n\ncaptureStream().pipe(\n  throttleTime(1000),\n  map(({message: img}) => {\n    const [x,y,z] = calculateCentroid(faceLandmarker.detect(img).faceLandmarks[0]);\n    const distance = visionLine-x;\n    const relativeDistance = Math.abs(distance)/x;\n    console.log(relativeDistanc);\n    return relativeDistance <= threshold ? \"NONE\" : distance > 0 ? \"l\" : \"r\";\n  }),\n  rewrite()\n)",
                      "language": "javascript",
                      "output": ""
                    },
                    "index": 1,
                    "lastEditedBy": "f313b510-8ff6-4ef7-8c27-070c2ae45fc1",
                    "_deleted": false
                  }
                }
              }
            ],
            "creator": "pkhexmkwbs",
            "time": 1684302911681.01
          }
        ],
        [
          {
            "body": [
              {
                "ifMatch": {
                  "$set": {
                    "data": {
                      "code": "import {\n    FaceLandmarker,\n    FilesetResolver,\n    DrawingUtils\n} from \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0\";\n\nconst filesetResolver = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm\"\n);\n\nfunction calculateCentroid(landmarks) {\n    const sum = landmarks.reduce((acc, landmark) => {\n        acc[0] = landmark.x + acc[0];\n        acc[1] = landmark.y + acc[1];\n        acc[2] = landmark.z + acc[2];\n        return acc;\n    }, [0, 0, 0]);\n    return sum.map(coord => coord / landmarks.length);\n}\n\nconst faceLandmarker = await FaceLandmarker.createFromOptions(filesetResolver, {\n    baseOptions: {\n        modelAssetPath: \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task\",\n        delegate: \"GPU\"\n    },\n    outputFaceBlendshapes: true,\n    runningMode: \"IMAGE\",\n    numFaces: 1\n});\n\n\nconst visionLine = 0.5;\nconst threshold = 0.2;\n\ncaptureStream().pipe(\n  throttleTime(1000),\n  map(({message: img}) => {\n    const [x,y,z] = calculateCentroid(faceLandmarker.detect(img).faceLandmarks[0]);\n    const distance = visionLine-x;\n    const relativeDistance = Math.abs(distance)/x;\n    console.log(relativeDistanc);\n    return relativeDistance <= threshold ? \"NONE\" : distance > 0 ? \"l\" : \"r\";\n  }),\n  rewrite()\n)",
                      "language": "javascript",
                      "output": "Uncaught ReferenceError: relativeDistanc is not defined\n"
                    },
                    "index": 1,
                    "lastEditedBy": "f313b510-8ff6-4ef7-8c27-070c2ae45fc1",
                    "_deleted": false
                  }
                }
              }
            ],
            "creator": "pkhexmkwbs",
            "time": 1684302913644.06
          }
        ],
        [
          {
            "body": [
              {
                "ifMatch": {
                  "$set": {
                    "data": {
                      "code": "import {\n    FaceLandmarker,\n    FilesetResolver,\n    DrawingUtils\n} from \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0\";\n\nconst filesetResolver = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm\"\n);\n\nfunction calculateCentroid(landmarks) {\n    const sum = landmarks.reduce((acc, landmark) => {\n        acc[0] = landmark.x + acc[0];\n        acc[1] = landmark.y + acc[1];\n        acc[2] = landmark.z + acc[2];\n        return acc;\n    }, [0, 0, 0]);\n    return sum.map(coord => coord / landmarks.length);\n}\n\nconst faceLandmarker = await FaceLandmarker.createFromOptions(filesetResolver, {\n    baseOptions: {\n        modelAssetPath: \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task\",\n        delegate: \"GPU\"\n    },\n    outputFaceBlendshapes: true,\n    runningMode: \"IMAGE\",\n    numFaces: 1\n});\n\n\nconst visionLine = 0.5;\nconst threshold = 0.2;\n\ncaptureStream().pipe(\n  throttleTime(1000),\n  map(({message: img}) => {\n    const [x,y,z] = calculateCentroid(faceLandmarker.detect(img).faceLandmarks[0]);\n    const distance = visionLine-x;\n    const relativeDistance = Math.abs(distance)/x;\n    console.log(relativeDistance);\n    return relativeDistance <= threshold ? \"NONE\" : distance > 0 ? \"l\" : \"r\";\n  }),\n  rewrite()\n)",
                      "language": "javascript",
                      "output": "Uncaught ReferenceError: relativeDistanc is not defined\n"
                    },
                    "index": 1,
                    "lastEditedBy": "f313b510-8ff6-4ef7-8c27-070c2ae45fc1",
                    "_deleted": false
                  }
                }
              }
            ],
            "creator": "pkhexmkwbs",
            "time": 1684302916481.05
          }
        ],
        [
          {
            "body": [
              {
                "ifMatch": {
                  "$set": {
                    "data": {
                      "code": "import {\n    FaceLandmarker,\n    FilesetResolver,\n    DrawingUtils\n} from \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0\";\n\nconst filesetResolver = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm\"\n);\n\nfunction calculateCentroid(landmarks) {\n    const sum = landmarks.reduce((acc, landmark) => {\n        acc[0] = landmark.x + acc[0];\n        acc[1] = landmark.y + acc[1];\n        acc[2] = landmark.z + acc[2];\n        return acc;\n    }, [0, 0, 0]);\n    return sum.map(coord => coord / landmarks.length);\n}\n\nconst faceLandmarker = await FaceLandmarker.createFromOptions(filesetResolver, {\n    baseOptions: {\n        modelAssetPath: \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task\",\n        delegate: \"GPU\"\n    },\n    outputFaceBlendshapes: true,\n    runningMode: \"IMAGE\",\n    numFaces: 1\n});\n\n\nconst visionLine = 0.5;\nconst threshold = 0.2;\n\ncaptureStream().pipe(\n  throttleTime(1000),\n  map(({message: img}) => {\n    const [x,y,z] = calculateCentroid(faceLandmarker.detect(img).faceLandmarks[0]);\n    const distance = visionLine-x;\n    const relativeDistance = Math.abs(distance)/x;\n    console.log(relativeDistance);\n    return relativeDistance <= threshold ? \"NONE\" : distance > 0 ? \"l\" : \"r\";\n  }),\n  rewrite()\n)",
                      "language": "javascript",
                      "output": ""
                    },
                    "index": 1,
                    "lastEditedBy": "f313b510-8ff6-4ef7-8c27-070c2ae45fc1",
                    "_deleted": false
                  }
                }
              }
            ],
            "creator": "pkhexmkwbs",
            "time": 1684302917230.01
          }
        ],
        [
          {
            "body": [
              {
                "ifMatch": {
                  "$set": {
                    "data": {
                      "code": "import {\n    FaceLandmarker,\n    FilesetResolver,\n    DrawingUtils\n} from \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0\";\n\nconst filesetResolver = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm\"\n);\n\nfunction calculateCentroid(landmarks) {\n    const sum = landmarks.reduce((acc, landmark) => {\n        acc[0] = landmark.x + acc[0];\n        acc[1] = landmark.y + acc[1];\n        acc[2] = landmark.z + acc[2];\n        return acc;\n    }, [0, 0, 0]);\n    return sum.map(coord => coord / landmarks.length);\n}\n\nconst faceLandmarker = await FaceLandmarker.createFromOptions(filesetResolver, {\n    baseOptions: {\n        modelAssetPath: \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task\",\n        delegate: \"GPU\"\n    },\n    outputFaceBlendshapes: true,\n    runningMode: \"IMAGE\",\n    numFaces: 1\n});\n\n\nconst visionLine = 0.5;\nconst threshold = 0.2;\n\ncaptureStream().pipe(\n  throttleTime(1000),\n  map(({message: img}) => {\n    const [x,y,z] = calculateCentroid(faceLandmarker.detect(img).faceLandmarks[0]);\n    const distance = visionLine-x;\n    const relativeDistance = Math.abs(distance)/x;\n    console.log(relativeDistance);\n    return relativeDistance <= threshold ? \"NONE\" : distance > 0 ? \"l\" : \"r\";\n  }),\n  rewrite()\n)",
                      "language": "javascript",
                      "output": "NONE"
                    },
                    "index": 1,
                    "lastEditedBy": "f313b510-8ff6-4ef7-8c27-070c2ae45fc1",
                    "_deleted": false
                  }
                }
              }
            ],
            "creator": "pkhexmkwbs",
            "time": 1684302919112.02
          }
        ],
        [
          {
            "body": [
              {
                "ifMatch": {
                  "$set": {
                    "data": {
                      "code": "import {\n    FaceLandmarker,\n    FilesetResolver,\n    DrawingUtils\n} from \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0\";\n\nconst filesetResolver = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm\"\n);\n\nfunction calculateCentroid(landmarks) {\n    const sum = landmarks.reduce((acc, landmark) => {\n        acc[0] = landmark.x + acc[0];\n        acc[1] = landmark.y + acc[1];\n        acc[2] = landmark.z + acc[2];\n        return acc;\n    }, [0, 0, 0]);\n    return sum.map(coord => coord / landmarks.length);\n}\n\nconst faceLandmarker = await FaceLandmarker.createFromOptions(filesetResolver, {\n    baseOptions: {\n        modelAssetPath: \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task\",\n        delegate: \"GPU\"\n    },\n    outputFaceBlendshapes: true,\n    runningMode: \"IMAGE\",\n    numFaces: 1\n});\n\n\nconst visionLine = 0.5;\nconst threshold = 0.2;\n\ncaptureStream().pipe(\n  throttleTime(1000),\n  map(({message: img}) => {\n    const [x,y,z] = calculateCentroid(faceLandmarker.detect(img).faceLandmarks[0]);\n    const distance = visionLine-x;\n    const relativeDistance = Math.abs(distance)/x;\n    console.log(relativeDistance);\n    return relativeDistance <= threshold ? \"NONE\" : distance > 0 ? \"l\" : \"r\";\n  }),\n  rewrite()\n)",
                      "language": "javascript",
                      "output": "l"
                    },
                    "index": 1,
                    "lastEditedBy": "f313b510-8ff6-4ef7-8c27-070c2ae45fc1",
                    "_deleted": false
                  }
                }
              }
            ],
            "creator": "pkhexmkwbs",
            "time": 1684302923275.01
          }
        ],
        [
          {
            "body": [
              {
                "ifMatch": {
                  "$set": {
                    "data": {
                      "code": "import {\n    FaceLandmarker,\n    FilesetResolver,\n    DrawingUtils\n} from \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0\";\n\nconst filesetResolver = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm\"\n);\n\nfunction calculateCentroid(landmarks) {\n    const sum = landmarks.reduce((acc, landmark) => {\n        acc[0] = landmark.x + acc[0];\n        acc[1] = landmark.y + acc[1];\n        acc[2] = landmark.z + acc[2];\n        return acc;\n    }, [0, 0, 0]);\n    return sum.map(coord => coord / landmarks.length);\n}\n\nconst faceLandmarker = await FaceLandmarker.createFromOptions(filesetResolver, {\n    baseOptions: {\n        modelAssetPath: \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task\",\n        delegate: \"GPU\"\n    },\n    outputFaceBlendshapes: true,\n    runningMode: \"IMAGE\",\n    numFaces: 1\n});\n\n\nconst visionLine = 0.5;\nconst threshold = 0.2;\n\ncaptureStream().pipe(\n  throttleTime(1000),\n  map(({message: img}) => {\n    const [x,y,z] = calculateCentroid(faceLandmarker.detect(img).faceLandmarks[0]);\n    const distance = visionLine-x;\n    const relativeDistance = Math.abs(distance)/x;\n    console.log(relativeDistance);\n    return relativeDistance <= threshold ? \"NONE\" : distance > 0 ? \"l\" : \"r\";\n  }),\n  rewrite()\n)",
                      "language": "javascript",
                      "output": "NONE"
                    },
                    "index": 1,
                    "lastEditedBy": "f313b510-8ff6-4ef7-8c27-070c2ae45fc1",
                    "_deleted": false
                  }
                }
              }
            ],
            "creator": "pkhexmkwbs",
            "time": 1684302938216.01
          }
        ],
        [
          {
            "body": [
              {
                "ifMatch": {
                  "$set": {
                    "data": {
                      "code": "import {\n    FaceLandmarker,\n    FilesetResolver,\n    DrawingUtils\n} from \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0\";\n\nconst filesetResolver = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm\"\n);\n\nfunction calculateCentroid(landmarks) {\n    const sum = landmarks.reduce((acc, landmark) => {\n        acc[0] = landmark.x + acc[0];\n        acc[1] = landmark.y + acc[1];\n        acc[2] = landmark.z + acc[2];\n        return acc;\n    }, [0, 0, 0]);\n    return sum.map(coord => coord / landmarks.length);\n}\n\nconst faceLandmarker = await FaceLandmarker.createFromOptions(filesetResolver, {\n    baseOptions: {\n        modelAssetPath: \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task\",\n        delegate: \"GPU\"\n    },\n    outputFaceBlendshapes: true,\n    runningMode: \"IMAGE\",\n    numFaces: 1\n});\n\n\nconst visionLine = 0.5;\nconst threshold = 0.2;\n\ncaptureStream().pipe(\n  throttleTime(1000),\n  map(({message: img}) => {\n    const [x,y,z] = calculateCentroid(faceLandmarker.detect(img).faceLandmarks[0]);\n    const distance = visionLine-x;\n    const relativeDistance = Math.abs(distance)/x;\n    console.log(relativeDistance);\n    return relativeDistance <= threshold ? \"NONE\" : distance > 0 ? \"l\" : \"r\";\n  }),\n  rewrite()\n)",
                      "language": "javascript",
                      "output": "l"
                    },
                    "index": 1,
                    "lastEditedBy": "f313b510-8ff6-4ef7-8c27-070c2ae45fc1",
                    "_deleted": false
                  }
                }
              }
            ],
            "creator": "pkhexmkwbs",
            "time": 1684302949881.01
          }
        ],
        [
          {
            "body": [
              {
                "ifMatch": {
                  "$set": {
                    "data": {
                      "code": "import {\n    FaceLandmarker,\n    FilesetResolver,\n    DrawingUtils\n} from \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0\";\n\nconst filesetResolver = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm\"\n);\n\nfunction calculateCentroid(landmarks) {\n    const sum = landmarks.reduce((acc, landmark) => {\n        acc[0] = landmark.x + acc[0];\n        acc[1] = landmark.y + acc[1];\n        acc[2] = landmark.z + acc[2];\n        return acc;\n    }, [0, 0, 0]);\n    return sum.map(coord => coord / landmarks.length);\n}\n\nconst faceLandmarker = await FaceLandmarker.createFromOptions(filesetResolver, {\n    baseOptions: {\n        modelAssetPath: \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task\",\n        delegate: \"GPU\"\n    },\n    outputFaceBlendshapes: true,\n    runningMode: \"IMAGE\",\n    numFaces: 1\n});\n\n\nconst visionLine = 0.5;\nconst threshold = 0.2;\n\ncaptureStream().pipe(\n  throttleTime(1000),\n  map(({message: img}) => {\n    const [x,y,z] = calculateCentroid(faceLandmarker.detect(img).faceLandmarks[0]);\n    const distance = visionLine-x;\n    const relativeDistance = Math.abs(distance)/x;\n    console.log(relativeDistance);\n    return relativeDistance <= threshold ? \"NONE\" : distance > 0 ? \"l\" : \"r\";\n  }),\n  rewrite()\n)",
                      "language": "javascript",
                      "output": "NONE"
                    },
                    "index": 1,
                    "lastEditedBy": "f313b510-8ff6-4ef7-8c27-070c2ae45fc1",
                    "_deleted": false
                  }
                }
              }
            ],
            "creator": "pkhexmkwbs",
            "time": 1684302960446.01
          }
        ],
        [
          {
            "body": [
              {
                "ifMatch": {
                  "$set": {
                    "data": {
                      "code": "import {\n    FaceLandmarker,\n    FilesetResolver,\n    DrawingUtils\n} from \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0\";\n\nconst filesetResolver = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm\"\n);\n\nfunction calculateCentroid(landmarks) {\n    const sum = landmarks.reduce((acc, landmark) => {\n        acc[0] = landmark.x + acc[0];\n        acc[1] = landmark.y + acc[1];\n        acc[2] = landmark.z + acc[2];\n        return acc;\n    }, [0, 0, 0]);\n    return sum.map(coord => coord / landmarks.length);\n}\n\nconst faceLandmarker = await FaceLandmarker.createFromOptions(filesetResolver, {\n    baseOptions: {\n        modelAssetPath: \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task\",\n        delegate: \"GPU\"\n    },\n    outputFaceBlendshapes: true,\n    runningMode: \"IMAGE\",\n    numFaces: 1\n});\n\n\nconst visionLine = 0.5;\nconst threshold = 0.2;\n\ncaptureStream().pipe(\n  throttleTime(1000),\n  map(({message: img}) => {\n    const [x,y,z] = calculateCentroid(faceLandmarker.detect(img).faceLandmarks[0]);\n    const distance = visionLine-x;\n    const relativeDistance = Math.abs(distance)/x;\n    console.log(relativeDistance);\n    return relativeDistance <= threshold ? \"NONE\" : distance > 0 ? \"l\" : \"r\";\n  }),\n  rewrite()\n)",
                      "language": "javascript",
                      "output": "r"
                    },
                    "index": 1,
                    "lastEditedBy": "f313b510-8ff6-4ef7-8c27-070c2ae45fc1",
                    "_deleted": false
                  }
                }
              }
            ],
            "creator": "pkhexmkwbs",
            "time": 1684302969988.01
          }
        ],
        [
          {
            "body": [
              {
                "ifMatch": {
                  "$set": {
                    "data": {
                      "code": "import {\n    FaceLandmarker,\n    FilesetResolver,\n    DrawingUtils\n} from \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0\";\n\nconst filesetResolver = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm\"\n);\n\nfunction calculateCentroid(landmarks) {\n    const sum = landmarks.reduce((acc, landmark) => {\n        acc[0] = landmark.x + acc[0];\n        acc[1] = landmark.y + acc[1];\n        acc[2] = landmark.z + acc[2];\n        return acc;\n    }, [0, 0, 0]);\n    return sum.map(coord => coord / landmarks.length);\n}\n\nconst faceLandmarker = await FaceLandmarker.createFromOptions(filesetResolver, {\n    baseOptions: {\n        modelAssetPath: \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task\",\n        delegate: \"GPU\"\n    },\n    outputFaceBlendshapes: true,\n    runningMode: \"IMAGE\",\n    numFaces: 1\n});\n\n\nconst visionLine = 0.5;\nconst threshold = 0.2;\n\ncaptureStream().pipe(\n  throttleTime(1000),\n  map(({message: img}) => {\n    const [x,y,z] = calculateCentroid(faceLandmarker.detect(img).faceLandmarks[0]);\n    const distance = visionLine-x;\n    const relativeDistance = Math.abs(distance)/x;\n    console.log(relativeDistance);\n    return relativeDistance <= threshold ? \"NONE\" : distance > 0 ? \"l\" : \"r\";\n  }),\n  rewrite()\n)",
                      "language": "javascript",
                      "output": "NONE"
                    },
                    "index": 1,
                    "lastEditedBy": "f313b510-8ff6-4ef7-8c27-070c2ae45fc1",
                    "_deleted": false
                  }
                }
              }
            ],
            "creator": "pkhexmkwbs",
            "time": 1684302978442.01
          }
        ],
        [
          {
            "body": [
              {
                "ifMatch": {
                  "$set": {
                    "data": {
                      "code": "import {\n    FaceLandmarker,\n    FilesetResolver,\n    DrawingUtils\n} from \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0\";\n\nconst filesetResolver = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm\"\n);\n\nfunction calculateCentroid(landmarks) {\n    const sum = landmarks.reduce((acc, landmark) => {\n        acc[0] = landmark.x + acc[0];\n        acc[1] = landmark.y + acc[1];\n        acc[2] = landmark.z + acc[2];\n        return acc;\n    }, [0, 0, 0]);\n    return sum.map(coord => coord / landmarks.length);\n}\n\nconst faceLandmarker = await FaceLandmarker.createFromOptions(filesetResolver, {\n    baseOptions: {\n        modelAssetPath: \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task\",\n        delegate: \"GPU\"\n    },\n    outputFaceBlendshapes: true,\n    runningMode: \"IMAGE\",\n    numFaces: 1\n});\n\n\nconst visionLine = 0.5;\nconst threshold = 0.2;\n\ncaptureStream().pipe(\n  throttleTime(1000),\n  map(({message: img}) => {\n    const [x,y,z] = calculateCentroid(faceLandmarker.detect(img).faceLandmarks[0]);\n    const distance = visionLine-x;\n    const relativeDistance = Math.abs(distance)/x;\n    return relativeDistance <= threshold ? \"NONE\" : distance > 0 ? \"l\" : \"r\";\n  }),\n  rewrite()\n)",
                      "language": "javascript",
                      "output": "NONE"
                    },
                    "index": 1,
                    "lastEditedBy": "f313b510-8ff6-4ef7-8c27-070c2ae45fc1",
                    "_deleted": false
                  }
                }
              }
            ],
            "creator": "pkhexmkwbs",
            "time": 1684303013099.02
          }
        ],
        [
          {
            "body": [
              {
                "ifMatch": {
                  "$set": {
                    "data": {
                      "code": "import {\n    FaceLandmarker,\n    FilesetResolver,\n    DrawingUtils\n} from \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0\";\n\nconst filesetResolver = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm\"\n);\n\nfunction calculateCentroid(landmarks) {\n    const sum = landmarks.reduce((acc, landmark) => {\n        acc[0] = landmark.x + acc[0];\n        acc[1] = landmark.y + acc[1];\n        acc[2] = landmark.z + acc[2];\n        return acc;\n    }, [0, 0, 0]);\n    return sum.map(coord => coord / landmarks.length);\n}\n\nconst faceLandmarker = await FaceLandmarker.createFromOptions(filesetResolver, {\n    baseOptions: {\n        modelAssetPath: \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task\",\n        delegate: \"GPU\"\n    },\n    outputFaceBlendshapes: true,\n    runningMode: \"IMAGE\",\n    numFaces: 1\n});\n\n\nconst visionLine = 0.5;\nconst threshold = 0.2;\n\ncaptureStream().pipe(\n  throttleTime(1000),\n  map(({message: img}) => {\n    const [x,y,z] = calculateCentroid(faceLandmarker.detect(img).faceLandmarks[0]);\n    const distance = visionLine-x;\n    const relativeDistance = Math.abs(distance)/x;\n    return relativeDistance <= threshold ? \"NONE\" : distance > 0 ? \"l\" : \"r\";\n  }),\n  rewrite()\n)",
                      "language": "javascript",
                      "output": ""
                    },
                    "index": 1,
                    "lastEditedBy": "f313b510-8ff6-4ef7-8c27-070c2ae45fc1",
                    "_deleted": false
                  }
                }
              }
            ],
            "creator": "pkhexmkwbs",
            "time": 1684303081489.01
          }
        ],
        [
          {
            "body": [
              {
                "ifMatch": {
                  "$set": {
                    "data": {
                      "code": "import {\n    FaceLandmarker,\n    FilesetResolver,\n    DrawingUtils\n} from \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0\";\n\nconst filesetResolver = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm\"\n);\n\nfunction calculateCentroid(landmarks) {\n    const sum = landmarks.reduce((acc, landmark) => {\n        acc[0] = landmark.x + acc[0];\n        acc[1] = landmark.y + acc[1];\n        acc[2] = landmark.z + acc[2];\n        return acc;\n    }, [0, 0, 0]);\n    return sum.map(coord => coord / landmarks.length);\n}\n\nconst faceLandmarker = await FaceLandmarker.createFromOptions(filesetResolver, {\n    baseOptions: {\n        modelAssetPath: \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task\",\n        delegate: \"GPU\"\n    },\n    outputFaceBlendshapes: true,\n    runningMode: \"IMAGE\",\n    numFaces: 1\n});\n\n\nconst visionLine = 0.5;\nconst threshold = 0.2;\n\ncaptureStream().pipe(\n  throttleTime(1000),\n  map(({message: img}) => {\n    const [x,y,z] = calculateCentroid(faceLandmarker.detect(img).faceLandmarks[0]);\n    const distance = visionLine-x;\n    const relativeDistance = Math.abs(distance)/x;\n    return relativeDistance <= threshold ? \"NONE\" : distance > 0 ? \"l\" : \"r\";\n  }),\n  rewrite()\n)",
                      "language": "javascript",
                      "output": "l"
                    },
                    "index": 1,
                    "lastEditedBy": "f313b510-8ff6-4ef7-8c27-070c2ae45fc1",
                    "_deleted": false
                  }
                }
              }
            ],
            "creator": "pkhexmkwbs",
            "time": 1684303083152.06
          }
        ],
        [
          {
            "body": [
              {
                "ifMatch": {
                  "$set": {
                    "data": {
                      "code": "import {\n    FaceLandmarker,\n    FilesetResolver,\n    DrawingUtils\n} from \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0\";\n\nconst filesetResolver = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm\"\n);\n\nfunction calculateCentroid(landmarks) {\n    const sum = landmarks.reduce((acc, landmark) => {\n        acc[0] = landmark.x + acc[0];\n        acc[1] = landmark.y + acc[1];\n        acc[2] = landmark.z + acc[2];\n        return acc;\n    }, [0, 0, 0]);\n    return sum.map(coord => coord / landmarks.length);\n}\n\nconst faceLandmarker = await FaceLandmarker.createFromOptions(filesetResolver, {\n    baseOptions: {\n        modelAssetPath: \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task\",\n        delegate: \"GPU\"\n    },\n    outputFaceBlendshapes: true,\n    runningMode: \"IMAGE\",\n    numFaces: 1\n});\n\n\nconst visionLine = 0.5;\nconst threshold = 0.2;\n\ncaptureStream().pipe(\n  throttleTime(1000),\n  map(({message: img}) => {\n    const [x,y,z] = calculateCentroid(faceLandmarker.detect(img).faceLandmarks[0]);\n    const distance = visionLine-x;\n    const relativeDistance = Math.abs(distance)/x;\n    return relativeDistance <= threshold ? \"NONE\" : distance > 0 ? \"l\" : \"r\";\n  }),\n  rewrite()\n)",
                      "language": "javascript",
                      "output": "NONE"
                    },
                    "index": 1,
                    "lastEditedBy": "f313b510-8ff6-4ef7-8c27-070c2ae45fc1",
                    "_deleted": false
                  }
                }
              }
            ],
            "creator": "pkhexmkwbs",
            "time": 1684303088411.01
          }
        ],
        [
          {
            "body": [
              {
                "ifMatch": {
                  "$set": {
                    "data": {
                      "code": "import {\n    FaceLandmarker,\n    FilesetResolver,\n    DrawingUtils\n} from \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0\";\n\nconst filesetResolver = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm\"\n);\n\nfunction calculateCentroid(landmarks) {\n    const sum = landmarks.reduce((acc, landmark) => {\n        acc[0] = landmark.x + acc[0];\n        acc[1] = landmark.y + acc[1];\n        acc[2] = landmark.z + acc[2];\n        return acc;\n    }, [0, 0, 0]);\n    return sum.map(coord => coord / landmarks.length);\n}\n\nconst faceLandmarker = await FaceLandmarker.createFromOptions(filesetResolver, {\n    baseOptions: {\n        modelAssetPath: \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task\",\n        delegate: \"GPU\"\n    },\n    outputFaceBlendshapes: true,\n    runningMode: \"IMAGE\",\n    numFaces: 1\n});\n\n\nconst visionLine = 0.5;\nconst threshold = 0.2;\n\ncaptureStream().pipe(\n  throttleTime(1000),\n  map(({message: img}) => {\n    const [x,y,z] = calculateCentroid(faceLandmarker.detect(img).faceLandmarks[0]);\n    const distance = visionLine-x;\n    const relativeDistance = Math.abs(distance)/x;\n    return relativeDistance <= threshold ? \"NONE\" : distance > 0 ? \"l\" : \"r\";\n  }),\n  rewrite()\n)",
                      "language": "javascript",
                      "output": "NONEUncaught TypeError: Cannot read properties of undefined (reading 'reduce')\n"
                    },
                    "index": 1,
                    "lastEditedBy": "f313b510-8ff6-4ef7-8c27-070c2ae45fc1",
                    "_deleted": false
                  }
                }
              }
            ],
            "creator": "pkhexmkwbs",
            "time": 1684303090483.02
          }
        ],
        [
          {
            "body": [
              {
                "ifMatch": {
                  "$set": {
                    "data": {
                      "code": "import {\n    FaceLandmarker,\n    FilesetResolver,\n    DrawingUtils\n} from \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0\";\n\nconst filesetResolver = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm\"\n);\n\nfunction calculateCentroid(landmarks) {\n    const sum = landmarks.reduce((acc, landmark) => {\n        acc[0] = landmark.x + acc[0];\n        acc[1] = landmark.y + acc[1];\n        acc[2] = landmark.z + acc[2];\n        return acc;\n    }, [0, 0, 0]);\n    return sum.map(coord => coord / landmarks.length);\n}\n\nconst faceLandmarker = await FaceLandmarker.createFromOptions(filesetResolver, {\n    baseOptions: {\n        modelAssetPath: \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task\",\n        delegate: \"GPU\"\n    },\n    outputFaceBlendshapes: true,\n    runningMode: \"IMAGE\",\n    numFaces: 1\n});\n\n\nconst visionLine = 0.5;\nconst threshold = 0.2;\n\ncaptureStream().pipe(\n  throttleTime(1000),\n  map(({message: img}) => {\n    const [x,y,z] = calculateCentroid(\n      faceLandmarker.detect(img).faceLandmarks[0]);\n    const distance = visionLine-x;\n    const relativeDistance = Math.abs(distance)/x;\n    return relativeDistance <= threshold ? \"NONE\" : distance > 0 ? \"l\" : \"r\";\n  }),\n  rewrite()\n)",
                      "language": "javascript",
                      "output": "NONEUncaught TypeError: Cannot read properties of undefined (reading 'reduce')\n"
                    },
                    "index": 1,
                    "lastEditedBy": "f313b510-8ff6-4ef7-8c27-070c2ae45fc1",
                    "_deleted": false
                  }
                }
              }
            ],
            "creator": "pkhexmkwbs",
            "time": 1684303101574.01
          }
        ],
        [
          {
            "body": [
              {
                "ifMatch": {
                  "$set": {
                    "data": {
                      "code": "import {\n    FaceLandmarker,\n    FilesetResolver,\n    DrawingUtils\n} from \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0\";\n\nconst filesetResolver = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm\"\n);\n\nfunction calculateCentroid(landmarks) {\n    const sum = landmarks.reduce((acc, landmark) => {\n        acc[0] = landmark.x + acc[0];\n        acc[1] = landmark.y + acc[1];\n        acc[2] = landmark.z + acc[2];\n        return acc;\n    }, [0, 0, 0]);\n    return sum.map(coord => coord / landmarks.length);\n}\n\nconst faceLandmarker = await FaceLandmarker.createFromOptions(filesetResolver, {\n    baseOptions: {\n        modelAssetPath: \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task\",\n        delegate: \"GPU\"\n    },\n    outputFaceBlendshapes: true,\n    runningMode: \"IMAGE\",\n    numFaces: 1\n});\n\n\nconst visionLine = 0.5;\nconst threshold = 0.2;\n\ncaptureStream().pipe(\n  throttleTime(1000),\n  map(({message: img}) => {\n    const [x,y,z] = calculateCentroid(faceLandmarker.detect(img).faceLandmarks[0]);\n    const distance = visionLine-x;\n    const relativeDistance = Math.abs(distance)/x;\n    return relativeDistance <= threshold ? \"NONE\" : distance > 0 ? \"l\" : \"r\";\n  }),\n  rewrite()\n)",
                      "language": "javascript",
                      "output": "NONEUncaught TypeError: Cannot read properties of undefined (reading 'reduce')\n"
                    },
                    "index": 1,
                    "lastEditedBy": "f313b510-8ff6-4ef7-8c27-070c2ae45fc1",
                    "_deleted": false
                  }
                }
              }
            ],
            "creator": "pkhexmkwbs",
            "time": 1684303102053.02
          }
        ],
        [
          {
            "body": [
              {
                "ifMatch": {
                  "$set": {
                    "data": {
                      "code": "import {\n    FaceLandmarker,\n    FilesetResolver,\n    DrawingUtils\n} from \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0\";\n\nconst filesetResolver = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm\"\n);\n\nfunction calculateCentroid(landmarks) {\n    const sum = landmarks.reduce((acc, landmark) => {\n        acc[0] = landmark.x + acc[0];\n        acc[1] = landmark.y + acc[1];\n        acc[2] = landmark.z + acc[2];\n        return acc;\n    }, [0, 0, 0]);\n    return sum.map(coord => coord / landmarks.length);\n}\n\nconst faceLandmarker = await FaceLandmarker.createFromOptions(filesetResolver, {\n    baseOptions: {\n        modelAssetPath: \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task\",\n        delegate: \"GPU\"\n    },\n    outputFaceBlendshapes: true,\n    runningMode: \"IMAGE\",\n    numFaces: 1\n});\n\n\nconst visionLine = 0.5;\nconst threshold = 0.2;\n\ncaptureStream().pipe(\n  throttleTime(1000),\n  map(({message: img}) => {\n    faceLandmarker.detect(img);\n    const [x,y,z] = calculateCentroid(faceLandmarker.detect(img).faceLandmarks[0]);\n    const distance = visionLine-x;\n    const relativeDistance = Math.abs(distance)/x;\n    return relativeDistance <= threshold ? \"NONE\" : distance > 0 ? \"l\" : \"r\";\n  }),\n  rewrite()\n)",
                      "language": "javascript",
                      "output": "NONEUncaught TypeError: Cannot read properties of undefined (reading 'reduce')\n"
                    },
                    "index": 1,
                    "lastEditedBy": "f313b510-8ff6-4ef7-8c27-070c2ae45fc1",
                    "_deleted": false
                  }
                }
              }
            ],
            "creator": "pkhexmkwbs",
            "time": 1684303106904.02
          }
        ],
        [
          {
            "body": [
              {
                "ifMatch": {
                  "$set": {
                    "data": {
                      "code": "import {\n    FaceLandmarker,\n    FilesetResolver,\n    DrawingUtils\n} from \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0\";\n\nconst filesetResolver = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm\"\n);\n\nfunction calculateCentroid(landmarks) {\n    const sum = landmarks.reduce((acc, landmark) => {\n        acc[0] = landmark.x + acc[0];\n        acc[1] = landmark.y + acc[1];\n        acc[2] = landmark.z + acc[2];\n        return acc;\n    }, [0, 0, 0]);\n    return sum.map(coord => coord / landmarks.length);\n}\n\nconst faceLandmarker = await FaceLandmarker.createFromOptions(filesetResolver, {\n    baseOptions: {\n        modelAssetPath: \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task\",\n        delegate: \"GPU\"\n    },\n    outputFaceBlendshapes: true,\n    runningMode: \"IMAGE\",\n    numFaces: 1\n});\n\n\nconst visionLine = 0.5;\nconst threshold = 0.2;\n\ncaptureStream().pipe(\n  throttleTime(1000),\n  map(({message: img}) => {\n    const faceLandmarker.detect(img);\n    const [x,y,z] = calculateCentroid(faceLandmarker.detect(img).faceLandmarks[0]);\n    const distance = visionLine-x;\n    const relativeDistance = Math.abs(distance)/x;\n    return relativeDistance <= threshold ? \"NONE\" : distance > 0 ? \"l\" : \"r\";\n  }),\n  rewrite()\n)",
                      "language": "javascript",
                      "output": "NONEUncaught TypeError: Cannot read properties of undefined (reading 'reduce')\n"
                    },
                    "index": 1,
                    "lastEditedBy": "f313b510-8ff6-4ef7-8c27-070c2ae45fc1",
                    "_deleted": false
                  }
                }
              }
            ],
            "creator": "pkhexmkwbs",
            "time": 1684303108813.01
          }
        ],
        [
          {
            "body": [
              {
                "ifMatch": {
                  "$set": {
                    "data": {
                      "code": "import {\n    FaceLandmarker,\n    FilesetResolver,\n    DrawingUtils\n} from \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0\";\n\nconst filesetResolver = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm\"\n);\n\nfunction calculateCentroid(landmarks) {\n    const sum = landmarks.reduce((acc, landmark) => {\n        acc[0] = landmark.x + acc[0];\n        acc[1] = landmark.y + acc[1];\n        acc[2] = landmark.z + acc[2];\n        return acc;\n    }, [0, 0, 0]);\n    return sum.map(coord => coord / landmarks.length);\n}\n\nconst faceLandmarker = await FaceLandmarker.createFromOptions(filesetResolver, {\n    baseOptions: {\n        modelAssetPath: \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task\",\n        delegate: \"GPU\"\n    },\n    outputFaceBlendshapes: true,\n    runningMode: \"IMAGE\",\n    numFaces: 1\n});\n\n\nconst visionLine = 0.5;\nconst threshold = 0.2;\n\ncaptureStream().pipe(\n  throttleTime(1000),\n  map(({message: img}) => {\n    const lanfaceLandmarker.detect(img);\n    const [x,y,z] = calculateCentroid(faceLandmarker.detect(img).faceLandmarks[0]);\n    const distance = visionLine-x;\n    const relativeDistance = Math.abs(distance)/x;\n    return relativeDistance <= threshold ? \"NONE\" : distance > 0 ? \"l\" : \"r\";\n  }),\n  rewrite()\n)",
                      "language": "javascript",
                      "output": "NONEUncaught TypeError: Cannot read properties of undefined (reading 'reduce')\n"
                    },
                    "index": 1,
                    "lastEditedBy": "f313b510-8ff6-4ef7-8c27-070c2ae45fc1",
                    "_deleted": false
                  }
                }
              }
            ],
            "creator": "pkhexmkwbs",
            "time": 1684303109845.05
          }
        ],
        [
          {
            "body": [
              {
                "ifMatch": {
                  "$set": {
                    "data": {
                      "code": "import {\n    FaceLandmarker,\n    FilesetResolver,\n    DrawingUtils\n} from \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0\";\n\nconst filesetResolver = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm\"\n);\n\nfunction calculateCentroid(landmarks) {\n    const sum = landmarks.reduce((acc, landmark) => {\n        acc[0] = landmark.x + acc[0];\n        acc[1] = landmark.y + acc[1];\n        acc[2] = landmark.z + acc[2];\n        return acc;\n    }, [0, 0, 0]);\n    return sum.map(coord => coord / landmarks.length);\n}\n\nconst faceLandmarker = await FaceLandmarker.createFromOptions(filesetResolver, {\n    baseOptions: {\n        modelAssetPath: \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task\",\n        delegate: \"GPU\"\n    },\n    outputFaceBlendshapes: true,\n    runningMode: \"IMAGE\",\n    numFaces: 1\n});\n\n\nconst visionLine = 0.5;\nconst threshold = 0.2;\n\ncaptureStream().pipe(\n  throttleTime(1000),\n  map(({message: img}) => {\n    const landmarks = faceLandmarker.detect(img);\n    const [x,y,z] = calculateCentroid(faceLandmarker.detect(img).faceLandmarks[0]);\n    const distance = visionLine-x;\n    const relativeDistance = Math.abs(distance)/x;\n    return relativeDistance <= threshold ? \"NONE\" : distance > 0 ? \"l\" : \"r\";\n  }),\n  rewrite()\n)",
                      "language": "javascript",
                      "output": "NONEUncaught TypeError: Cannot read properties of undefined (reading 'reduce')\n"
                    },
                    "index": 1,
                    "lastEditedBy": "f313b510-8ff6-4ef7-8c27-070c2ae45fc1",
                    "_deleted": false
                  }
                }
              }
            ],
            "creator": "pkhexmkwbs",
            "time": 1684303111675.06
          }
        ],
        [
          {
            "body": [
              {
                "ifMatch": {
                  "$set": {
                    "data": {
                      "code": "import {\n    FaceLandmarker,\n    FilesetResolver,\n    DrawingUtils\n} from \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0\";\n\nconst filesetResolver = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm\"\n);\n\nfunction calculateCentroid(landmarks) {\n    const sum = landmarks.reduce((acc, landmark) => {\n        acc[0] = landmark.x + acc[0];\n        acc[1] = landmark.y + acc[1];\n        acc[2] = landmark.z + acc[2];\n        return acc;\n    }, [0, 0, 0]);\n    return sum.map(coord => coord / landmarks.length);\n}\n\nconst faceLandmarker = await FaceLandmarker.createFromOptions(filesetResolver, {\n    baseOptions: {\n        modelAssetPath: \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task\",\n        delegate: \"GPU\"\n    },\n    outputFaceBlendshapes: true,\n    runningMode: \"IMAGE\",\n    numFaces: 1\n});\n\n\nconst visionLine = 0.5;\nconst threshold = 0.2;\n\ncaptureStream().pipe(\n  throttleTime(1000),\n  map(({message: img}) => {\n    const landmarks = faceLandmarker.detect(img);\n    const [x,y,z] = calculateCentroid(lan.faceLandmarks[0]);\n    const distance = visionLine-x;\n    const relativeDistance = Math.abs(distance)/x;\n    return relativeDistance <= threshold ? \"NONE\" : distance > 0 ? \"l\" : \"r\";\n  }),\n  rewrite()\n)",
                      "language": "javascript",
                      "output": "NONEUncaught TypeError: Cannot read properties of undefined (reading 'reduce')\n"
                    },
                    "index": 1,
                    "lastEditedBy": "f313b510-8ff6-4ef7-8c27-070c2ae45fc1",
                    "_deleted": false
                  }
                }
              }
            ],
            "creator": "pkhexmkwbs",
            "time": 1684303116682.01
          }
        ],
        [
          {
            "body": [
              {
                "ifMatch": {
                  "$set": {
                    "data": {
                      "code": "import {\n    FaceLandmarker,\n    FilesetResolver,\n    DrawingUtils\n} from \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0\";\n\nconst filesetResolver = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm\"\n);\n\nfunction calculateCentroid(landmarks) {\n    const sum = landmarks.reduce((acc, landmark) => {\n        acc[0] = landmark.x + acc[0];\n        acc[1] = landmark.y + acc[1];\n        acc[2] = landmark.z + acc[2];\n        return acc;\n    }, [0, 0, 0]);\n    return sum.map(coord => coord / landmarks.length);\n}\n\nconst faceLandmarker = await FaceLandmarker.createFromOptions(filesetResolver, {\n    baseOptions: {\n        modelAssetPath: \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task\",\n        delegate: \"GPU\"\n    },\n    outputFaceBlendshapes: true,\n    runningMode: \"IMAGE\",\n    numFaces: 1\n});\n\n\nconst visionLine = 0.5;\nconst threshold = 0.2;\n\ncaptureStream().pipe(\n  throttleTime(1000),\n  map(({message: img}) => {\n    const landmarks = faceLandmarker.detect(img);\n    const [x,y,z] = calculateCentroid(landmarks.faceLandmarks[0]);\n    const distance = visionLine-x;\n    const relativeDistance = Math.abs(distance)/x;\n    return relativeDistance <= threshold ? \"NONE\" : distance > 0 ? \"l\" : \"r\";\n  }),\n  rewrite()\n)",
                      "language": "javascript",
                      "output": "NONEUncaught TypeError: Cannot read properties of undefined (reading 'reduce')\n"
                    },
                    "index": 1,
                    "lastEditedBy": "f313b510-8ff6-4ef7-8c27-070c2ae45fc1",
                    "_deleted": false
                  }
                }
              }
            ],
            "creator": "pkhexmkwbs",
            "time": 1684303117248.01
          }
        ],
        [
          {
            "body": [
              {
                "ifMatch": {
                  "$set": {
                    "data": {
                      "code": "import {\n    FaceLandmarker,\n    FilesetResolver,\n    DrawingUtils\n} from \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0\";\n\nconst filesetResolver = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm\"\n);\n\nfunction calculateCentroid(landmarks) {\n    const sum = landmarks.reduce((acc, landmark) => {\n        acc[0] = landmark.x + acc[0];\n        acc[1] = landmark.y + acc[1];\n        acc[2] = landmark.z + acc[2];\n        return acc;\n    }, [0, 0, 0]);\n    return sum.map(coord => coord / landmarks.length);\n}\n\nconst faceLandmarker = await FaceLandmarker.createFromOptions(filesetResolver, {\n    baseOptions: {\n        modelAssetPath: \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task\",\n        delegate: \"GPU\"\n    },\n    outputFaceBlendshapes: true,\n    runningMode: \"IMAGE\",\n    numFaces: 1\n});\n\n\nconst visionLine = 0.5;\nconst threshold = 0.2;\n\ncaptureStream().pipe(\n  throttleTime(1000),\n  map(({message: img}) => {\n    const landmarks = faceLandmarker.detect(img);\n    console.log(land)\n    const [x,y,z] = calculateCentroid(landmarks.faceLandmarks[0]);\n    const distance = visionLine-x;\n    const relativeDistance = Math.abs(distance)/x;\n    return relativeDistance <= threshold ? \"NONE\" : distance > 0 ? \"l\" : \"r\";\n  }),\n  rewrite()\n)",
                      "language": "javascript",
                      "output": "NONEUncaught TypeError: Cannot read properties of undefined (reading 'reduce')\n"
                    },
                    "index": 1,
                    "lastEditedBy": "f313b510-8ff6-4ef7-8c27-070c2ae45fc1",
                    "_deleted": false
                  }
                }
              }
            ],
            "creator": "pkhexmkwbs",
            "time": 1684303120952.06
          }
        ],
        [
          {
            "body": [
              {
                "ifMatch": {
                  "$set": {
                    "data": {
                      "code": "import {\n    FaceLandmarker,\n    FilesetResolver,\n    DrawingUtils\n} from \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0\";\n\nconst filesetResolver = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm\"\n);\n\nfunction calculateCentroid(landmarks) {\n    const sum = landmarks.reduce((acc, landmark) => {\n        acc[0] = landmark.x + acc[0];\n        acc[1] = landmark.y + acc[1];\n        acc[2] = landmark.z + acc[2];\n        return acc;\n    }, [0, 0, 0]);\n    return sum.map(coord => coord / landmarks.length);\n}\n\nconst faceLandmarker = await FaceLandmarker.createFromOptions(filesetResolver, {\n    baseOptions: {\n        modelAssetPath: \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task\",\n        delegate: \"GPU\"\n    },\n    outputFaceBlendshapes: true,\n    runningMode: \"IMAGE\",\n    numFaces: 1\n});\n\n\nconst visionLine = 0.5;\nconst threshold = 0.2;\n\ncaptureStream().pipe(\n  throttleTime(1000),\n  map(({message: img}) => {\n    const landmarks = faceLandmarker.detect(img);\n    console.log(landmarks\n               )\n    const [x,y,z] = calculateCentroid(landmarks.faceLandmarks[0]);\n    const distance = visionLine-x;\n    const relativeDistance = Math.abs(distance)/x;\n    return relativeDistance <= threshold ? \"NONE\" : distance > 0 ? \"l\" : \"r\";\n  }),\n  rewrite()\n)",
                      "language": "javascript",
                      "output": "NONEUncaught TypeError: Cannot read properties of undefined (reading 'reduce')\n"
                    },
                    "index": 1,
                    "lastEditedBy": "f313b510-8ff6-4ef7-8c27-070c2ae45fc1",
                    "_deleted": false
                  }
                }
              }
            ],
            "creator": "pkhexmkwbs",
            "time": 1684303121641.06
          }
        ],
        [
          {
            "body": [
              {
                "ifMatch": {
                  "$set": {
                    "data": {
                      "code": "import {\n    FaceLandmarker,\n    FilesetResolver,\n    DrawingUtils\n} from \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0\";\n\nconst filesetResolver = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm\"\n);\n\nfunction calculateCentroid(landmarks) {\n    const sum = landmarks.reduce((acc, landmark) => {\n        acc[0] = landmark.x + acc[0];\n        acc[1] = landmark.y + acc[1];\n        acc[2] = landmark.z + acc[2];\n        return acc;\n    }, [0, 0, 0]);\n    return sum.map(coord => coord / landmarks.length);\n}\n\nconst faceLandmarker = await FaceLandmarker.createFromOptions(filesetResolver, {\n    baseOptions: {\n        modelAssetPath: \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task\",\n        delegate: \"GPU\"\n    },\n    outputFaceBlendshapes: true,\n    runningMode: \"IMAGE\",\n    numFaces: 1\n});\n\n\nconst visionLine = 0.5;\nconst threshold = 0.2;\n\ncaptureStream().pipe(\n  throttleTime(1000),\n  map(({message: img}) => {\n    const landmarks = faceLandmarker.detect(img);\n    console.log(landmarks)\n    const [x,y,z] = calculateCentroid(landmarks.faceLandmarks[0]);\n    const distance = visionLine-x;\n    const relativeDistance = Math.abs(distance)/x;\n    return relativeDistance <= threshold ? \"NONE\" : distance > 0 ? \"l\" : \"r\";\n  }),\n  rewrite()\n)",
                      "language": "javascript",
                      "output": "NONEUncaught TypeError: Cannot read properties of undefined (reading 'reduce')\n"
                    },
                    "index": 1,
                    "lastEditedBy": "f313b510-8ff6-4ef7-8c27-070c2ae45fc1",
                    "_deleted": false
                  }
                }
              }
            ],
            "creator": "pkhexmkwbs",
            "time": 1684303122514.01
          }
        ],
        [
          {
            "body": [
              {
                "ifMatch": {
                  "$set": {
                    "data": {
                      "code": "import {\n    FaceLandmarker,\n    FilesetResolver,\n    DrawingUtils\n} from \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0\";\n\nconst filesetResolver = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm\"\n);\n\nfunction calculateCentroid(landmarks) {\n    const sum = landmarks.reduce((acc, landmark) => {\n        acc[0] = landmark.x + acc[0];\n        acc[1] = landmark.y + acc[1];\n        acc[2] = landmark.z + acc[2];\n        return acc;\n    }, [0, 0, 0]);\n    return sum.map(coord => coord / landmarks.length);\n}\n\nconst faceLandmarker = await FaceLandmarker.createFromOptions(filesetResolver, {\n    baseOptions: {\n        modelAssetPath: \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task\",\n        delegate: \"GPU\"\n    },\n    outputFaceBlendshapes: true,\n    runningMode: \"IMAGE\",\n    numFaces: 1\n});\n\n\nconst visionLine = 0.5;\nconst threshold = 0.2;\n\ncaptureStream().pipe(\n  throttleTime(1000),\n  map(({message: img}) => {\n    const landmarks = faceLandmarker.detect(img);\n    console.log(landmarks);\n    const [x,y,z] = calculateCentroid(landmarks.faceLandmarks[0]);\n    const distance = visionLine-x;\n    const relativeDistance = Math.abs(distance)/x;\n    return relativeDistance <= threshold ? \"NONE\" : distance > 0 ? \"l\" : \"r\";\n  }),\n  rewrite()\n)",
                      "language": "javascript",
                      "output": "NONEUncaught TypeError: Cannot read properties of undefined (reading 'reduce')\n"
                    },
                    "index": 1,
                    "lastEditedBy": "f313b510-8ff6-4ef7-8c27-070c2ae45fc1",
                    "_deleted": false
                  }
                }
              }
            ],
            "creator": "pkhexmkwbs",
            "time": 1684303123645.01
          }
        ],
        [
          {
            "body": [
              {
                "ifMatch": {
                  "$set": {
                    "data": {
                      "code": "import {\n    FaceLandmarker,\n    FilesetResolver,\n    DrawingUtils\n} from \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0\";\n\nconst filesetResolver = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm\"\n);\n\nfunction calculateCentroid(landmarks) {\n    const sum = landmarks.reduce((acc, landmark) => {\n        acc[0] = landmark.x + acc[0];\n        acc[1] = landmark.y + acc[1];\n        acc[2] = landmark.z + acc[2];\n        return acc;\n    }, [0, 0, 0]);\n    return sum.map(coord => coord / landmarks.length);\n}\n\nconst faceLandmarker = await FaceLandmarker.createFromOptions(filesetResolver, {\n    baseOptions: {\n        modelAssetPath: \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task\",\n        delegate: \"GPU\"\n    },\n    outputFaceBlendshapes: true,\n    runningMode: \"IMAGE\",\n    numFaces: 1\n});\n\n\nconst visionLine = 0.5;\nconst threshold = 0.2;\n\ncaptureStream().pipe(\n  throttleTime(1000),\n  map(({message: img}) => {\n    const landmarks = faceLandmarker.detect(img);\n    console.log(landmarks);\n    const [x,y,z] = calculateCentroid(landmarks.faceLandmarks[0]);\n    const distance = visionLine-x;\n    const relativeDistance = Math.abs(distance)/x;\n    return relativeDistance <= threshold ? \"NONE\" : distance > 0 ? \"l\" : \"r\";\n  }),\n  rewrite()\n)",
                      "language": "javascript",
                      "output": ""
                    },
                    "index": 1,
                    "lastEditedBy": "f313b510-8ff6-4ef7-8c27-070c2ae45fc1",
                    "_deleted": false
                  }
                }
              }
            ],
            "creator": "pkhexmkwbs",
            "time": 1684303131634.01
          }
        ],
        [
          {
            "body": [
              {
                "ifMatch": {
                  "$set": {
                    "data": {
                      "code": "import {\n    FaceLandmarker,\n    FilesetResolver,\n    DrawingUtils\n} from \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0\";\n\nconst filesetResolver = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm\"\n);\n\nfunction calculateCentroid(landmarks) {\n    const sum = landmarks.reduce((acc, landmark) => {\n        acc[0] = landmark.x + acc[0];\n        acc[1] = landmark.y + acc[1];\n        acc[2] = landmark.z + acc[2];\n        return acc;\n    }, [0, 0, 0]);\n    return sum.map(coord => coord / landmarks.length);\n}\n\nconst faceLandmarker = await FaceLandmarker.createFromOptions(filesetResolver, {\n    baseOptions: {\n        modelAssetPath: \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task\",\n        delegate: \"GPU\"\n    },\n    outputFaceBlendshapes: true,\n    runningMode: \"IMAGE\",\n    numFaces: 1\n});\n\n\nconst visionLine = 0.5;\nconst threshold = 0.2;\n\ncaptureStream().pipe(\n  throttleTime(1000),\n  map(({message: img}) => {\n    const landmarks = faceLandmarker.detect(img);\n    console.log(landmarks);\n    const [x,y,z] = calculateCentroid(landmarks.faceLandmarks[0]);\n    const distance = visionLine-x;\n    const relativeDistance = Math.abs(distance)/x;\n    return relativeDistance <= threshold ? \"NONE\" : distance > 0 ? \"l\" : \"r\";\n  }),\n  rewrite()\n)",
                      "language": "javascript",
                      "output": "Uncaught TypeError: Cannot read properties of undefined (reading 'reduce')\n"
                    },
                    "index": 1,
                    "lastEditedBy": "f313b510-8ff6-4ef7-8c27-070c2ae45fc1",
                    "_deleted": false
                  }
                }
              }
            ],
            "creator": "pkhexmkwbs",
            "time": 1684303133648.01
          }
        ],
        [
          {
            "body": [
              {
                "ifMatch": {
                  "$set": {
                    "data": {
                      "code": "import {\n    FaceLandmarker,\n    FilesetResolver,\n    DrawingUtils\n} from \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0\";\n\nconst filesetResolver = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm\"\n);\n\nfunction calculateCentroid(landmarks) {\n    const sum = landmarks.reduce((acc, landmark) => {\n        acc[0] = landmark.x + acc[0];\n        acc[1] = landmark.y + acc[1];\n        acc[2] = landmark.z + acc[2];\n        return acc;\n    }, [0, 0, 0]);\n    return sum.map(coord => coord / landmarks.length);\n}\n\nconst faceLandmarker = await FaceLandmarker.createFromOptions(filesetResolver, {\n    baseOptions: {\n        modelAssetPath: \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task\",\n        delegate: \"GPU\"\n    },\n    outputFaceBlendshapes: true,\n    runningMode: \"IMAGE\",\n    numFaces: 1\n});\n\n\nconst visionLine = 0.5;\nconst threshold = 0.2;\n\ncaptureStream().pipe(\n  throttleTime(1000),\n  map(({message: img}) => {\n    const landmarks = faceLandmarker.detect(img);\n    \n    const [x,y,z] = calculateCentroid(landmarks.faceLandmarks[0]);\n    const distance = visionLine-x;\n    const relativeDistance = Math.abs(distance)/x;\n    return relativeDistance <= threshold ? \"NONE\" : distance > 0 ? \"l\" : \"r\";\n  }),\n  rewrite()\n)",
                      "language": "javascript",
                      "output": "Uncaught TypeError: Cannot read properties of undefined (reading 'reduce')\n"
                    },
                    "index": 1,
                    "lastEditedBy": "f313b510-8ff6-4ef7-8c27-070c2ae45fc1",
                    "_deleted": false
                  }
                }
              }
            ],
            "creator": "pkhexmkwbs",
            "time": 1684303141543.01
          }
        ],
        [
          {
            "body": [
              {
                "ifMatch": {
                  "$set": {
                    "data": {
                      "code": "import {\n    FaceLandmarker,\n    FilesetResolver,\n    DrawingUtils\n} from \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0\";\n\nconst filesetResolver = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm\"\n);\n\nfunction calculateCentroid(landmarks) {\n    const sum = landmarks.reduce((acc, landmark) => {\n        acc[0] = landmark.x + acc[0];\n        acc[1] = landmark.y + acc[1];\n        acc[2] = landmark.z + acc[2];\n        return acc;\n    }, [0, 0, 0]);\n    return sum.map(coord => coord / landmarks.length);\n}\n\nconst faceLandmarker = await FaceLandmarker.createFromOptions(filesetResolver, {\n    baseOptions: {\n        modelAssetPath: \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task\",\n        delegate: \"GPU\"\n    },\n    outputFaceBlendshapes: true,\n    runningMode: \"IMAGE\",\n    numFaces: 1\n});\n\n\nconst visionLine = 0.5;\nconst threshold = 0.2;\n\ncaptureStream().pipe(\n  throttleTime(1000),\n  map(({message: img}) => {\n    const landmarks = faceLandmarker.detect(img);\n    if \n    const [x,y,z] = calculateCentroid(landmarks.faceLandmarks[0]);\n    const distance = visionLine-x;\n    const relativeDistance = Math.abs(distance)/x;\n    return relativeDistance <= threshold ? \"NONE\" : distance > 0 ? \"l\" : \"r\";\n  }),\n  rewrite()\n)",
                      "language": "javascript",
                      "output": "Uncaught TypeError: Cannot read properties of undefined (reading 'reduce')\n"
                    },
                    "index": 1,
                    "lastEditedBy": "f313b510-8ff6-4ef7-8c27-070c2ae45fc1",
                    "_deleted": false
                  }
                }
              }
            ],
            "creator": "pkhexmkwbs",
            "time": 1684303142648.01
          }
        ],
        [
          {
            "body": [
              {
                "ifMatch": {
                  "$set": {
                    "data": {
                      "code": "import {\n    FaceLandmarker,\n    FilesetResolver,\n    DrawingUtils\n} from \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0\";\n\nconst filesetResolver = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm\"\n);\n\nfunction calculateCentroid(landmarks) {\n    const sum = landmarks.reduce((acc, landmark) => {\n        acc[0] = landmark.x + acc[0];\n        acc[1] = landmark.y + acc[1];\n        acc[2] = landmark.z + acc[2];\n        return acc;\n    }, [0, 0, 0]);\n    return sum.map(coord => coord / landmarks.length);\n}\n\nconst faceLandmarker = await FaceLandmarker.createFromOptions(filesetResolver, {\n    baseOptions: {\n        modelAssetPath: \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task\",\n        delegate: \"GPU\"\n    },\n    outputFaceBlendshapes: true,\n    runningMode: \"IMAGE\",\n    numFaces: 1\n});\n\n\nconst visionLine = 0.5;\nconst threshold = 0.2;\n\ncaptureStream().pipe(\n  throttleTime(1000),\n  map(({message: img}) => {\n    const landmarks = faceLandmarker.detect(img);\n    if (landmarks.)\n    const [x,y,z] = calculateCentroid(landmarks.faceLandmarks[0]);\n    const distance = visionLine-x;\n    const relativeDistance = Math.abs(distance)/x;\n    return relativeDistance <= threshold ? \"NONE\" : distance > 0 ? \"l\" : \"r\";\n  }),\n  rewrite()\n)",
                      "language": "javascript",
                      "output": "Uncaught TypeError: Cannot read properties of undefined (reading 'reduce')\n"
                    },
                    "index": 1,
                    "lastEditedBy": "f313b510-8ff6-4ef7-8c27-070c2ae45fc1",
                    "_deleted": false
                  }
                }
              }
            ],
            "creator": "pkhexmkwbs",
            "time": 1684303145757.05
          }
        ],
        [
          {
            "body": [
              {
                "ifMatch": {
                  "$set": {
                    "data": {
                      "code": "import {\n    FaceLandmarker,\n    FilesetResolver,\n    DrawingUtils\n} from \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0\";\n\nconst filesetResolver = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm\"\n);\n\nfunction calculateCentroid(landmarks) {\n    const sum = landmarks.reduce((acc, landmark) => {\n        acc[0] = landmark.x + acc[0];\n        acc[1] = landmark.y + acc[1];\n        acc[2] = landmark.z + acc[2];\n        return acc;\n    }, [0, 0, 0]);\n    return sum.map(coord => coord / landmarks.length);\n}\n\nconst faceLandmarker = await FaceLandmarker.createFromOptions(filesetResolver, {\n    baseOptions: {\n        modelAssetPath: \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task\",\n        delegate: \"GPU\"\n    },\n    outputFaceBlendshapes: true,\n    runningMode: \"IMAGE\",\n    numFaces: 1\n});\n\n\nconst visionLine = 0.5;\nconst threshold = 0.2;\n\ncaptureStream().pipe(\n  throttleTime(1000),\n  map(({message: img}) => {\n    const landmarks = faceLandmarker.detect(img).faceLandmarks;\n    if (landmarks.)\n    const [x,y,z] = calculateCentroid(landmarks.faceLandmarks[0]);\n    const distance = visionLine-x;\n    const relativeDistance = Math.abs(distance)/x;\n    return relativeDistance <= threshold ? \"NONE\" : distance > 0 ? \"l\" : \"r\";\n  }),\n  rewrite()\n)",
                      "language": "javascript",
                      "output": "Uncaught TypeError: Cannot read properties of undefined (reading 'reduce')\n"
                    },
                    "index": 1,
                    "lastEditedBy": "f313b510-8ff6-4ef7-8c27-070c2ae45fc1",
                    "_deleted": false
                  }
                }
              }
            ],
            "creator": "pkhexmkwbs",
            "time": 1684303157748.01
          }
        ],
        [
          {
            "body": [
              {
                "ifMatch": {
                  "$set": {
                    "data": {
                      "code": "import {\n    FaceLandmarker,\n    FilesetResolver,\n    DrawingUtils\n} from \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0\";\n\nconst filesetResolver = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm\"\n);\n\nfunction calculateCentroid(landmarks) {\n    const sum = landmarks.reduce((acc, landmark) => {\n        acc[0] = landmark.x + acc[0];\n        acc[1] = landmark.y + acc[1];\n        acc[2] = landmark.z + acc[2];\n        return acc;\n    }, [0, 0, 0]);\n    return sum.map(coord => coord / landmarks.length);\n}\n\nconst faceLandmarker = await FaceLandmarker.createFromOptions(filesetResolver, {\n    baseOptions: {\n        modelAssetPath: \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task\",\n        delegate: \"GPU\"\n    },\n    outputFaceBlendshapes: true,\n    runningMode: \"IMAGE\",\n    numFaces: 1\n});\n\n\nconst visionLine = 0.5;\nconst threshold = 0.2;\n\ncaptureStream().pipe(\n  throttleTime(1000),\n  map(({message: img}) => {\n    const landmarks = faceLandmarker.detect(img).faceLandmarks;\n    if (landmarks.)\n    const [x,y,z] = calculateCentroid(landmarks.faceLandmark[0]);\n    const distance = visionLine-x;\n    const relativeDistance = Math.abs(distance)/x;\n    return relativeDistance <= threshold ? \"NONE\" : distance > 0 ? \"l\" : \"r\";\n  }),\n  rewrite()\n)",
                      "language": "javascript",
                      "output": "Uncaught TypeError: Cannot read properties of undefined (reading 'reduce')\n"
                    },
                    "index": 1,
                    "lastEditedBy": "f313b510-8ff6-4ef7-8c27-070c2ae45fc1",
                    "_deleted": false
                  }
                }
              }
            ],
            "creator": "pkhexmkwbs",
            "time": 1684303160572.01
          }
        ],
        [
          {
            "body": [
              {
                "ifMatch": {
                  "$set": {
                    "data": {
                      "code": "import {\n    FaceLandmarker,\n    FilesetResolver,\n    DrawingUtils\n} from \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0\";\n\nconst filesetResolver = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm\"\n);\n\nfunction calculateCentroid(landmarks) {\n    const sum = landmarks.reduce((acc, landmark) => {\n        acc[0] = landmark.x + acc[0];\n        acc[1] = landmark.y + acc[1];\n        acc[2] = landmark.z + acc[2];\n        return acc;\n    }, [0, 0, 0]);\n    return sum.map(coord => coord / landmarks.length);\n}\n\nconst faceLandmarker = await FaceLandmarker.createFromOptions(filesetResolver, {\n    baseOptions: {\n        modelAssetPath: \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task\",\n        delegate: \"GPU\"\n    },\n    outputFaceBlendshapes: true,\n    runningMode: \"IMAGE\",\n    numFaces: 1\n});\n\n\nconst visionLine = 0.5;\nconst threshold = 0.2;\n\ncaptureStream().pipe(\n  throttleTime(1000),\n  map(({message: img}) => {\n    const landmarks = faceLandmarker.detect(img).faceLandmarks;\n    if (landmarks.)\n    const [x,y,z] = calculateCentroid(landmarks[0]);\n    const distance = visionLine-x;\n    const relativeDistance = Math.abs(distance)/x;\n    return relativeDistance <= threshold ? \"NONE\" : distance > 0 ? \"l\" : \"r\";\n  }),\n  rewrite()\n)",
                      "language": "javascript",
                      "output": "Uncaught TypeError: Cannot read properties of undefined (reading 'reduce')\n"
                    },
                    "index": 1,
                    "lastEditedBy": "f313b510-8ff6-4ef7-8c27-070c2ae45fc1",
                    "_deleted": false
                  }
                }
              }
            ],
            "creator": "pkhexmkwbs",
            "time": 1684303161432.01
          }
        ],
        [
          {
            "body": [
              {
                "ifMatch": {
                  "$set": {
                    "data": {
                      "code": "import {\n    FaceLandmarker,\n    FilesetResolver,\n    DrawingUtils\n} from \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0\";\n\nconst filesetResolver = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm\"\n);\n\nfunction calculateCentroid(landmarks) {\n    const sum = landmarks.reduce((acc, landmark) => {\n        acc[0] = landmark.x + acc[0];\n        acc[1] = landmark.y + acc[1];\n        acc[2] = landmark.z + acc[2];\n        return acc;\n    }, [0, 0, 0]);\n    return sum.map(coord => coord / landmarks.length);\n}\n\nconst faceLandmarker = await FaceLandmarker.createFromOptions(filesetResolver, {\n    baseOptions: {\n        modelAssetPath: \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task\",\n        delegate: \"GPU\"\n    },\n    outputFaceBlendshapes: true,\n    runningMode: \"IMAGE\",\n    numFaces: 1\n});\n\n\nconst visionLine = 0.5;\nconst threshold = 0.2;\n\ncaptureStream().pipe(\n  throttleTime(1000),\n  map(({message: img}) => {\n    const landmarks = faceLandmarker.detect(img).faceLandmarks;\n    if (landmarks.)\n    const [x,y,z] = calculateCentroid(faceLandmarks[0]);\n    const distance = visionLine-x;\n    const relativeDistance = Math.abs(distance)/x;\n    return relativeDistance <= threshold ? \"NONE\" : distance > 0 ? \"l\" : \"r\";\n  }),\n  rewrite()\n)",
                      "language": "javascript",
                      "output": "Uncaught TypeError: Cannot read properties of undefined (reading 'reduce')\n"
                    },
                    "index": 1,
                    "lastEditedBy": "f313b510-8ff6-4ef7-8c27-070c2ae45fc1",
                    "_deleted": false
                  }
                }
              }
            ],
            "creator": "pkhexmkwbs",
            "time": 1684303165284.01
          }
        ],
        [
          {
            "body": [
              {
                "ifMatch": {
                  "$set": {
                    "data": {
                      "code": "import {\n    FaceLandmarker,\n    FilesetResolver,\n    DrawingUtils\n} from \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0\";\n\nconst filesetResolver = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm\"\n);\n\nfunction calculateCentroid(landmarks) {\n    const sum = landmarks.reduce((acc, landmark) => {\n        acc[0] = landmark.x + acc[0];\n        acc[1] = landmark.y + acc[1];\n        acc[2] = landmark.z + acc[2];\n        return acc;\n    }, [0, 0, 0]);\n    return sum.map(coord => coord / landmarks.length);\n}\n\nconst faceLandmarker = await FaceLandmarker.createFromOptions(filesetResolver, {\n    baseOptions: {\n        modelAssetPath: \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task\",\n        delegate: \"GPU\"\n    },\n    outputFaceBlendshapes: true,\n    runningMode: \"IMAGE\",\n    numFaces: 1\n});\n\n\nconst visionLine = 0.5;\nconst threshold = 0.2;\n\ncaptureStream().pipe(\n  throttleTime(1000),\n  map(({message: img}) => {\n    const landmarks = faceLandmarker.detect(img).faceLandmarks;\n    if (landmark.)\n    const [x,y,z] = calculateCentroid(faceLandmarks[0]);\n    const distance = visionLine-x;\n    const relativeDistance = Math.abs(distance)/x;\n    return relativeDistance <= threshold ? \"NONE\" : distance > 0 ? \"l\" : \"r\";\n  }),\n  rewrite()\n)",
                      "language": "javascript",
                      "output": "Uncaught TypeError: Cannot read properties of undefined (reading 'reduce')\n"
                    },
                    "index": 1,
                    "lastEditedBy": "f313b510-8ff6-4ef7-8c27-070c2ae45fc1",
                    "_deleted": false
                  }
                }
              }
            ],
            "creator": "pkhexmkwbs",
            "time": 1684303166920.01
          }
        ],
        [
          {
            "body": [
              {
                "ifMatch": {
                  "$set": {
                    "data": {
                      "code": "import {\n    FaceLandmarker,\n    FilesetResolver,\n    DrawingUtils\n} from \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0\";\n\nconst filesetResolver = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm\"\n);\n\nfunction calculateCentroid(landmarks) {\n    const sum = landmarks.reduce((acc, landmark) => {\n        acc[0] = landmark.x + acc[0];\n        acc[1] = landmark.y + acc[1];\n        acc[2] = landmark.z + acc[2];\n        return acc;\n    }, [0, 0, 0]);\n    return sum.map(coord => coord / landmarks.length);\n}\n\nconst faceLandmarker = await FaceLandmarker.createFromOptions(filesetResolver, {\n    baseOptions: {\n        modelAssetPath: \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task\",\n        delegate: \"GPU\"\n    },\n    outputFaceBlendshapes: true,\n    runningMode: \"IMAGE\",\n    numFaces: 1\n});\n\n\nconst visionLine = 0.5;\nconst threshold = 0.2;\n\ncaptureStream().pipe(\n  throttleTime(1000),\n  map(({message: img}) => {\n    const landmarks = faceLandmarker.detect(img).faceLandmarks;\n    if (faceLandmarks.)\n    const [x,y,z] = calculateCentroid(faceLandmarks[0]);\n    const distance = visionLine-x;\n    const relativeDistance = Math.abs(distance)/x;\n    return relativeDistance <= threshold ? \"NONE\" : distance > 0 ? \"l\" : \"r\";\n  }),\n  rewrite()\n)",
                      "language": "javascript",
                      "output": "Uncaught TypeError: Cannot read properties of undefined (reading 'reduce')\n"
                    },
                    "index": 1,
                    "lastEditedBy": "f313b510-8ff6-4ef7-8c27-070c2ae45fc1",
                    "_deleted": false
                  }
                }
              }
            ],
            "creator": "pkhexmkwbs",
            "time": 1684303168252.01
          }
        ],
        [
          {
            "body": [
              {
                "ifMatch": {
                  "$set": {
                    "data": {
                      "code": "import {\n    FaceLandmarker,\n    FilesetResolver,\n    DrawingUtils\n} from \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0\";\n\nconst filesetResolver = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm\"\n);\n\nfunction calculateCentroid(landmarks) {\n    const sum = landmarks.reduce((acc, landmark) => {\n        acc[0] = landmark.x + acc[0];\n        acc[1] = landmark.y + acc[1];\n        acc[2] = landmark.z + acc[2];\n        return acc;\n    }, [0, 0, 0]);\n    return sum.map(coord => coord / landmarks.length);\n}\n\nconst faceLandmarker = await FaceLandmarker.createFromOptions(filesetResolver, {\n    baseOptions: {\n        modelAssetPath: \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task\",\n        delegate: \"GPU\"\n    },\n    outputFaceBlendshapes: true,\n    runningMode: \"IMAGE\",\n    numFaces: 1\n});\n\n\nconst visionLine = 0.5;\nconst threshold = 0.2;\n\ncaptureStream().pipe(\n  throttleTime(1000),\n  map(({message: img}) => {\n    const landmarks = faceLandmarker.detect(img).faceLandmarks;\n    if (faceLandmarks.length === 0) {}\n    const [x,y,z] = calculateCentroid(faceLandmarks[0]);\n    const distance = visionLine-x;\n    const relativeDistance = Math.abs(distance)/x;\n    return relativeDistance <= threshold ? \"NONE\" : distance > 0 ? \"l\" : \"r\";\n  }),\n  rewrite()\n)",
                      "language": "javascript",
                      "output": "Uncaught TypeError: Cannot read properties of undefined (reading 'reduce')\n"
                    },
                    "index": 1,
                    "lastEditedBy": "f313b510-8ff6-4ef7-8c27-070c2ae45fc1",
                    "_deleted": false
                  }
                }
              }
            ],
            "creator": "pkhexmkwbs",
            "time": 1684303173252.01
          }
        ],
        [
          {
            "body": [
              {
                "ifMatch": {
                  "$set": {
                    "data": {
                      "code": "import {\n    FaceLandmarker,\n    FilesetResolver,\n    DrawingUtils\n} from \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0\";\n\nconst filesetResolver = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm\"\n);\n\nfunction calculateCentroid(landmarks) {\n    const sum = landmarks.reduce((acc, landmark) => {\n        acc[0] = landmark.x + acc[0];\n        acc[1] = landmark.y + acc[1];\n        acc[2] = landmark.z + acc[2];\n        return acc;\n    }, [0, 0, 0]);\n    return sum.map(coord => coord / landmarks.length);\n}\n\nconst faceLandmarker = await FaceLandmarker.createFromOptions(filesetResolver, {\n    baseOptions: {\n        modelAssetPath: \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task\",\n        delegate: \"GPU\"\n    },\n    outputFaceBlendshapes: true,\n    runningMode: \"IMAGE\",\n    numFaces: 1\n});\n\n\nconst visionLine = 0.5;\nconst threshold = 0.2;\n\ncaptureStream().pipe(\n  throttleTime(1000),\n  map(({message: img}) => {\n    const landmarks = faceLandmarker.detect(img).faceLandmarks;\n    if (faceLandmarks.length === 0)\n        return \"NONE\"\n    const [x,y,z] = calculateCentroid(faceLandmarks[0]);\n    const distance = visionLine-x;\n    const relativeDistance = Math.abs(distance)/x;\n    return relativeDistance <= threshold ? \"NONE\" : distance > 0 ? \"l\" : \"r\";\n  }),\n  rewrite()\n)",
                      "language": "javascript",
                      "output": "Uncaught TypeError: Cannot read properties of undefined (reading 'reduce')\n"
                    },
                    "index": 1,
                    "lastEditedBy": "f313b510-8ff6-4ef7-8c27-070c2ae45fc1",
                    "_deleted": false
                  }
                }
              }
            ],
            "creator": "pkhexmkwbs",
            "time": 1684303177585.05
          }
        ],
        [
          {
            "body": [
              {
                "ifMatch": {
                  "$set": {
                    "data": {
                      "code": "import {\n    FaceLandmarker,\n    FilesetResolver,\n    DrawingUtils\n} from \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0\";\n\nconst filesetResolver = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm\"\n);\n\nfunction calculateCentroid(landmarks) {\n    const sum = landmarks.reduce((acc, landmark) => {\n        acc[0] = landmark.x + acc[0];\n        acc[1] = landmark.y + acc[1];\n        acc[2] = landmark.z + acc[2];\n        return acc;\n    }, [0, 0, 0]);\n    return sum.map(coord => coord / landmarks.length);\n}\n\nconst faceLandmarker = await FaceLandmarker.createFromOptions(filesetResolver, {\n    baseOptions: {\n        modelAssetPath: \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task\",\n        delegate: \"GPU\"\n    },\n    outputFaceBlendshapes: true,\n    runningMode: \"IMAGE\",\n    numFaces: 1\n});\n\n\nconst visionLine = 0.5;\nconst threshold = 0.2;\n\ncaptureStream().pipe(\n  throttleTime(1000),\n  map(({message: img}) => {\n    const landmarks = faceLandmarker.detect(img).faceLandmarks;\n    if (faceLandmarks.length === 0)\n        return \"NONE\";\n    const [x,y,z] = calculateCentroid(faceLandmarks[0]);\n    const distance = visionLine-x;\n    const relativeDistance = Math.abs(distance)/x;\n    return relativeDistance <= threshold ? \"NONE\" : distance > 0 ? \"l\" : \"r\";\n  }),\n  rewrite()\n)",
                      "language": "javascript",
                      "output": ""
                    },
                    "index": 1,
                    "lastEditedBy": "f313b510-8ff6-4ef7-8c27-070c2ae45fc1",
                    "_deleted": false
                  }
                }
              }
            ],
            "creator": "pkhexmkwbs",
            "time": 1684303178925.01
          }
        ],
        [
          {
            "body": [
              {
                "ifMatch": {
                  "$set": {
                    "data": {
                      "code": "import {\n    FaceLandmarker,\n    FilesetResolver,\n    DrawingUtils\n} from \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0\";\n\nconst filesetResolver = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm\"\n);\n\nfunction calculateCentroid(landmarks) {\n    const sum = landmarks.reduce((acc, landmark) => {\n        acc[0] = landmark.x + acc[0];\n        acc[1] = landmark.y + acc[1];\n        acc[2] = landmark.z + acc[2];\n        return acc;\n    }, [0, 0, 0]);\n    return sum.map(coord => coord / landmarks.length);\n}\n\nconst faceLandmarker = await FaceLandmarker.createFromOptions(filesetResolver, {\n    baseOptions: {\n        modelAssetPath: \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task\",\n        delegate: \"GPU\"\n    },\n    outputFaceBlendshapes: true,\n    runningMode: \"IMAGE\",\n    numFaces: 1\n});\n\n\nconst visionLine = 0.5;\nconst threshold = 0.2;\n\ncaptureStream().pipe(\n  throttleTime(1000),\n  map(({message: img}) => {\n    const landmarks = faceLandmarker.detect(img).faceLandmarks;\n    if (faceLandmarks.length === 0)\n        return \"NONE\";\n    const [x,y,z] = calculateCentroid(faceLandmarks[0]);\n    const distance = visionLine-x;\n    const relativeDistance = Math.abs(distance)/x;\n    return relativeDistance <= threshold ? \"NONE\" : distance > 0 ? \"l\" : \"r\";\n  }),\n  rewrite()\n)",
                      "language": "javascript",
                      "output": "Uncaught ReferenceError: faceLandmarks is not defined\n"
                    },
                    "index": 1,
                    "lastEditedBy": "f313b510-8ff6-4ef7-8c27-070c2ae45fc1",
                    "_deleted": false
                  }
                }
              }
            ],
            "creator": "pkhexmkwbs",
            "time": 1684303180936.02
          }
        ],
        [
          {
            "body": [
              {
                "ifMatch": {
                  "$set": {
                    "data": {
                      "code": "import {\n    FaceLandmarker,\n    FilesetResolver,\n    DrawingUtils\n} from \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0\";\n\nconst filesetResolver = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm\"\n);\n\nfunction calculateCentroid(landmarks) {\n    const sum = landmarks.reduce((acc, landmark) => {\n        acc[0] = landmark.x + acc[0];\n        acc[1] = landmark.y + acc[1];\n        acc[2] = landmark.z + acc[2];\n        return acc;\n    }, [0, 0, 0]);\n    return sum.map(coord => coord / landmarks.length);\n}\n\nconst faceLandmarker = await FaceLandmarker.createFromOptions(filesetResolver, {\n    baseOptions: {\n        modelAssetPath: \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task\",\n        delegate: \"GPU\"\n    },\n    outputFaceBlendshapes: true,\n    runningMode: \"IMAGE\",\n    numFaces: 1\n});\n\n\nconst visionLine = 0.5;\nconst threshold = 0.2;\n\ncaptureStream().pipe(\n  throttleTime(1000),\n  map(({message: img}) => {\n    const landmarks = faceLandmarker.detect(img).faceLandmarks;\n    if (faceLandmarks.length === 0)\n        return \"NONE\";\n    const [x,y,z] = calculateCentroid(faceLandmarks[0]);\n    const distance = visionLine-x;\n    const relativeDistance = Math.abs(distance)/x;\n    return relativeDistance <= threshold ? \"NONE\" : distance > 0 ? \"l\" : \"r\";\n  }),\n  rewrite()\n)",
                      "language": "javascript",
                      "output": ""
                    },
                    "index": 1,
                    "lastEditedBy": "f313b510-8ff6-4ef7-8c27-070c2ae45fc1",
                    "_deleted": false
                  }
                }
              }
            ],
            "creator": "pkhexmkwbs",
            "time": 1684303185554.01
          }
        ],
        [
          {
            "body": [
              {
                "ifMatch": {
                  "$set": {
                    "data": {
                      "code": "import {\n    FaceLandmarker,\n    FilesetResolver,\n    DrawingUtils\n} from \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0\";\n\nconst filesetResolver = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm\"\n);\n\nfunction calculateCentroid(landmarks) {\n    const sum = landmarks.reduce((acc, landmark) => {\n        acc[0] = landmark.x + acc[0];\n        acc[1] = landmark.y + acc[1];\n        acc[2] = landmark.z + acc[2];\n        return acc;\n    }, [0, 0, 0]);\n    return sum.map(coord => coord / landmarks.length);\n}\n\nconst faceLandmarker = await FaceLandmarker.createFromOptions(filesetResolver, {\n    baseOptions: {\n        modelAssetPath: \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task\",\n        delegate: \"GPU\"\n    },\n    outputFaceBlendshapes: true,\n    runningMode: \"IMAGE\",\n    numFaces: 1\n});\n\n\nconst visionLine = 0.5;\nconst threshold = 0.2;\n\ncaptureStream().pipe(\n  throttleTime(1000),\n  map(({message: img}) => {\n    const landmarks = faceLandmarker.detect(img).faceLandmarks;\n    if (faceLandmarks.length === 0)\n        return \"NONE\";\n    const [x,y,z] = calculateCentroid(faceLandmarks[0]);\n    const distance = visionLine-x;\n    const relativeDistance = Math.abs(distance)/x;\n    return relativeDistance <= threshold ? \"NONE\" : distance > 0 ? \"l\" : \"r\";\n  }),\n  rewrite()\n)",
                      "language": "javascript",
                      "output": "Uncaught ReferenceError: faceLandmarks is not defined\n"
                    },
                    "index": 1,
                    "lastEditedBy": "f313b510-8ff6-4ef7-8c27-070c2ae45fc1",
                    "_deleted": false
                  }
                }
              }
            ],
            "creator": "pkhexmkwbs",
            "time": 1684303188213.01
          }
        ],
        [
          {
            "body": [
              {
                "ifMatch": {
                  "$set": {
                    "data": {
                      "code": "import {\n    FaceLandmarker,\n    FilesetResolver,\n    DrawingUtils\n} from \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0\";\n\nconst filesetResolver = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm\"\n);\n\nfunction calculateCentroid(landmarks) {\n    const sum = landmarks.reduce((acc, landmark) => {\n        acc[0] = landmark.x + acc[0];\n        acc[1] = landmark.y + acc[1];\n        acc[2] = landmark.z + acc[2];\n        return acc;\n    }, [0, 0, 0]);\n    return sum.map(coord => coord / landmarks.length);\n}\n\nconst faceLandmarker = await FaceLandmarker.createFromOptions(filesetResolver, {\n    baseOptions: {\n        modelAssetPath: \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task\",\n        delegate: \"GPU\"\n    },\n    outputFaceBlendshapes: true,\n    runningMode: \"IMAGE\",\n    numFaces: 1\n});\n\n\nconst visionLine = 0.5;\nconst threshold = 0.2;\n\ncaptureStream().pipe(\n  throttleTime(1000),faceLandmarksfaceLandmarks\n  map(({message: img}) => {\n    const landmarks = faceLandmarker.detect(img).faceLandmarks;\n    if (faceLandmarks.length === 0)\n        return \"NONE\";\n    const [x,y,z] = calculateCentroid(faceLandmarks[0]);\n    const distance = visionLine-x;\n    const relativeDistance = Math.abs(distance)/x;\n    return relativeDistance <= threshold ? \"NONE\" : distance > 0 ? \"l\" : \"r\";\n  }),\n  rewrite()\n)",
                      "language": "javascript",
                      "output": "Uncaught ReferenceError: faceLandmarks is not defined\n"
                    },
                    "index": 1,
                    "lastEditedBy": "f313b510-8ff6-4ef7-8c27-070c2ae45fc1",
                    "_deleted": false
                  }
                }
              }
            ],
            "creator": "pkhexmkwbs",
            "time": 1684303191919.01
          }
        ],
        [
          {
            "body": [
              {
                "ifMatch": {
                  "$set": {
                    "data": {
                      "code": "import {\n    FaceLandmarker,\n    FilesetResolver,\n    DrawingUtils\n} from \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0\";\n\nconst filesetResolver = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm\"\n);\n\nfunction calculateCentroid(landmarks) {\n    const sum = landmarks.reduce((acc, landmark) => {\n        acc[0] = landmark.x + acc[0];\n        acc[1] = landmark.y + acc[1];\n        acc[2] = landmark.z + acc[2];\n        return acc;\n    }, [0, 0, 0]);\n    return sum.map(coord => coord / landmarks.length);\n}\n\nconst faceLandmarker = await FaceLandmarker.createFromOptions(filesetResolver, {\n    baseOptions: {\n        modelAssetPath: \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task\",\n        delegate: \"GPU\"\n    },\n    outputFaceBlendshapes: true,\n    runningMode: \"IMAGE\",\n    numFaces: 1\n});\n\n\nconst visionLine = 0.5;\nconst threshold = 0.2;\n\ncaptureStream().pipe(\n  throttleTime(1000),\n  map(({message: img}) => {\n    const landmarks = faceLandmarker.detect(img).faceLandmarks;\n    if (faceLandmarks.length === 0)\n        return \"NONE\";\n    const [x,y,z] = calculateCentroid(faceLandmarks[0]);\n    const distance = visionLine-x;\n    const relativeDistance = Math.abs(distance)/x;\n    return relativeDistance <= threshold ? \"NONE\" : distance > 0 ? \"l\" : \"r\";\n  }),\n  rewrite()\n)",
                      "language": "javascript",
                      "output": "Uncaught ReferenceError: faceLandmarks is not defined\n"
                    },
                    "index": 1,
                    "lastEditedBy": "f313b510-8ff6-4ef7-8c27-070c2ae45fc1",
                    "_deleted": false
                  }
                }
              }
            ],
            "creator": "pkhexmkwbs",
            "time": 1684303193282.01
          }
        ],
        [
          {
            "body": [
              {
                "ifMatch": {
                  "$set": {
                    "data": {
                      "code": "import {\n    FaceLandmarker,\n    FilesetResolver,\n    DrawingUtils\n} from \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0\";\n\nconst filesetResolver = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm\"\n);\n\nfunction calculateCentroid(landmarks) {\n    const sum = landmarks.reduce((acc, landmark) => {\n        acc[0] = landmark.x + acc[0];\n        acc[1] = landmark.y + acc[1];\n        acc[2] = landmark.z + acc[2];\n        return acc;\n    }, [0, 0, 0]);\n    return sum.map(coord => coord / landmarks.length);\n}\n\nconst faceLandmarker = await FaceLandmarker.createFromOptions(filesetResolver, {\n    baseOptions: {\n        modelAssetPath: \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task\",\n        delegate: \"GPU\"\n    },\n    outputFaceBlendshapes: true,\n    runningMode: \"IMAGE\",\n    numFaces: 1\n});\n\n\nconst visionLine = 0.5;\nconst threshold = 0.2;\n\ncaptureStream().pipe(\n  throttleTime(1000),\n  map(({message: img}) => {\n    const faceLandmarks = faceLandmarker.detect(img).faceLandmarks;\n    if (faceLandmarks.length === 0)\n        return \"NONE\";\n    const [x,y,z] = calculateCentroid(faceLandmarks[0]);\n    const distance = visionLine-x;\n    const relativeDistance = Math.abs(distance)/x;\n    return relativeDistance <= threshold ? \"NONE\" : distance > 0 ? \"l\" : \"r\";\n  }),\n  rewrite()\n)",
                      "language": "javascript",
                      "output": "Uncaught ReferenceError: faceLandmarks is not defined\n"
                    },
                    "index": 1,
                    "lastEditedBy": "f313b510-8ff6-4ef7-8c27-070c2ae45fc1",
                    "_deleted": false
                  }
                }
              }
            ],
            "creator": "pkhexmkwbs",
            "time": 1684303194056.01
          }
        ],
        [
          {
            "body": [
              {
                "ifMatch": {
                  "$set": {
                    "data": {
                      "code": "import {\n    FaceLandmarker,\n    FilesetResolver,\n    DrawingUtils\n} from \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0\";\n\nconst filesetResolver = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm\"\n);\n\nfunction calculateCentroid(landmarks) {\n    const sum = landmarks.reduce((acc, landmark) => {\n        acc[0] = landmark.x + acc[0];\n        acc[1] = landmark.y + acc[1];\n        acc[2] = landmark.z + acc[2];\n        return acc;\n    }, [0, 0, 0]);\n    return sum.map(coord => coord / landmarks.length);\n}\n\nconst faceLandmarker = await FaceLandmarker.createFromOptions(filesetResolver, {\n    baseOptions: {\n        modelAssetPath: \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task\",\n        delegate: \"GPU\"\n    },\n    outputFaceBlendshapes: true,\n    runningMode: \"IMAGE\",\n    numFaces: 1\n});\n\n\nconst visionLine = 0.5;\nconst threshold = 0.2;\n\ncaptureStream().pipe(\n  throttleTime(1000),\n  map(({message: img}) => {\n    const faceLandmarks = faceLandmarker.detect(img).faceLandmarks;\n    if (faceLandmarks.length === 0)\n        return \"NONE\";\n    const [x,y,z] = calculateCentroid(faceLandmarks[0]);\n    const distance = visionLine-x;\n    const relativeDistance = Math.abs(distance)/x;\n    return relativeDistance <= threshold ? \"NONE\" : distance > 0 ? \"l\" : \"r\";\n  }),\n  rewrite()\n)",
                      "language": "javascript",
                      "output": ""
                    },
                    "index": 1,
                    "lastEditedBy": "f313b510-8ff6-4ef7-8c27-070c2ae45fc1",
                    "_deleted": false
                  }
                }
              }
            ],
            "creator": "pkhexmkwbs",
            "time": 1684303195331.01
          }
        ],
        [
          {
            "body": [
              {
                "ifMatch": {
                  "$set": {
                    "data": {
                      "code": "import {\n    FaceLandmarker,\n    FilesetResolver,\n    DrawingUtils\n} from \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0\";\n\nconst filesetResolver = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm\"\n);\n\nfunction calculateCentroid(landmarks) {\n    const sum = landmarks.reduce((acc, landmark) => {\n        acc[0] = landmark.x + acc[0];\n        acc[1] = landmark.y + acc[1];\n        acc[2] = landmark.z + acc[2];\n        return acc;\n    }, [0, 0, 0]);\n    return sum.map(coord => coord / landmarks.length);\n}\n\nconst faceLandmarker = await FaceLandmarker.createFromOptions(filesetResolver, {\n    baseOptions: {\n        modelAssetPath: \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task\",\n        delegate: \"GPU\"\n    },\n    outputFaceBlendshapes: true,\n    runningMode: \"IMAGE\",\n    numFaces: 1\n});\n\n\nconst visionLine = 0.5;\nconst threshold = 0.2;\n\ncaptureStream().pipe(\n  throttleTime(1000),\n  map(({message: img}) => {\n    const faceLandmarks = faceLandmarker.detect(img).faceLandmarks;\n    if (faceLandmarks.length === 0)\n        return \"NONE\";\n    const [x,y,z] = calculateCentroid(faceLandmarks[0]);\n    const distance = visionLine-x;\n    const relativeDistance = Math.abs(distance)/x;\n    return relativeDistance <= threshold ? \"NONE\" : distance > 0 ? \"l\" : \"r\";\n  }),\n  rewrite()\n)",
                      "language": "javascript",
                      "output": "NONE"
                    },
                    "index": 1,
                    "lastEditedBy": "f313b510-8ff6-4ef7-8c27-070c2ae45fc1",
                    "_deleted": false
                  }
                }
              }
            ],
            "creator": "pkhexmkwbs",
            "time": 1684303197446.01
          }
        ],
        [
          {
            "body": [
              {
                "ifMatch": {
                  "$set": {
                    "data": {
                      "code": "import {\n    FaceLandmarker,\n    FilesetResolver,\n    DrawingUtils\n} from \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0\";\n\nconst filesetResolver = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm\"\n);\n\nfunction calculateCentroid(landmarks) {\n    const sum = landmarks.reduce((acc, landmark) => {\n        acc[0] = landmark.x + acc[0];\n        acc[1] = landmark.y + acc[1];\n        acc[2] = landmark.z + acc[2];\n        return acc;\n    }, [0, 0, 0]);\n    return sum.map(coord => coord / landmarks.length);\n}\n\nconst faceLandmarker = await FaceLandmarker.createFromOptions(filesetResolver, {\n    baseOptions: {\n        modelAssetPath: \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task\",\n        delegate: \"GPU\"\n    },\n    outputFaceBlendshapes: true,\n    runningMode: \"IMAGE\",\n    numFaces: 1\n});\n\n\nconst visionLine = 0.5;\nconst threshold = 0.2;\n\ncaptureStream().pipe(\n  throttleTime(1000),\n  map(({message: img}) => {\n    const faceLandmarks = faceLandmarker.detect(img).faceLandmarks;\n    if (faceLandmarks.length === 0)\n        return \"NONE\";\n    const [x,y,z] = calculateCentroid(faceLandmarks[0]);\n    const distance = visionLine-x;\n    const relativeDistance = Math.abs(distance)/x;\n    return relativeDistance <= threshold ? \"NONE\" : distance > 0 ? \"l\" : \"r\";\n  }),\n  rewrite()\n)",
                      "language": "javascript",
                      "output": "r"
                    },
                    "index": 1,
                    "lastEditedBy": "f313b510-8ff6-4ef7-8c27-070c2ae45fc1",
                    "_deleted": false
                  }
                }
              }
            ],
            "creator": "pkhexmkwbs",
            "time": 1684303203612.01
          }
        ],
        [
          {
            "body": [
              {
                "ifMatch": {
                  "$set": {
                    "data": {
                      "code": "import {\n    FaceLandmarker,\n    FilesetResolver,\n    DrawingUtils\n} from \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0\";\n\nconst filesetResolver = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm\"\n);\n\nfunction calculateCentroid(landmarks) {\n    const sum = landmarks.reduce((acc, landmark) => {\n        acc[0] = landmark.x + acc[0];\n        acc[1] = landmark.y + acc[1];\n        acc[2] = landmark.z + acc[2];\n        return acc;\n    }, [0, 0, 0]);\n    return sum.map(coord => coord / landmarks.length);\n}\n\nconst faceLandmarker = await FaceLandmarker.createFromOptions(filesetResolver, {\n    baseOptions: {\n        modelAssetPath: \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task\",\n        delegate: \"GPU\"\n    },\n    outputFaceBlendshapes: true,\n    runningMode: \"IMAGE\",\n    numFaces: 1\n});\n\n\nconst visionLine = 0.5;\nconst threshold = 0.2;\n\ncaptureStream().pipe(\n  throttleTime(1000),\n  map(({message: img}) => {\n    const faceLandmarks = faceLandmarker.detect(img).faceLandmarks;\n    if (faceLandmarks.length === 0)\n        return \"NONE\";\n    const [x,y,z] = calculateCentroid(faceLandmarks[0]);\n    const distance = visionLine-x;\n    const relativeDistance = Math.abs(distance)/x;\n    return relativeDistance <= threshold ? \"NONE\" : distance > 0 ? \"l\" : \"r\";\n  }),\n  rewrite()\n)",
                      "language": "javascript",
                      "output": "NONE"
                    },
                    "index": 1,
                    "lastEditedBy": "f313b510-8ff6-4ef7-8c27-070c2ae45fc1",
                    "_deleted": false
                  }
                }
              }
            ],
            "creator": "pkhexmkwbs",
            "time": 1684303208845.01
          }
        ],
        [
          {
            "body": [
              {
                "ifMatch": {
                  "$set": {
                    "data": {
                      "code": "import {\n    FaceLandmarker,\n    FilesetResolver,\n    DrawingUtils\n} from \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0\";\n\nconst filesetResolver = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm\"\n);\n\nfunction calculateCentroid(landmarks) {\n    const sum = landmarks.reduce((acc, landmark) => {\n        acc[0] = landmark.x + acc[0];\n        acc[1] = landmark.y + acc[1];\n        acc[2] = landmark.z + acc[2];\n        return acc;\n    }, [0, 0, 0]);\n    return sum.map(coord => coord / landmarks.length);\n}\n\nconst faceLandmarker = await FaceLandmarker.createFromOptions(filesetResolver, {\n    baseOptions: {\n        modelAssetPath: \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task\",\n        delegate: \"GPU\"\n    },\n    outputFaceBlendshapes: true,\n    runningMode: \"IMAGE\",\n    numFaces: 1\n});\n\n\nconst visionLine = 0.5;\nconst threshold = 0.2;\n\ncaptureStream().pipe(\n  throttleTime(1000),\n  map(({message: img}) => {\n    const faceLandmarks = faceLandmarker.detect(img).faceLandmarks;\n    if (faceLandmarks.length === 0)\n        return \"c\";\n    const [x,y,z] = calculateCentroid(faceLandmarks[0]);\n    const distance = visionLine-x;\n    const relativeDistance = Math.abs(distance)/x;\n    return relativeDistance <= threshold ? \"NONE\" : distance > 0 ? \"l\" : \"r\";\n  }),\n  rewrite()\n)",
                      "language": "javascript",
                      "output": "NONE"
                    },
                    "index": 1,
                    "lastEditedBy": "f313b510-8ff6-4ef7-8c27-070c2ae45fc1",
                    "_deleted": false
                  }
                }
              }
            ],
            "creator": "pkhexmkwbs",
            "time": 1684303215457.02
          }
        ],
        [
          {
            "body": [
              {
                "ifMatch": {
                  "$set": {
                    "data": {
                      "code": "import {\n    FaceLandmarker,\n    FilesetResolver,\n    DrawingUtils\n} from \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0\";\n\nconst filesetResolver = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm\"\n);\n\n// TODO \nfunction calculateCentroid(landmarks) {\n    const sum = landmarks.reduce((acc, landmark) => {\n        acc[0] = landmark.x + acc[0];\n        acc[1] = landmark.y + acc[1];\n        acc[2] = landmark.z + acc[2];\n        return acc;\n    }, [0, 0, 0]);\n    return sum.map(coord => coord / landmarks.length);\n}\n\nconst faceLandmarker = await FaceLandmarker.createFromOptions(filesetResolver, {\n    baseOptions: {\n        modelAssetPath: \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task\",\n        delegate: \"GPU\"\n    },\n    outputFaceBlendshapes: true,\n    runningMode: \"IMAGE\",\n    numFaces: 1\n});\n\n\nconst visionLine = 0.5;\nconst threshold = 0.2;\n\ncaptureStream().pipe(\n  throttleTime(1000),\n  map(({message: img}) => {\n    const faceLandmarks = faceLandmarker.detect(img).faceLandmarks;\n    if (faceLandmarks.length === 0)\n        return \"c\";\n    const [x,y,z] = calculateCentroid(faceLandmarks[0]);\n    const distance = visionLine-x;\n    const relativeDistance = Math.abs(distance)/x;\n    return relativeDistance <= threshold ? \"NONE\" : distance > 0 ? \"l\" : \"r\";\n  }),\n  rewrite()\n)",
                      "language": "javascript",
                      "output": "NONE"
                    },
                    "index": 1,
                    "lastEditedBy": "f313b510-8ff6-4ef7-8c27-070c2ae45fc1",
                    "_deleted": false
                  }
                }
              }
            ],
            "creator": "pkhexmkwbs",
            "time": 1684303236374.01
          }
        ],
        [
          {
            "body": [
              {
                "ifMatch": {
                  "$set": {
                    "data": {
                      "code": "import {\n    FaceLandmarker,\n    FilesetResolver,\n    DrawingUtils\n} from \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0\";\n\nconst filesetResolver = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm\"\n);\n\n// TODO: This function \nfunction calculateCentroid(landmarks) {\n    const sum = landmarks.reduce((acc, landmark) => {\n        acc[0] = landmark.x + acc[0];\n        acc[1] = landmark.y + acc[1];\n        acc[2] = landmark.z + acc[2];\n        return acc;\n    }, [0, 0, 0]);\n    return sum.map(coord => coord / landmarks.length);\n}\n\nconst faceLandmarker = await FaceLandmarker.createFromOptions(filesetResolver, {\n    baseOptions: {\n        modelAssetPath: \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task\",\n        delegate: \"GPU\"\n    },\n    outputFaceBlendshapes: true,\n    runningMode: \"IMAGE\",\n    numFaces: 1\n});\n\n\nconst visionLine = 0.5;\nconst threshold = 0.2;\n\ncaptureStream().pipe(\n  throttleTime(1000),\n  map(({message: img}) => {\n    const faceLandmarks = faceLandmarker.detect(img).faceLandmarks;\n    if (faceLandmarks.length === 0)\n        return \"c\";\n    const [x,y,z] = calculateCentroid(faceLandmarks[0]);\n    const distance = visionLine-x;\n    const relativeDistance = Math.abs(distance)/x;\n    return relativeDistance <= threshold ? \"NONE\" : distance > 0 ? \"l\" : \"r\";\n  }),\n  rewrite()\n)",
                      "language": "javascript",
                      "output": "NONE"
                    },
                    "index": 1,
                    "lastEditedBy": "f313b510-8ff6-4ef7-8c27-070c2ae45fc1",
                    "_deleted": false
                  }
                }
              }
            ],
            "creator": "pkhexmkwbs",
            "time": 1684303240419.06
          }
        ],
        [
          {
            "body": [
              {
                "ifMatch": {
                  "$set": {
                    "data": {
                      "code": "import {\n    FaceLandmarker,\n    FilesetResolver,\n    DrawingUtils\n} from \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0\";\n\nconst filesetResolver = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm\"\n);\n\n// TODO: This function\nfunction calculateCentroid(landmarks) {\n    const sum = landmarks.reduce((acc, landmark) => {\n        acc[0] = landmark.x + acc[0];\n        acc[1] = landmark.y + acc[1];\n        acc[2] = landmark.z + acc[2];\n        return acc;\n    }, [0, 0, 0]);\n    return sum.map(coord => coord / landmarks.length);\n}\n\nconst faceLandmarker = await FaceLandmarker.createFromOptions(filesetResolver, {\n    baseOptions: {\n        modelAssetPath: \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task\",\n        delegate: \"GPU\"\n    },\n    outputFaceBlendshapes: true,\n    runningMode: \"IMAGE\",\n    numFaces: 1\n});\n\n\nconst visionLine = 0.5;\nconst threshold = 0.2;\n\ncaptureStream().pipe(\n  throttleTime(1000),\n  map(({message: img}) => {\n    const faceLandmarks = faceLandmarker.detect(img).faceLandmarks;\n    if (faceLandmarks.length === 0)\n        return \"c\";\n    const [x,y,z] = calculateCentroid(faceLandmarks[0]);\n    const distance = visionLine-x;\n    const relativeDistance = Math.abs(distance)/x;\n    return relativeDistance <= threshold ? \"NONE\" : distance > 0 ? \"l\" : \"r\";\n  }),\n  rewrite()\n)",
                      "language": "javascript",
                      "output": "NONE"
                    },
                    "index": 1,
                    "lastEditedBy": "f313b510-8ff6-4ef7-8c27-070c2ae45fc1",
                    "_deleted": false
                  }
                }
              }
            ],
            "creator": "pkhexmkwbs",
            "time": 1684303246523.01
          }
        ],
        [
          {
            "body": [
              {
                "ifMatch": {
                  "$set": {
                    "data": {
                      "code": "import {\n    FaceLandmarker,\n    FilesetResolver,\n    DrawingUtils\n} from \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0\";\n\nconst filesetResolver = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm\"\n);\n\n// TODO: This function \nfunction calculateCentroid(landmarks) {\n    const sum = landmarks.reduce((acc, landmark) => {\n        acc[0] = landmark.x + acc[0];\n        acc[1] = landmark.y + acc[1];\n        acc[2] = landmark.z + acc[2];\n        return acc;\n    }, [0, 0, 0]);\n    return sum.map(coord => coord / landmarks.length);\n}\n\nconst faceLandmarker = await FaceLandmarker.createFromOptions(filesetResolver, {\n    baseOptions: {\n        modelAssetPath: \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task\",\n        delegate: \"GPU\"\n    },\n    outputFaceBlendshapes: true,\n    runningMode: \"IMAGE\",\n    numFaces: 1\n});\n\n\nconst visionLine = 0.5;\nconst threshold = 0.2;\n\ncaptureStream().pipe(\n  throttleTime(1000),\n  map(({message: img}) => {\n    const faceLandmarks = faceLandmarker.detect(img).faceLandmarks;\n    if (faceLandmarks.length === 0)\n        return \"c\";\n    const [x,y,z] = calculateCentroid(faceLandmarks[0]);\n    const distance = visionLine-x;\n    const relativeDistance = Math.abs(distance)/x;\n    return relativeDistance <= threshold ? \"NONE\" : distance > 0 ? \"l\" : \"r\";\n  }),\n  rewrite()\n)",
                      "language": "javascript",
                      "output": "NONE"
                    },
                    "index": 1,
                    "lastEditedBy": "f313b510-8ff6-4ef7-8c27-070c2ae45fc1",
                    "_deleted": false
                  }
                }
              }
            ],
            "creator": "pkhexmkwbs",
            "time": 1684303247683.01
          }
        ],
        [
          {
            "body": [
              {
                "ifMatch": {
                  "$set": {
                    "data": {
                      "code": "import {\n    FaceLandmarker,\n    FilesetResolver,\n    DrawingUtils\n} from \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0\";\n\nconst filesetResolver = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm\"\n);\n\n// TODO: This function\nfunction calculateCentroid(landmarks) {\n    const sum = landmarks.reduce((acc, landmark) => {\n        acc[0] = landmark.x + acc[0];\n        acc[1] = landmark.y + acc[1];\n        acc[2] = landmark.z + acc[2];\n        return acc;\n    }, [0, 0, 0]);\n    return sum.map(coord => coord / landmarks.length);\n}\n\nconst faceLandmarker = await FaceLandmarker.createFromOptions(filesetResolver, {\n    baseOptions: {\n        modelAssetPath: \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task\",\n        delegate: \"GPU\"\n    },\n    outputFaceBlendshapes: true,\n    runningMode: \"IMAGE\",\n    numFaces: 1\n});\n\n\nconst visionLine = 0.5;\nconst threshold = 0.2;\n\ncaptureStream().pipe(\n  throttleTime(1000),\n  map(({message: img}) => {\n    const faceLandmarks = faceLandmarker.detect(img).faceLandmarks;\n    if (faceLandmarks.length === 0)\n        return \"c\";\n    const [x,y,z] = calculateCentroid(faceLandmarks[0]);\n    const distance = visionLine-x;\n    const relativeDistance = Math.abs(distance)/x;\n    return relativeDistance <= threshold ? \"NONE\" : distance > 0 ? \"l\" : \"r\";\n  }),\n  rewrite()\n)",
                      "language": "javascript",
                      "output": "NONE"
                    },
                    "index": 1,
                    "lastEditedBy": "f313b510-8ff6-4ef7-8c27-070c2ae45fc1",
                    "_deleted": false
                  }
                }
              }
            ],
            "creator": "pkhexmkwbs",
            "time": 1684303248720.06
          }
        ],
        [
          {
            "body": [
              {
                "ifMatch": {
                  "$set": {
                    "data": {
                      "code": "import {\n    FaceLandmarker,\n    FilesetResolver,\n    DrawingUtils\n} from \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0\";\n\nconst filesetResolver = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm\"\n);\n\n// TODO: I think \nfunction calculateCentroid(landmarks) {\n    const sum = landmarks.reduce((acc, landmark) => {\n        acc[0] = landmark.x + acc[0];\n        acc[1] = landmark.y + acc[1];\n        acc[2] = landmark.z + acc[2];\n        return acc;\n    }, [0, 0, 0]);\n    return sum.map(coord => coord / landmarks.length);\n}\n\nconst faceLandmarker = await FaceLandmarker.createFromOptions(filesetResolver, {\n    baseOptions: {\n        modelAssetPath: \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task\",\n        delegate: \"GPU\"\n    },\n    outputFaceBlendshapes: true,\n    runningMode: \"IMAGE\",\n    numFaces: 1\n});\n\n\nconst visionLine = 0.5;\nconst threshold = 0.2;\n\ncaptureStream().pipe(\n  throttleTime(1000),\n  map(({message: img}) => {\n    const faceLandmarks = faceLandmarker.detect(img).faceLandmarks;\n    if (faceLandmarks.length === 0)\n        return \"c\";\n    const [x,y,z] = calculateCentroid(faceLandmarks[0]);\n    const distance = visionLine-x;\n    const relativeDistance = Math.abs(distance)/x;\n    return relativeDistance <= threshold ? \"NONE\" : distance > 0 ? \"l\" : \"r\";\n  }),\n  rewrite()\n)",
                      "language": "javascript",
                      "output": "NONE"
                    },
                    "index": 1,
                    "lastEditedBy": "f313b510-8ff6-4ef7-8c27-070c2ae45fc1",
                    "_deleted": false
                  }
                }
              }
            ],
            "creator": "pkhexmkwbs",
            "time": 1684303251256.01
          }
        ],
        [
          {
            "body": [
              {
                "ifMatch": {
                  "$set": {
                    "data": {
                      "code": "import {\n    FaceLandmarker,\n    FilesetResolver,\n    DrawingUtils\n} from \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0\";\n\nconst filesetResolver = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm\"\n);\n\n// TODO: I think this u\nfunction calculateCentroid(landmarks) {\n    const sum = landmarks.reduce((acc, landmark) => {\n        acc[0] = landmark.x + acc[0];\n        acc[1] = landmark.y + acc[1];\n        acc[2] = landmark.z + acc[2];\n        return acc;\n    }, [0, 0, 0]);\n    return sum.map(coord => coord / landmarks.length);\n}\n\nconst faceLandmarker = await FaceLandmarker.createFromOptions(filesetResolver, {\n    baseOptions: {\n        modelAssetPath: \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task\",\n        delegate: \"GPU\"\n    },\n    outputFaceBlendshapes: true,\n    runningMode: \"IMAGE\",\n    numFaces: 1\n});\n\n\nconst visionLine = 0.5;\nconst threshold = 0.2;\n\ncaptureStream().pipe(\n  throttleTime(1000),\n  map(({message: img}) => {\n    const faceLandmarks = faceLandmarker.detect(img).faceLandmarks;\n    if (faceLandmarks.length === 0)\n        return \"c\";\n    const [x,y,z] = calculateCentroid(faceLandmarks[0]);\n    const distance = visionLine-x;\n    const relativeDistance = Math.abs(distance)/x;\n    return relativeDistance <= threshold ? \"NONE\" : distance > 0 ? \"l\" : \"r\";\n  }),\n  rewrite()\n)",
                      "language": "javascript",
                      "output": "NONE"
                    },
                    "index": 1,
                    "lastEditedBy": "f313b510-8ff6-4ef7-8c27-070c2ae45fc1",
                    "_deleted": false
                  }
                }
              }
            ],
            "creator": "pkhexmkwbs",
            "time": 1684303253843.06
          }
        ],
        [
          {
            "body": [
              {
                "ifMatch": {
                  "$set": {
                    "data": {
                      "code": "import {\n    FaceLandmarker,\n    FilesetResolver,\n    DrawingUtils\n} from \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0\";\n\nconst filesetResolver = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm\"\n);\n\n// TODO: I think this function \nfunction calculateCentroid(landmarks) {\n    const sum = landmarks.reduce((acc, landmark) => {\n        acc[0] = landmark.x + acc[0];\n        acc[1] = landmark.y + acc[1];\n        acc[2] = landmark.z + acc[2];\n        return acc;\n    }, [0, 0, 0]);\n    return sum.map(coord => coord / landmarks.length);\n}\n\nconst faceLandmarker = await FaceLandmarker.createFromOptions(filesetResolver, {\n    baseOptions: {\n        modelAssetPath: \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task\",\n        delegate: \"GPU\"\n    },\n    outputFaceBlendshapes: true,\n    runningMode: \"IMAGE\",\n    numFaces: 1\n});\n\n\nconst visionLine = 0.5;\nconst threshold = 0.2;\n\ncaptureStream().pipe(\n  throttleTime(1000),\n  map(({message: img}) => {\n    const faceLandmarks = faceLandmarker.detect(img).faceLandmarks;\n    if (faceLandmarks.length === 0)\n        return \"c\";\n    const [x,y,z] = calculateCentroid(faceLandmarks[0]);\n    const distance = visionLine-x;\n    const relativeDistance = Math.abs(distance)/x;\n    return relativeDistance <= threshold ? \"NONE\" : distance > 0 ? \"l\" : \"r\";\n  }),\n  rewrite()\n)",
                      "language": "javascript",
                      "output": "NONE"
                    },
                    "index": 1,
                    "lastEditedBy": "f313b510-8ff6-4ef7-8c27-070c2ae45fc1",
                    "_deleted": false
                  }
                }
              }
            ],
            "creator": "pkhexmkwbs",
            "time": 1684303255326.06
          }
        ],
        [
          {
            "body": [
              {
                "ifMatch": {
                  "$set": {
                    "data": {
                      "code": "import {\n    FaceLandmarker,\n    FilesetResolver,\n    DrawingUtils\n} from \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0\";\n\nconst filesetResolver = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm\"\n);\n\n// TODO: I think this function introduce a \nfunction calculateCentroid(landmarks) {\n    const sum = landmarks.reduce((acc, landmark) => {\n        acc[0] = landmark.x + acc[0];\n        acc[1] = landmark.y + acc[1];\n        acc[2] = landmark.z + acc[2];\n        return acc;\n    }, [0, 0, 0]);\n    return sum.map(coord => coord / landmarks.length);\n}\n\nconst faceLandmarker = await FaceLandmarker.createFromOptions(filesetResolver, {\n    baseOptions: {\n        modelAssetPath: \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task\",\n        delegate: \"GPU\"\n    },\n    outputFaceBlendshapes: true,\n    runningMode: \"IMAGE\",\n    numFaces: 1\n});\n\n\nconst visionLine = 0.5;\nconst threshold = 0.2;\n\ncaptureStream().pipe(\n  throttleTime(1000),\n  map(({message: img}) => {\n    const faceLandmarks = faceLandmarker.detect(img).faceLandmarks;\n    if (faceLandmarks.length === 0)\n        return \"c\";\n    const [x,y,z] = calculateCentroid(faceLandmarks[0]);\n    const distance = visionLine-x;\n    const relativeDistance = Math.abs(distance)/x;\n    return relativeDistance <= threshold ? \"NONE\" : distance > 0 ? \"l\" : \"r\";\n  }),\n  rewrite()\n)",
                      "language": "javascript",
                      "output": "NONE"
                    },
                    "index": 1,
                    "lastEditedBy": "f313b510-8ff6-4ef7-8c27-070c2ae45fc1",
                    "_deleted": false
                  }
                }
              }
            ],
            "creator": "pkhexmkwbs",
            "time": 1684303261421.01
          }
        ],
        [
          {
            "body": [
              {
                "ifMatch": {
                  "$set": {
                    "data": {
                      "code": "import {\n    FaceLandmarker,\n    FilesetResolver,\n    DrawingUtils\n} from \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0\";\n\nconst filesetResolver = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm\"\n);\n\n// TODO: I think this function introduce a high over\nfunction calculateCentroid(landmarks) {\n    const sum = landmarks.reduce((acc, landmark) => {\n        acc[0] = landmark.x + acc[0];\n        acc[1] = landmark.y + acc[1];\n        acc[2] = landmark.z + acc[2];\n        return acc;\n    }, [0, 0, 0]);\n    return sum.map(coord => coord / landmarks.length);\n}\n\nconst faceLandmarker = await FaceLandmarker.createFromOptions(filesetResolver, {\n    baseOptions: {\n        modelAssetPath: \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task\",\n        delegate: \"GPU\"\n    },\n    outputFaceBlendshapes: true,\n    runningMode: \"IMAGE\",\n    numFaces: 1\n});\n\n\nconst visionLine = 0.5;\nconst threshold = 0.2;\n\ncaptureStream().pipe(\n  throttleTime(1000),\n  map(({message: img}) => {\n    const faceLandmarks = faceLandmarker.detect(img).faceLandmarks;\n    if (faceLandmarks.length === 0)\n        return \"c\";\n    const [x,y,z] = calculateCentroid(faceLandmarks[0]);\n    const distance = visionLine-x;\n    const relativeDistance = Math.abs(distance)/x;\n    return relativeDistance <= threshold ? \"NONE\" : distance > 0 ? \"l\" : \"r\";\n  }),\n  rewrite()\n)",
                      "language": "javascript",
                      "output": "NONE"
                    },
                    "index": 1,
                    "lastEditedBy": "f313b510-8ff6-4ef7-8c27-070c2ae45fc1",
                    "_deleted": false
                  }
                }
              }
            ],
            "creator": "pkhexmkwbs",
            "time": 1684303263857.01
          }
        ],
        [
          {
            "body": [
              {
                "ifMatch": {
                  "$set": {
                    "data": {
                      "code": "import {\n    FaceLandmarker,\n    FilesetResolver,\n    DrawingUtils\n} from \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0\";\n\nconst filesetResolver = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm\"\n);\n\n// TODO: I think this function introduce a high overhead\nfunction calculateCentroid(landmarks) {\n    const sum = landmarks.reduce((acc, landmark) => {\n        acc[0] = landmark.x + acc[0];\n        acc[1] = landmark.y + acc[1];\n        acc[2] = landmark.z + acc[2];\n        return acc;\n    }, [0, 0, 0]);\n    return sum.map(coord => coord / landmarks.length);\n}\n\nconst faceLandmarker = await FaceLandmarker.createFromOptions(filesetResolver, {\n    baseOptions: {\n        modelAssetPath: \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task\",\n        delegate: \"GPU\"\n    },\n    outputFaceBlendshapes: true,\n    runningMode: \"IMAGE\",\n    numFaces: 1\n});\n\n\nconst visionLine = 0.5;\nconst threshold = 0.2;\n\ncaptureStream().pipe(\n  throttleTime(1000),\n  map(({message: img}) => {\n    const faceLandmarks = faceLandmarker.detect(img).faceLandmarks;\n    if (faceLandmarks.length === 0)\n        return \"c\";\n    const [x,y,z] = calculateCentroid(faceLandmarks[0]);\n    const distance = visionLine-x;\n    const relativeDistance = Math.abs(distance)/x;\n    return relativeDistance <= threshold ? \"NONE\" : distance > 0 ? \"l\" : \"r\";\n  }),\n  rewrite()\n)",
                      "language": "javascript",
                      "output": "NONE"
                    },
                    "index": 1,
                    "lastEditedBy": "f313b510-8ff6-4ef7-8c27-070c2ae45fc1",
                    "_deleted": false
                  }
                }
              }
            ],
            "creator": "pkhexmkwbs",
            "time": 1684303264684.06
          }
        ],
        [
          {
            "body": [
              {
                "ifMatch": {
                  "$set": {
                    "data": {
                      "code": "import {\n    FaceLandmarker,\n    FilesetResolver,\n    DrawingUtils\n} from \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0\";\n\nconst filesetResolver = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm\"\n);\n\n/* TODO: I think this function introduce a high overhead\nfunction calculateCentroid(landmarks) {\n    const sum = landmarks.reduce((acc, landmark) => {\n        acc[0] = landmark.x + acc[0];\n        acc[1] = landmark.y + acc[1];\n        acc[2] = landmark.z + acc[2];\n        return acc;\n    }, [0, 0, 0]);\n    return sum.map(coord => coord / landmarks.length);\n}\n\nconst faceLandmarker = await FaceLandmarker.createFromOptions(filesetResolver, {\n    baseOptions: {\n        modelAssetPath: \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task\",\n        delegate: \"GPU\"\n    },\n    outputFaceBlendshapes: true,\n    runningMode: \"IMAGE\",\n    numFaces: 1\n});\n\n\nconst visionLine = 0.5;\nconst threshold = 0.2;\n\ncaptureStream().pipe(\n  throttleTime(1000),\n  map(({message: img}) => {\n    const faceLandmarks = faceLandmarker.detect(img).faceLandmarks;\n    if (faceLandmarks.length === 0)\n        return \"c\";\n    const [x,y,z] = calculateCentroid(faceLandmarks[0]);\n    const distance = visionLine-x;\n    const relativeDistance = Math.abs(distance)/x;\n    return relativeDistance <= threshold ? \"NONE\" : distance > 0 ? \"l\" : \"r\";\n  }),\n  rewrite()\n)",
                      "language": "javascript",
                      "output": "NONE"
                    },
                    "index": 1,
                    "lastEditedBy": "f313b510-8ff6-4ef7-8c27-070c2ae45fc1",
                    "_deleted": false
                  }
                }
              }
            ],
            "creator": "pkhexmkwbs",
            "time": 1684303268284.05
          }
        ],
        [
          {
            "body": [
              {
                "ifMatch": {
                  "$set": {
                    "data": {
                      "code": "import {\n    FaceLandmarker,\n    FilesetResolver,\n    DrawingUtils\n} from \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0\";\n\nconst filesetResolver = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm\"\n);\n\n/* TODO: I think this function introduce a high overhead\n\nfunction calculateCentroid(landmarks) {\n    const sum = landmarks.reduce((acc, landmark) => {\n        acc[0] = landmark.x + acc[0];\n        acc[1] = landmark.y + acc[1];\n        acc[2] = landmark.z + acc[2];\n        return acc;\n    }, [0, 0, 0]);\n    return sum.map(coord => coord / landmarks.length);\n}\n\nconst faceLandmarker = await FaceLandmarker.createFromOptions(filesetResolver, {\n    baseOptions: {\n        modelAssetPath: \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task\",\n        delegate: \"GPU\"\n    },\n    outputFaceBlendshapes: true,\n    runningMode: \"IMAGE\",\n    numFaces: 1\n});\n\n\nconst visionLine = 0.5;\nconst threshold = 0.2;\n\ncaptureStream().pipe(\n  throttleTime(1000),\n  map(({message: img}) => {\n    const faceLandmarks = faceLandmarker.detect(img).faceLandmarks;\n    if (faceLandmarks.length === 0)\n        return \"c\";\n    const [x,y,z] = calculateCentroid(faceLandmarks[0]);\n    const distance = visionLine-x;\n    const relativeDistance = Math.abs(distance)/x;\n    return relativeDistance <= threshold ? \"NONE\" : distance > 0 ? \"l\" : \"r\";\n  }),\n  rewrite()\n)",
                      "language": "javascript",
                      "output": "NONE"
                    },
                    "index": 1,
                    "lastEditedBy": "f313b510-8ff6-4ef7-8c27-070c2ae45fc1",
                    "_deleted": false
                  }
                }
              }
            ],
            "creator": "pkhexmkwbs",
            "time": 1684303269121.06
          }
        ],
        [
          {
            "body": [
              {
                "ifMatch": {
                  "$set": {
                    "data": {
                      "code": "import {\n    FaceLandmarker,\n    FilesetResolver,\n    DrawingUtils\n} from \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0\";\n\nconst filesetResolver = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm\"\n);\n\n/* TODO: I think this function introduce a high overhead\n/\nfunction calculateCentroid(landmarks) {\n    const sum = landmarks.reduce((acc, landmark) => {\n        acc[0] = landmark.x + acc[0];\n        acc[1] = landmark.y + acc[1];\n        acc[2] = landmark.z + acc[2];\n        return acc;\n    }, [0, 0, 0]);\n    return sum.map(coord => coord / landmarks.length);\n}\n\nconst faceLandmarker = await FaceLandmarker.createFromOptions(filesetResolver, {\n    baseOptions: {\n        modelAssetPath: \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task\",\n        delegate: \"GPU\"\n    },\n    outputFaceBlendshapes: true,\n    runningMode: \"IMAGE\",\n    numFaces: 1\n});\n\n\nconst visionLine = 0.5;\nconst threshold = 0.2;\n\ncaptureStream().pipe(\n  throttleTime(1000),\n  map(({message: img}) => {\n    const faceLandmarks = faceLandmarker.detect(img).faceLandmarks;\n    if (faceLandmarks.length === 0)\n        return \"c\";\n    const [x,y,z] = calculateCentroid(faceLandmarks[0]);\n    const distance = visionLine-x;\n    const relativeDistance = Math.abs(distance)/x;\n    return relativeDistance <= threshold ? \"NONE\" : distance > 0 ? \"l\" : \"r\";\n  }),\n  rewrite()\n)",
                      "language": "javascript",
                      "output": "NONE"
                    },
                    "index": 1,
                    "lastEditedBy": "f313b510-8ff6-4ef7-8c27-070c2ae45fc1",
                    "_deleted": false
                  }
                }
              }
            ],
            "creator": "pkhexmkwbs",
            "time": 1684303270879.01
          }
        ],
        [
          {
            "body": [
              {
                "ifMatch": {
                  "$set": {
                    "data": {
                      "code": "import {\n    FaceLandmarker,\n    FilesetResolver,\n    DrawingUtils\n} from \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0\";\n\nconst filesetResolver = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm\"\n);\n\n/* TODO: I think this function introduce a high overhead\n*/\nfunction calculateCentroid(landmarks) {\n    const sum = landmarks.reduce((acc, landmark) => {\n        acc[0] = landmark.x + acc[0];\n        acc[1] = landmark.y + acc[1];\n        acc[2] = landmark.z + acc[2];\n        return acc;\n    }, [0, 0, 0]);\n    return sum.map(coord => coord / landmarks.length);\n}\n\nconst faceLandmarker = await FaceLandmarker.createFromOptions(filesetResolver, {\n    baseOptions: {\n        modelAssetPath: \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task\",\n        delegate: \"GPU\"\n    },\n    outputFaceBlendshapes: true,\n    runningMode: \"IMAGE\",\n    numFaces: 1\n});\n\n\nconst visionLine = 0.5;\nconst threshold = 0.2;\n\ncaptureStream().pipe(\n  throttleTime(1000),\n  map(({message: img}) => {\n    const faceLandmarks = faceLandmarker.detect(img).faceLandmarks;\n    if (faceLandmarks.length === 0)\n        return \"c\";\n    const [x,y,z] = calculateCentroid(faceLandmarks[0]);\n    const distance = visionLine-x;\n    const relativeDistance = Math.abs(distance)/x;\n    return relativeDistance <= threshold ? \"NONE\" : distance > 0 ? \"l\" : \"r\";\n  }),\n  rewrite()\n)",
                      "language": "javascript",
                      "output": "NONE"
                    },
                    "index": 1,
                    "lastEditedBy": "f313b510-8ff6-4ef7-8c27-070c2ae45fc1",
                    "_deleted": false
                  }
                }
              }
            ],
            "creator": "pkhexmkwbs",
            "time": 1684303271762.06
          }
        ],
        [
          {
            "body": [
              {
                "ifMatch": {
                  "$set": {
                    "data": {
                      "code": "import {\n    FaceLandmarker,\n    FilesetResolver,\n    DrawingUtils\n} from \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0\";\n\nconst filesetResolver = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm\"\n);\n\n/* \nTODO: I think this function introduce a high overhead\n*/\nfunction calculateCentroid(landmarks) {\n    const sum = landmarks.reduce((acc, landmark) => {\n        acc[0] = landmark.x + acc[0];\n        acc[1] = landmark.y + acc[1];\n        acc[2] = landmark.z + acc[2];\n        return acc;\n    }, [0, 0, 0]);\n    return sum.map(coord => coord / landmarks.length);\n}\n\nconst faceLandmarker = await FaceLandmarker.createFromOptions(filesetResolver, {\n    baseOptions: {\n        modelAssetPath: \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task\",\n        delegate: \"GPU\"\n    },\n    outputFaceBlendshapes: true,\n    runningMode: \"IMAGE\",\n    numFaces: 1\n});\n\n\nconst visionLine = 0.5;\nconst threshold = 0.2;\n\ncaptureStream().pipe(\n  throttleTime(1000),\n  map(({message: img}) => {\n    const faceLandmarks = faceLandmarker.detect(img).faceLandmarks;\n    if (faceLandmarks.length === 0)\n        return \"c\";\n    const [x,y,z] = calculateCentroid(faceLandmarks[0]);\n    const distance = visionLine-x;\n    const relativeDistance = Math.abs(distance)/x;\n    return relativeDistance <= threshold ? \"NONE\" : distance > 0 ? \"l\" : \"r\";\n  }),\n  rewrite()\n)",
                      "language": "javascript",
                      "output": "NONE"
                    },
                    "index": 1,
                    "lastEditedBy": "f313b510-8ff6-4ef7-8c27-070c2ae45fc1",
                    "_deleted": false
                  }
                }
              }
            ],
            "creator": "pkhexmkwbs",
            "time": 1684303272750.02
          }
        ],
        [
          {
            "body": [
              {
                "ifMatch": {
                  "$set": {
                    "data": {
                      "code": "import {\n    FaceLandmarker,\n    FilesetResolver,\n    DrawingUtils\n} from \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0\";\n\nconst filesetResolver = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm\"\n);\n\n/* \n   TODO: I think this function introduce a high overhead\n*/\nfunction calculateCentroid(landmarks) {\n    const sum = landmarks.reduce((acc, landmark) => {\n        acc[0] = landmark.x + acc[0];\n        acc[1] = landmark.y + acc[1];\n        acc[2] = landmark.z + acc[2];\n        return acc;\n    }, [0, 0, 0]);\n    return sum.map(coord => coord / landmarks.length);\n}\n\nconst faceLandmarker = await FaceLandmarker.createFromOptions(filesetResolver, {\n    baseOptions: {\n        modelAssetPath: \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task\",\n        delegate: \"GPU\"\n    },\n    outputFaceBlendshapes: true,\n    runningMode: \"IMAGE\",\n    numFaces: 1\n});\n\n\nconst visionLine = 0.5;\nconst threshold = 0.2;\n\ncaptureStream().pipe(\n  throttleTime(1000),\n  map(({message: img}) => {\n    const faceLandmarks = faceLandmarker.detect(img).faceLandmarks;\n    if (faceLandmarks.length === 0)\n        return \"c\";\n    const [x,y,z] = calculateCentroid(faceLandmarks[0]);\n    const distance = visionLine-x;\n    const relativeDistance = Math.abs(distance)/x;\n    return relativeDistance <= threshold ? \"NONE\" : distance > 0 ? \"l\" : \"r\";\n  }),\n  rewrite()\n)",
                      "language": "javascript",
                      "output": "NONE"
                    },
                    "index": 1,
                    "lastEditedBy": "f313b510-8ff6-4ef7-8c27-070c2ae45fc1",
                    "_deleted": false
                  }
                }
              }
            ],
            "creator": "pkhexmkwbs",
            "time": 1684303273590.01
          }
        ],
        [
          {
            "body": [
              {
                "ifMatch": {
                  "$set": {
                    "data": {
                      "code": "import {\n    FaceLandmarker,\n    FilesetResolver,\n    DrawingUtils\n} from \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0\";\n\nconst filesetResolver = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm\"\n);\n\n/* \n   TODO: I think this function introduce a high overhead, so \n*/\nfunction calculateCentroid(landmarks) {\n    const sum = landmarks.reduce((acc, landmark) => {\n        acc[0] = landmark.x + acc[0];\n        acc[1] = landmark.y + acc[1];\n        acc[2] = landmark.z + acc[2];\n        return acc;\n    }, [0, 0, 0]);\n    return sum.map(coord => coord / landmarks.length);\n}\n\nconst faceLandmarker = await FaceLandmarker.createFromOptions(filesetResolver, {\n    baseOptions: {\n        modelAssetPath: \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task\",\n        delegate: \"GPU\"\n    },\n    outputFaceBlendshapes: true,\n    runningMode: \"IMAGE\",\n    numFaces: 1\n});\n\n\nconst visionLine = 0.5;\nconst threshold = 0.2;\n\ncaptureStream().pipe(\n  throttleTime(1000),\n  map(({message: img}) => {\n    const faceLandmarks = faceLandmarker.detect(img).faceLandmarks;\n    if (faceLandmarks.length === 0)\n        return \"c\";\n    const [x,y,z] = calculateCentroid(faceLandmarks[0]);\n    const distance = visionLine-x;\n    const relativeDistance = Math.abs(distance)/x;\n    return relativeDistance <= threshold ? \"NONE\" : distance > 0 ? \"l\" : \"r\";\n  }),\n  rewrite()\n)",
                      "language": "javascript",
                      "output": "NONE"
                    },
                    "index": 1,
                    "lastEditedBy": "f313b510-8ff6-4ef7-8c27-070c2ae45fc1",
                    "_deleted": false
                  }
                }
              }
            ],
            "creator": "pkhexmkwbs",
            "time": 1684303274765.01
          }
        ],
        [
          {
            "body": [
              {
                "ifMatch": {
                  "$set": {
                    "data": {
                      "code": "import {\n    FaceLandmarker,\n    FilesetResolver,\n    DrawingUtils\n} from \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0\";\n\nconst filesetResolver = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm\"\n);\n\n/* \n   TODO: I think this function introduce a high overhead, so I \n*/\nfunction calculateCentroid(landmarks) {\n    const sum = landmarks.reduce((acc, landmark) => {\n        acc[0] = landmark.x + acc[0];\n        acc[1] = landmark.y + acc[1];\n        acc[2] = landmark.z + acc[2];\n        return acc;\n    }, [0, 0, 0]);\n    return sum.map(coord => coord / landmarks.length);\n}\n\nconst faceLandmarker = await FaceLandmarker.createFromOptions(filesetResolver, {\n    baseOptions: {\n        modelAssetPath: \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task\",\n        delegate: \"GPU\"\n    },\n    outputFaceBlendshapes: true,\n    runningMode: \"IMAGE\",\n    numFaces: 1\n});\n\n\nconst visionLine = 0.5;\nconst threshold = 0.2;\n\ncaptureStream().pipe(\n  throttleTime(1000),\n  map(({message: img}) => {\n    const faceLandmarks = faceLandmarker.detect(img).faceLandmarks;\n    if (faceLandmarks.length === 0)\n        return \"c\";\n    const [x,y,z] = calculateCentroid(faceLandmarks[0]);\n    const distance = visionLine-x;\n    const relativeDistance = Math.abs(distance)/x;\n    return relativeDistance <= threshold ? \"NONE\" : distance > 0 ? \"l\" : \"r\";\n  }),\n  rewrite()\n)",
                      "language": "javascript",
                      "output": "NONE"
                    },
                    "index": 1,
                    "lastEditedBy": "f313b510-8ff6-4ef7-8c27-070c2ae45fc1",
                    "_deleted": false
                  }
                }
              }
            ],
            "creator": "pkhexmkwbs",
            "time": 1684303277280.01
          }
        ],
        [
          {
            "body": [
              {
                "ifMatch": {
                  "$set": {
                    "data": {
                      "code": "import {\n    FaceLandmarker,\n    FilesetResolver,\n    DrawingUtils\n} from \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0\";\n\nconst filesetResolver = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm\"\n);\n\n/* \n   TODO: I think this function introduce a high overhead, so it \n*/\nfunction calculateCentroid(landmarks) {\n    const sum = landmarks.reduce((acc, landmark) => {\n        acc[0] = landmark.x + acc[0];\n        acc[1] = landmark.y + acc[1];\n        acc[2] = landmark.z + acc[2];\n        return acc;\n    }, [0, 0, 0]);\n    return sum.map(coord => coord / landmarks.length);\n}\n\nconst faceLandmarker = await FaceLandmarker.createFromOptions(filesetResolver, {\n    baseOptions: {\n        modelAssetPath: \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task\",\n        delegate: \"GPU\"\n    },\n    outputFaceBlendshapes: true,\n    runningMode: \"IMAGE\",\n    numFaces: 1\n});\n\n\nconst visionLine = 0.5;\nconst threshold = 0.2;\n\ncaptureStream().pipe(\n  throttleTime(1000),\n  map(({message: img}) => {\n    const faceLandmarks = faceLandmarker.detect(img).faceLandmarks;\n    if (faceLandmarks.length === 0)\n        return \"c\";\n    const [x,y,z] = calculateCentroid(faceLandmarks[0]);\n    const distance = visionLine-x;\n    const relativeDistance = Math.abs(distance)/x;\n    return relativeDistance <= threshold ? \"NONE\" : distance > 0 ? \"l\" : \"r\";\n  }),\n  rewrite()\n)",
                      "language": "javascript",
                      "output": "NONE"
                    },
                    "index": 1,
                    "lastEditedBy": "f313b510-8ff6-4ef7-8c27-070c2ae45fc1",
                    "_deleted": false
                  }
                }
              }
            ],
            "creator": "pkhexmkwbs",
            "time": 1684303278823.01
          }
        ],
        [
          {
            "body": [
              {
                "ifMatch": {
                  "$set": {
                    "data": {
                      "code": "import {\n    FaceLandmarker,\n    FilesetResolver,\n    DrawingUtils\n} from \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0\";\n\nconst filesetResolver = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm\"\n);\n\n/* \n   TODO: I think this function introduce a high overhead, so it must \n*/\nfunction calculateCentroid(landmarks) {\n    const sum = landmarks.reduce((acc, landmark) => {\n        acc[0] = landmark.x + acc[0];\n        acc[1] = landmark.y + acc[1];\n        acc[2] = landmark.z + acc[2];\n        return acc;\n    }, [0, 0, 0]);\n    return sum.map(coord => coord / landmarks.length);\n}\n\nconst faceLandmarker = await FaceLandmarker.createFromOptions(filesetResolver, {\n    baseOptions: {\n        modelAssetPath: \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task\",\n        delegate: \"GPU\"\n    },\n    outputFaceBlendshapes: true,\n    runningMode: \"IMAGE\",\n    numFaces: 1\n});\n\n\nconst visionLine = 0.5;\nconst threshold = 0.2;\n\ncaptureStream().pipe(\n  throttleTime(1000),\n  map(({message: img}) => {\n    const faceLandmarks = faceLandmarker.detect(img).faceLandmarks;\n    if (faceLandmarks.length === 0)\n        return \"c\";\n    const [x,y,z] = calculateCentroid(faceLandmarks[0]);\n    const distance = visionLine-x;\n    const relativeDistance = Math.abs(distance)/x;\n    return relativeDistance <= threshold ? \"NONE\" : distance > 0 ? \"l\" : \"r\";\n  }),\n  rewrite()\n)",
                      "language": "javascript",
                      "output": "NONE"
                    },
                    "index": 1,
                    "lastEditedBy": "f313b510-8ff6-4ef7-8c27-070c2ae45fc1",
                    "_deleted": false
                  }
                }
              }
            ],
            "creator": "pkhexmkwbs",
            "time": 1684303279991.01
          }
        ],
        [
          {
            "body": [
              {
                "ifMatch": {
                  "$set": {
                    "data": {
                      "code": "import {\n    FaceLandmarker,\n    FilesetResolver,\n    DrawingUtils\n} from \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0\";\n\nconst filesetResolver = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm\"\n);\n\n/* \n   TODO: I think this function introduce a high overhead, so it should \n*/\nfunction calculateCentroid(landmarks) {\n    const sum = landmarks.reduce((acc, landmark) => {\n        acc[0] = landmark.x + acc[0];\n        acc[1] = landmark.y + acc[1];\n        acc[2] = landmark.z + acc[2];\n        return acc;\n    }, [0, 0, 0]);\n    return sum.map(coord => coord / landmarks.length);\n}\n\nconst faceLandmarker = await FaceLandmarker.createFromOptions(filesetResolver, {\n    baseOptions: {\n        modelAssetPath: \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task\",\n        delegate: \"GPU\"\n    },\n    outputFaceBlendshapes: true,\n    runningMode: \"IMAGE\",\n    numFaces: 1\n});\n\n\nconst visionLine = 0.5;\nconst threshold = 0.2;\n\ncaptureStream().pipe(\n  throttleTime(1000),\n  map(({message: img}) => {\n    const faceLandmarks = faceLandmarker.detect(img).faceLandmarks;\n    if (faceLandmarks.length === 0)\n        return \"c\";\n    const [x,y,z] = calculateCentroid(faceLandmarks[0]);\n    const distance = visionLine-x;\n    const relativeDistance = Math.abs(distance)/x;\n    return relativeDistance <= threshold ? \"NONE\" : distance > 0 ? \"l\" : \"r\";\n  }),\n  rewrite()\n)",
                      "language": "javascript",
                      "output": "NONE"
                    },
                    "index": 1,
                    "lastEditedBy": "f313b510-8ff6-4ef7-8c27-070c2ae45fc1",
                    "_deleted": false
                  }
                }
              }
            ],
            "creator": "pkhexmkwbs",
            "time": 1684303282477.06
          }
        ],
        [
          {
            "body": [
              {
                "ifMatch": {
                  "$set": {
                    "data": {
                      "code": "import {\n    FaceLandmarker,\n    FilesetResolver,\n    DrawingUtils\n} from \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0\";\n\nconst filesetResolver = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm\"\n);\n\n/* \n   TODO: I think this function introduce a high overhead, so it should be migrated to \n*/\nfunction calculateCentroid(landmarks) {\n    const sum = landmarks.reduce((acc, landmark) => {\n        acc[0] = landmark.x + acc[0];\n        acc[1] = landmark.y + acc[1];\n        acc[2] = landmark.z + acc[2];\n        return acc;\n    }, [0, 0, 0]);\n    return sum.map(coord => coord / landmarks.length);\n}\n\nconst faceLandmarker = await FaceLandmarker.createFromOptions(filesetResolver, {\n    baseOptions: {\n        modelAssetPath: \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task\",\n        delegate: \"GPU\"\n    },\n    outputFaceBlendshapes: true,\n    runningMode: \"IMAGE\",\n    numFaces: 1\n});\n\n\nconst visionLine = 0.5;\nconst threshold = 0.2;\n\ncaptureStream().pipe(\n  throttleTime(1000),\n  map(({message: img}) => {\n    const faceLandmarks = faceLandmarker.detect(img).faceLandmarks;\n    if (faceLandmarks.length === 0)\n        return \"c\";\n    const [x,y,z] = calculateCentroid(faceLandmarks[0]);\n    const distance = visionLine-x;\n    const relativeDistance = Math.abs(distance)/x;\n    return relativeDistance <= threshold ? \"NONE\" : distance > 0 ? \"l\" : \"r\";\n  }),\n  rewrite()\n)",
                      "language": "javascript",
                      "output": "NONE"
                    },
                    "index": 1,
                    "lastEditedBy": "f313b510-8ff6-4ef7-8c27-070c2ae45fc1",
                    "_deleted": false
                  }
                }
              }
            ],
            "creator": "pkhexmkwbs",
            "time": 1684303286028.01
          }
        ],
        [
          {
            "body": [
              {
                "ifMatch": {
                  "$set": {
                    "data": {
                      "code": "import {\n    FaceLandmarker,\n    FilesetResolver,\n    DrawingUtils\n} from \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0\";\n\nconst filesetResolver = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm\"\n);\n\n/* \n   TODO: I think this function introduce a high overhead, so it should be migrated to C++.\n*/\nfunction calculateCentroid(landmarks) {\n    const sum = landmarks.reduce((acc, landmark) => {\n        acc[0] = landmark.x + acc[0];\n        acc[1] = landmark.y + acc[1];\n        acc[2] = landmark.z + acc[2];\n        return acc;\n    }, [0, 0, 0]);\n    return sum.map(coord => coord / landmarks.length);\n}\n\nconst faceLandmarker = await FaceLandmarker.createFromOptions(filesetResolver, {\n    baseOptions: {\n        modelAssetPath: \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task\",\n        delegate: \"GPU\"\n    },\n    outputFaceBlendshapes: true,\n    runningMode: \"IMAGE\",\n    numFaces: 1\n});\n\n\nconst visionLine = 0.5;\nconst threshold = 0.2;\n\ncaptureStream().pipe(\n  throttleTime(1000),\n  map(({message: img}) => {\n    const faceLandmarks = faceLandmarker.detect(img).faceLandmarks;\n    if (faceLandmarks.length === 0)\n        return \"c\";\n    const [x,y,z] = calculateCentroid(faceLandmarks[0]);\n    const distance = visionLine-x;\n    const relativeDistance = Math.abs(distance)/x;\n    return relativeDistance <= threshold ? \"NONE\" : distance > 0 ? \"l\" : \"r\";\n  }),\n  rewrite()\n)",
                      "language": "javascript",
                      "output": "NONE"
                    },
                    "index": 1,
                    "lastEditedBy": "f313b510-8ff6-4ef7-8c27-070c2ae45fc1",
                    "_deleted": false
                  }
                }
              }
            ],
            "creator": "pkhexmkwbs",
            "time": 1684303287773.01
          }
        ],
        [
          {
            "body": [
              {
                "ifMatch": {
                  "$set": {
                    "data": {
                      "code": "import {\n    FaceLandmarker,\n    FilesetResolver,\n    DrawingUtils\n} from \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0\";\n\nconst filesetResolver = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm\"\n);\n\n/* \n   TODO: I think this function introduce a high overhead, so it should be migrated to C.\n*/\nfunction calculateCentroid(landmarks) {\n    const sum = landmarks.reduce((acc, landmark) => {\n        acc[0] = landmark.x + acc[0];\n        acc[1] = landmark.y + acc[1];\n        acc[2] = landmark.z + acc[2];\n        return acc;\n    }, [0, 0, 0]);\n    return sum.map(coord => coord / landmarks.length);\n}\n\nconst faceLandmarker = await FaceLandmarker.createFromOptions(filesetResolver, {\n    baseOptions: {\n        modelAssetPath: \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task\",\n        delegate: \"GPU\"\n    },\n    outputFaceBlendshapes: true,\n    runningMode: \"IMAGE\",\n    numFaces: 1\n});\n\n\nconst visionLine = 0.5;\nconst threshold = 0.2;\n\ncaptureStream().pipe(\n  throttleTime(1000),\n  map(({message: img}) => {\n    const faceLandmarks = faceLandmarker.detect(img).faceLandmarks;\n    if (faceLandmarks.length === 0)\n        return \"c\";\n    const [x,y,z] = calculateCentroid(faceLandmarks[0]);\n    const distance = visionLine-x;\n    const relativeDistance = Math.abs(distance)/x;\n    return relativeDistance <= threshold ? \"NONE\" : distance > 0 ? \"l\" : \"r\";\n  }),\n  rewrite()\n)",
                      "language": "javascript",
                      "output": "NONE"
                    },
                    "index": 1,
                    "lastEditedBy": "f313b510-8ff6-4ef7-8c27-070c2ae45fc1",
                    "_deleted": false
                  }
                }
              }
            ],
            "creator": "pkhexmkwbs",
            "time": 1684303289225.01
          }
        ],
        [
          {
            "body": [
              {
                "ifMatch": {
                  "$set": {
                    "data": {
                      "code": "import {\n    FaceLandmarker,\n    FilesetResolver,\n    DrawingUtils\n} from \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0\";\n\nconst filesetResolver = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm\"\n);\n\n/* \n   TODO: I think this function introduce a high overhead, so it should be migrated to WASM C.\n*/\nfunction calculateCentroid(landmarks) {\n    const sum = landmarks.reduce((acc, landmark) => {\n        acc[0] = landmark.x + acc[0];\n        acc[1] = landmark.y + acc[1];\n        acc[2] = landmark.z + acc[2];\n        return acc;\n    }, [0, 0, 0]);\n    return sum.map(coord => coord / landmarks.length);\n}\n\nconst faceLandmarker = await FaceLandmarker.createFromOptions(filesetResolver, {\n    baseOptions: {\n        modelAssetPath: \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task\",\n        delegate: \"GPU\"\n    },\n    outputFaceBlendshapes: true,\n    runningMode: \"IMAGE\",\n    numFaces: 1\n});\n\n\nconst visionLine = 0.5;\nconst threshold = 0.2;\n\ncaptureStream().pipe(\n  throttleTime(1000),\n  map(({message: img}) => {\n    const faceLandmarks = faceLandmarker.detect(img).faceLandmarks;\n    if (faceLandmarks.length === 0)\n        return \"c\";\n    const [x,y,z] = calculateCentroid(faceLandmarks[0]);\n    const distance = visionLine-x;\n    const relativeDistance = Math.abs(distance)/x;\n    return relativeDistance <= threshold ? \"NONE\" : distance > 0 ? \"l\" : \"r\";\n  }),\n  rewrite()\n)",
                      "language": "javascript",
                      "output": "NONE"
                    },
                    "index": 1,
                    "lastEditedBy": "f313b510-8ff6-4ef7-8c27-070c2ae45fc1",
                    "_deleted": false
                  }
                }
              }
            ],
            "creator": "pkhexmkwbs",
            "time": 1684303303598.02
          }
        ],
        [
          {
            "body": [
              {
                "ifMatch": {
                  "$set": {
                    "data": {
                      "code": "import {\n    FaceLandmarker,\n    FilesetResolver,\n    DrawingUtils\n} from \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0\";\n\nconst filesetResolver = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm\"\n);\n\n/* \n   TODO: I think this function introduce a high overhead, so it should be migrated to WASM C.\n*/\nfunction calculateCentroid(landmarks) {\n    const sum = landmarks.reduce((acc, landmark) => {\n        acc[0] = landmark.x + acc[0];\n        acc[1] = landmark.y + acc[1];\n        acc[2] = landmark.z + acc[2];\n        return acc;\n    }, [0, 0, 0]);\n    return sum.map(coord => coord / landmarks.length);\n}\n\nconst faceLandmarker = await FaceLandmarker.createFromOptions(filesetResolver, {\n    baseOptions: {\n        modelAssetPath: \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task\",\n        delegate: \"GPU\"\n    },\n    outputFaceBlendshapes: false,\n    runningMode: \"IMAGE\",\n    numFaces: 1\n});\n\n\nconst visionLine = 0.5;\nconst threshold = 0.2;\n\ncaptureStream().pipe(\n  throttleTime(1000),\n  map(({message: img}) => {\n    const faceLandmarks = faceLandmarker.detect(img).faceLandmarks;\n    if (faceLandmarks.length === 0)\n        return \"c\";\n    const [x,y,z] = calculateCentroid(faceLandmarks[0]);\n    const distance = visionLine-x;\n    const relativeDistance = Math.abs(distance)/x;\n    return relativeDistance <= threshold ? \"NONE\" : distance > 0 ? \"l\" : \"r\";\n  }),\n  rewrite()\n)",
                      "language": "javascript",
                      "output": "NONE"
                    },
                    "index": 5,
                    "lastEditedBy": "f313b510-8ff6-4ef7-8c27-070c2ae45fc1",
                    "_deleted": false
                  }
                }
              }
            ],
            "creator": "pkhexmkwbs",
            "time": 1684303827377.01
          }
        ]
      ],
      "hash": "1a930bb6f5f888885d60a9f58ce12dc8c707da812148d170f1b7a9dbbbdda063"
    },
    "_meta": {
      "lwt": 1684303827381.01
    },
    "_deleted": false,
    "_attachments": {},
    "_rev": "182-lxgnmepxds"
  },
  {
    "id": "wirInDdcHN",
    "type": "header",
    "data": {
      "text": "Track aliveness human",
      "level": 1
    },
    "index": 5,
    "createdBy": "f313b510-8ff6-4ef7-8c27-070c2ae45fc1",
    "lastEditedBy": "f313b510-8ff6-4ef7-8c27-070c2ae45fc1",
    "topic": "c70506cc-aefb-479a-9eee-9f7ef37b9d2c",
    "crdts": {
      "operations": [
        [
          {
            "creator": "pkhexmkwbs",
            "body": [
              {
                "ifMatch": {
                  "$set": {
                    "id": "wirInDdcHN",
                    "type": "header",
                    "data": {
                      "text": "",
                      "level": 2
                    },
                    "index": 0,
                    "createdBy": "f313b510-8ff6-4ef7-8c27-070c2ae45fc1",
                    "lastEditedBy": "f313b510-8ff6-4ef7-8c27-070c2ae45fc1",
                    "topic": "c70506cc-aefb-479a-9eee-9f7ef37b9d2c"
                  }
                }
              }
            ],
            "time": 1684302246467.02
          }
        ],
        [
          {
            "body": [
              {
                "ifMatch": {
                  "$set": {
                    "data": {
                      "text": "Move camera",
                      "level": 2
                    },
                    "index": 0,
                    "lastEditedBy": "f313b510-8ff6-4ef7-8c27-070c2ae45fc1",
                    "_deleted": false
                  }
                }
              }
            ],
            "creator": "pkhexmkwbs",
            "time": 1684302249989.06
          }
        ],
        [
          {
            "body": [
              {
                "ifMatch": {
                  "$set": {
                    "data": {
                      "text": "Move camera",
                      "level": 1
                    },
                    "index": 0,
                    "lastEditedBy": "f313b510-8ff6-4ef7-8c27-070c2ae45fc1",
                    "_deleted": false
                  }
                }
              }
            ],
            "creator": "pkhexmkwbs",
            "time": 1684302252432.06
          }
        ],
        [
          {
            "body": [
              {
                "ifMatch": {
                  "$set": {
                    "data": {
                      "text": "Track&nbsp;",
                      "level": 1
                    },
                    "index": 0,
                    "lastEditedBy": "f313b510-8ff6-4ef7-8c27-070c2ae45fc1",
                    "_deleted": false
                  }
                }
              }
            ],
            "creator": "pkhexmkwbs",
            "time": 1684302256112.01
          }
        ],
        [
          {
            "body": [
              {
                "ifMatch": {
                  "$set": {
                    "data": {
                      "text": "Track human",
                      "level": 1
                    },
                    "index": 0,
                    "lastEditedBy": "f313b510-8ff6-4ef7-8c27-070c2ae45fc1",
                    "_deleted": false
                  }
                }
              }
            ],
            "creator": "pkhexmkwbs",
            "time": 1684302259432.01
          }
        ],
        [
          {
            "body": [
              {
                "ifMatch": {
                  "$set": {
                    "data": {
                      "text": "Track liveness human",
                      "level": 1
                    },
                    "index": 0,
                    "lastEditedBy": "f313b510-8ff6-4ef7-8c27-070c2ae45fc1",
                    "_deleted": false
                  }
                }
              }
            ],
            "creator": "pkhexmkwbs",
            "time": 1684302266048.01
          }
        ],
        [
          {
            "body": [
              {
                "ifMatch": {
                  "$set": {
                    "data": {
                      "text": "Track aliveness human",
                      "level": 1
                    },
                    "index": 0,
                    "lastEditedBy": "f313b510-8ff6-4ef7-8c27-070c2ae45fc1",
                    "_deleted": false
                  }
                }
              }
            ],
            "creator": "pkhexmkwbs",
            "time": 1684302270000.01
          }
        ]
      ],
      "hash": "5f79c8793ce28a4f1268f7a953cd6e9d51c247aaec0ce668f89a82c8917745ae"
    },
    "_meta": {
      "lwt": 1684303701722.03
    },
    "_deleted": false,
    "_attachments": {},
    "_rev": "13-lxgnmepxds"
  },
  {
    "id": "XjqJQcINAA",
    "type": "header",
    "data": {
      "text": "Track aliveness human with MQTT and EVA",
      "level": 1
    },
    "index": 6,
    "createdBy": "f313b510-8ff6-4ef7-8c27-070c2ae45fc1",
    "lastEditedBy": "f313b510-8ff6-4ef7-8c27-070c2ae45fc1",
    "topic": "c70506cc-aefb-479a-9eee-9f7ef37b9d2c",
    "crdts": {
      "operations": [
        [
          {
            "creator": "pkhexmkwbs",
            "body": [
              {
                "ifMatch": {
                  "$set": {
                    "id": "XjqJQcINAA",
                    "type": "header",
                    "data": {
                      "text": "",
                      "level": 2
                    },
                    "index": 2,
                    "createdBy": "f313b510-8ff6-4ef7-8c27-070c2ae45fc1",
                    "lastEditedBy": "f313b510-8ff6-4ef7-8c27-070c2ae45fc1",
                    "topic": "c70506cc-aefb-479a-9eee-9f7ef37b9d2c"
                  }
                }
              }
            ],
            "time": 1684303640966.02
          }
        ],
        [
          {
            "body": [
              {
                "ifMatch": {
                  "$set": {
                    "data": {
                      "text": "Tracj",
                      "level": 2
                    },
                    "index": 2,
                    "lastEditedBy": "f313b510-8ff6-4ef7-8c27-070c2ae45fc1",
                    "_deleted": false
                  }
                }
              }
            ],
            "creator": "pkhexmkwbs",
            "time": 1684303643192.06
          }
        ],
        [
          {
            "body": [
              {
                "ifMatch": {
                  "$set": {
                    "data": {
                      "text": "Track ali",
                      "level": 2
                    },
                    "index": 2,
                    "lastEditedBy": "f313b510-8ff6-4ef7-8c27-070c2ae45fc1",
                    "_deleted": false
                  }
                }
              }
            ],
            "creator": "pkhexmkwbs",
            "time": 1684303644744.01
          }
        ],
        [
          {
            "body": [
              {
                "ifMatch": {
                  "$set": {
                    "data": {
                      "text": "Track alivness",
                      "level": 2
                    },
                    "index": 2,
                    "lastEditedBy": "f313b510-8ff6-4ef7-8c27-070c2ae45fc1",
                    "_deleted": false
                  }
                }
              }
            ],
            "creator": "pkhexmkwbs",
            "time": 1684303645904.01
          }
        ],
        [
          {
            "body": [
              {
                "ifMatch": {
                  "$set": {
                    "data": {
                      "text": "Track aliveness",
                      "level": 2
                    },
                    "index": 2,
                    "lastEditedBy": "f313b510-8ff6-4ef7-8c27-070c2ae45fc1",
                    "_deleted": false
                  }
                }
              }
            ],
            "creator": "pkhexmkwbs",
            "time": 1684303649312.01
          }
        ],
        [
          {
            "body": [
              {
                "ifMatch": {
                  "$set": {
                    "data": {
                      "text": "Track aliveness human with&nbsp;",
                      "level": 2
                    },
                    "index": 2,
                    "lastEditedBy": "f313b510-8ff6-4ef7-8c27-070c2ae45fc1",
                    "_deleted": false
                  }
                }
              }
            ],
            "creator": "pkhexmkwbs",
            "time": 1684303653960.01
          }
        ],
        [
          {
            "body": [
              {
                "ifMatch": {
                  "$set": {
                    "data": {
                      "text": "Track aliveness human with MQTT",
                      "level": 2
                    },
                    "index": 2,
                    "lastEditedBy": "f313b510-8ff6-4ef7-8c27-070c2ae45fc1",
                    "_deleted": false
                  }
                }
              }
            ],
            "creator": "pkhexmkwbs",
            "time": 1684303655616.01
          }
        ],
        [
          {
            "body": [
              {
                "ifMatch": {
                  "$set": {
                    "data": {
                      "text": "Track aliveness human with MQTT and EVA",
                      "level": 2
                    },
                    "index": 2,
                    "lastEditedBy": "f313b510-8ff6-4ef7-8c27-070c2ae45fc1",
                    "_deleted": false
                  }
                }
              }
            ],
            "creator": "pkhexmkwbs",
            "time": 1684303657888.01
          }
        ],
        [
          {
            "body": [
              {
                "ifMatch": {
                  "$set": {
                    "data": {
                      "text": "Track aliveness human with MQTT and EVA",
                      "level": 1
                    },
                    "index": 2,
                    "lastEditedBy": "f313b510-8ff6-4ef7-8c27-070c2ae45fc1",
                    "_deleted": false
                  }
                }
              }
            ],
            "creator": "pkhexmkwbs",
            "time": 1684303661032.04
          }
        ]
      ],
      "hash": "5d1cec8a8e17d24c529476fb3913efe43a3606ccc685b0977dc312fd01b4ba4f"
    },
    "_meta": {
      "lwt": 1684303860001.01
    },
    "_deleted": false,
    "_attachments": {},
    "_rev": "16-lxgnmepxds"
  },
  {
    "id": "mGaaOWGgLc",
    "type": "code",
    "data": {
      "code": "import {\n    FaceLandmarker,\n    FilesetResolver,\n    DrawingUtils\n} from \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0\";\n\nconst filesetResolver = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm\"\n);\n\n/* \n   TODO: I think this function introduce a high overhead, so it should be migrated to WASM C.\n*/\nfunction calculateCentroid(landmarks) {\n    const sum = landmarks.reduce((acc, landmark) => {\n        acc[0] = landmark.x + acc[0];\n        acc[1] = landmark.y + acc[1];\n        acc[2] = landmark.z + acc[2];\n        return acc;\n    }, [0, 0, 0]);\n    return sum.map(coord => coord / landmarks.length);\n}\n\nconst faceLandmarker = await FaceLandmarker.createFromOptions(filesetResolver, {\n    baseOptions: {\n        modelAssetPath: \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task\",\n        delegate: \"GPU\"\n    },\n    outputFaceBlendshapes: false,\n    runningMode: \"IMAGE\",\n    numFaces: 1\n});\n\n\nconst visionLine = 0.5;\nconst threshold = 0.2;\n\nconnect(\"\", {\n   \n}).pipe(\n  throttleTime(1000),\n  map(({message: img}) => {\n    const faceLandmarks = faceLandmarker.detect(img).faceLandmarks;\n    if (faceLandmarks.length === 0)\n        return \"c\";\n    const [x,y,z] = calculateCentroid(faceLandmarks[0]);\n    const distance = visionLine-x;\n    const relativeDistance = Math.abs(distance)/x;\n    return relativeDistance <= threshold ? \"NONE\" : distance > 0 ? \"l\" : \"r\";\n  }),\n  rewrite()\n)",
      "language": "javascript",
      "output": ""
    },
    "index": 7,
    "createdBy": "f313b510-8ff6-4ef7-8c27-070c2ae45fc1",
    "lastEditedBy": "f313b510-8ff6-4ef7-8c27-070c2ae45fc1",
    "topic": "c70506cc-aefb-479a-9eee-9f7ef37b9d2c",
    "crdts": {
      "operations": [
        [
          {
            "creator": "pkhexmkwbs",
            "body": [
              {
                "ifMatch": {
                  "$set": {
                    "id": "mGaaOWGgLc",
                    "type": "code",
                    "data": {
                      "code": "",
                      "language": "javascript",
                      "output": ""
                    },
                    "index": 7,
                    "createdBy": "f313b510-8ff6-4ef7-8c27-070c2ae45fc1",
                    "lastEditedBy": "f313b510-8ff6-4ef7-8c27-070c2ae45fc1",
                    "topic": "c70506cc-aefb-479a-9eee-9f7ef37b9d2c"
                  }
                }
              }
            ],
            "time": 1684303862130.02
          }
        ],
        [
          {
            "body": [
              {
                "ifMatch": {
                  "$set": {
                    "data": {
                      "code": "import {\n    FaceLandmarker,\n    FilesetResolver,\n    DrawingUtils\n} from \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0\";\n\nconst filesetResolver = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm\"\n);\n\n/* \n   TODO: I think this function introduce a high overhead, so it should be migrated to WASM C.\n*/\nfunction calculateCentroid(landmarks) {\n    const sum = landmarks.reduce((acc, landmark) => {\n        acc[0] = landmark.x + acc[0];\n        acc[1] = landmark.y + acc[1];\n        acc[2] = landmark.z + acc[2];\n        return acc;\n    }, [0, 0, 0]);\n    return sum.map(coord => coord / landmarks.length);\n}\n\nconst faceLandmarker = await FaceLandmarker.createFromOptions(filesetResolver, {\n    baseOptions: {\n        modelAssetPath: \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task\",\n        delegate: \"GPU\"\n    },\n    outputFaceBlendshapes: false,\n    runningMode: \"IMAGE\",\n    numFaces: 1\n});\n\n\nconst visionLine = 0.5;\nconst threshold = 0.2;\n\ncaptureStream().pipe(\n  throttleTime(1000),\n  map(({message: img}) => {\n    const faceLandmarks = faceLandmarker.detect(img).faceLandmarks;\n    if (faceLandmarks.length === 0)\n        return \"c\";\n    const [x,y,z] = calculateCentroid(faceLandmarks[0]);\n    const distance = visionLine-x;\n    const relativeDistance = Math.abs(distance)/x;\n    return relativeDistance <= threshold ? \"NONE\" : distance > 0 ? \"l\" : \"r\";\n  }),\n  rewrite()\n)",
                      "language": "javascript",
                      "output": ""
                    },
                    "index": 7,
                    "lastEditedBy": "f313b510-8ff6-4ef7-8c27-070c2ae45fc1",
                    "_deleted": false
                  }
                }
              }
            ],
            "creator": "pkhexmkwbs",
            "time": 1684303863049.01
          }
        ],
        [
          {
            "body": [
              {
                "ifMatch": {
                  "$set": {
                    "data": {
                      "code": "import {\n    FaceLandmarker,\n    FilesetResolver,\n    DrawingUtils\n} from \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0\";\n\nconst filesetResolver = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm\"\n);\n\n/* \n   TODO: I think this function introduce a high overhead, so it should be migrated to WASM C.\n*/\nfunction calculateCentroid(landmarks) {\n    const sum = landmarks.reduce((acc, landmark) => {\n        acc[0] = landmark.x + acc[0];\n        acc[1] = landmark.y + acc[1];\n        acc[2] = landmark.z + acc[2];\n        return acc;\n    }, [0, 0, 0]);\n    return sum.map(coord => coord / landmarks.length);\n}\n\nconst faceLandmarker = await FaceLandmarker.createFromOptions(filesetResolver, {\n    baseOptions: {\n        modelAssetPath: \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task\",\n        delegate: \"GPU\"\n    },\n    outputFaceBlendshapes: false,\n    runningMode: \"IMAGE\",\n    numFaces: 1\n});\n\n\nconst visionLine = 0.5;\nconst threshold = 0.2;\n\nconnect.pipe(\n  throttleTime(1000),\n  map(({message: img}) => {\n    const faceLandmarks = faceLandmarker.detect(img).faceLandmarks;\n    if (faceLandmarks.length === 0)\n        return \"c\";\n    const [x,y,z] = calculateCentroid(faceLandmarks[0]);\n    const distance = visionLine-x;\n    const relativeDistance = Math.abs(distance)/x;\n    return relativeDistance <= threshold ? \"NONE\" : distance > 0 ? \"l\" : \"r\";\n  }),\n  rewrite()\n)",
                      "language": "javascript",
                      "output": ""
                    },
                    "index": 7,
                    "lastEditedBy": "f313b510-8ff6-4ef7-8c27-070c2ae45fc1",
                    "_deleted": false
                  }
                }
              }
            ],
            "creator": "pkhexmkwbs",
            "time": 1684304258800.02
          }
        ],
        [
          {
            "body": [
              {
                "ifMatch": {
                  "$set": {
                    "data": {
                      "code": "import {\n    FaceLandmarker,\n    FilesetResolver,\n    DrawingUtils\n} from \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0\";\n\nconst filesetResolver = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm\"\n);\n\n/* \n   TODO: I think this function introduce a high overhead, so it should be migrated to WASM C.\n*/\nfunction calculateCentroid(landmarks) {\n    const sum = landmarks.reduce((acc, landmark) => {\n        acc[0] = landmark.x + acc[0];\n        acc[1] = landmark.y + acc[1];\n        acc[2] = landmark.z + acc[2];\n        return acc;\n    }, [0, 0, 0]);\n    return sum.map(coord => coord / landmarks.length);\n}\n\nconst faceLandmarker = await FaceLandmarker.createFromOptions(filesetResolver, {\n    baseOptions: {\n        modelAssetPath: \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task\",\n        delegate: \"GPU\"\n    },\n    outputFaceBlendshapes: false,\n    runningMode: \"IMAGE\",\n    numFaces: 1\n});\n\n\nconst visionLine = 0.5;\nconst threshold = 0.2;\n\nconnect(.pipe(\n  throttleTime(1000),\n  map(({message: img}) => {\n    const faceLandmarks = faceLandmarker.detect(img).faceLandmarks;\n    if (faceLandmarks.length === 0)\n        return \"c\";\n    const [x,y,z] = calculateCentroid(faceLandmarks[0]);\n    const distance = visionLine-x;\n    const relativeDistance = Math.abs(distance)/x;\n    return relativeDistance <= threshold ? \"NONE\" : distance > 0 ? \"l\" : \"r\";\n  }),\n  rewrite()\n)",
                      "language": "javascript",
                      "output": ""
                    },
                    "index": 7,
                    "lastEditedBy": "f313b510-8ff6-4ef7-8c27-070c2ae45fc1",
                    "_deleted": false
                  }
                }
              }
            ],
            "creator": "pkhexmkwbs",
            "time": 1684304259312.06
          }
        ],
        [
          {
            "body": [
              {
                "ifMatch": {
                  "$set": {
                    "data": {
                      "code": "import {\n    FaceLandmarker,\n    FilesetResolver,\n    DrawingUtils\n} from \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0\";\n\nconst filesetResolver = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm\"\n);\n\n/* \n   TODO: I think this function introduce a high overhead, so it should be migrated to WASM C.\n*/\nfunction calculateCentroid(landmarks) {\n    const sum = landmarks.reduce((acc, landmark) => {\n        acc[0] = landmark.x + acc[0];\n        acc[1] = landmark.y + acc[1];\n        acc[2] = landmark.z + acc[2];\n        return acc;\n    }, [0, 0, 0]);\n    return sum.map(coord => coord / landmarks.length);\n}\n\nconst faceLandmarker = await FaceLandmarker.createFromOptions(filesetResolver, {\n    baseOptions: {\n        modelAssetPath: \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task\",\n        delegate: \"GPU\"\n    },\n    outputFaceBlendshapes: false,\n    runningMode: \"IMAGE\",\n    numFaces: 1\n});\n\n\nconst visionLine = 0.5;\nconst threshold = 0.2;\n\nconnect().pipe(\n  throttleTime(1000),\n  map(({message: img}) => {\n    const faceLandmarks = faceLandmarker.detect(img).faceLandmarks;\n    if (faceLandmarks.length === 0)\n        return \"c\";\n    const [x,y,z] = calculateCentroid(faceLandmarks[0]);\n    const distance = visionLine-x;\n    const relativeDistance = Math.abs(distance)/x;\n    return relativeDistance <= threshold ? \"NONE\" : distance > 0 ? \"l\" : \"r\";\n  }),\n  rewrite()\n)",
                      "language": "javascript",
                      "output": ""
                    },
                    "index": 7,
                    "lastEditedBy": "f313b510-8ff6-4ef7-8c27-070c2ae45fc1",
                    "_deleted": false
                  }
                }
              }
            ],
            "creator": "pkhexmkwbs",
            "time": 1684304259944.06
          }
        ],
        [
          {
            "body": [
              {
                "ifMatch": {
                  "$set": {
                    "data": {
                      "code": "import {\n    FaceLandmarker,\n    FilesetResolver,\n    DrawingUtils\n} from \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0\";\n\nconst filesetResolver = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm\"\n);\n\n/* \n   TODO: I think this function introduce a high overhead, so it should be migrated to WASM C.\n*/\nfunction calculateCentroid(landmarks) {\n    const sum = landmarks.reduce((acc, landmark) => {\n        acc[0] = landmark.x + acc[0];\n        acc[1] = landmark.y + acc[1];\n        acc[2] = landmark.z + acc[2];\n        return acc;\n    }, [0, 0, 0]);\n    return sum.map(coord => coord / landmarks.length);\n}\n\nconst faceLandmarker = await FaceLandmarker.createFromOptions(filesetResolver, {\n    baseOptions: {\n        modelAssetPath: \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task\",\n        delegate: \"GPU\"\n    },\n    outputFaceBlendshapes: false,\n    runningMode: \"IMAGE\",\n    numFaces: 1\n});\n\n\nconst visionLine = 0.5;\nconst threshold = 0.2;\n\nconnect(\"\", ).pipe(\n  throttleTime(1000),\n  map(({message: img}) => {\n    const faceLandmarks = faceLandmarker.detect(img).faceLandmarks;\n    if (faceLandmarks.length === 0)\n        return \"c\";\n    const [x,y,z] = calculateCentroid(faceLandmarks[0]);\n    const distance = visionLine-x;\n    const relativeDistance = Math.abs(distance)/x;\n    return relativeDistance <= threshold ? \"NONE\" : distance > 0 ? \"l\" : \"r\";\n  }),\n  rewrite()\n)",
                      "language": "javascript",
                      "output": ""
                    },
                    "index": 7,
                    "lastEditedBy": "f313b510-8ff6-4ef7-8c27-070c2ae45fc1",
                    "_deleted": false
                  }
                }
              }
            ],
            "creator": "pkhexmkwbs",
            "time": 1684304262256.06
          }
        ],
        [
          {
            "body": [
              {
                "ifMatch": {
                  "$set": {
                    "data": {
                      "code": "import {\n    FaceLandmarker,\n    FilesetResolver,\n    DrawingUtils\n} from \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0\";\n\nconst filesetResolver = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm\"\n);\n\n/* \n   TODO: I think this function introduce a high overhead, so it should be migrated to WASM C.\n*/\nfunction calculateCentroid(landmarks) {\n    const sum = landmarks.reduce((acc, landmark) => {\n        acc[0] = landmark.x + acc[0];\n        acc[1] = landmark.y + acc[1];\n        acc[2] = landmark.z + acc[2];\n        return acc;\n    }, [0, 0, 0]);\n    return sum.map(coord => coord / landmarks.length);\n}\n\nconst faceLandmarker = await FaceLandmarker.createFromOptions(filesetResolver, {\n    baseOptions: {\n        modelAssetPath: \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task\",\n        delegate: \"GPU\"\n    },\n    outputFaceBlendshapes: false,\n    runningMode: \"IMAGE\",\n    numFaces: 1\n});\n\n\nconst visionLine = 0.5;\nconst threshold = 0.2;\n\nconnect(\"\", {\n  \n}).pipe(\n  throttleTime(1000),\n  map(({message: img}) => {\n    const faceLandmarks = faceLandmarker.detect(img).faceLandmarks;\n    if (faceLandmarks.length === 0)\n        return \"c\";\n    const [x,y,z] = calculateCentroid(faceLandmarks[0]);\n    const distance = visionLine-x;\n    const relativeDistance = Math.abs(distance)/x;\n    return relativeDistance <= threshold ? \"NONE\" : distance > 0 ? \"l\" : \"r\";\n  }),\n  rewrite()\n)",
                      "language": "javascript",
                      "output": ""
                    },
                    "index": 7,
                    "lastEditedBy": "f313b510-8ff6-4ef7-8c27-070c2ae45fc1",
                    "_deleted": false
                  }
                }
              }
            ],
            "creator": "pkhexmkwbs",
            "time": 1684304263312.06
          }
        ],
        [
          {
            "body": [
              {
                "ifMatch": {
                  "$set": {
                    "data": {
                      "code": "import {\n    FaceLandmarker,\n    FilesetResolver,\n    DrawingUtils\n} from \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0\";\n\nconst filesetResolver = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm\"\n);\n\n/* \n   TODO: I think this function introduce a high overhead, so it should be migrated to WASM C.\n*/\nfunction calculateCentroid(landmarks) {\n    const sum = landmarks.reduce((acc, landmark) => {\n        acc[0] = landmark.x + acc[0];\n        acc[1] = landmark.y + acc[1];\n        acc[2] = landmark.z + acc[2];\n        return acc;\n    }, [0, 0, 0]);\n    return sum.map(coord => coord / landmarks.length);\n}\n\nconst faceLandmarker = await FaceLandmarker.createFromOptions(filesetResolver, {\n    baseOptions: {\n        modelAssetPath: \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task\",\n        delegate: \"GPU\"\n    },\n    outputFaceBlendshapes: false,\n    runningMode: \"IMAGE\",\n    numFaces: 1\n});\n\n\nconst visionLine = 0.5;\nconst threshold = 0.2;\n\nconnect(\"\", {\n   \n}).pipe(\n  throttleTime(1000),\n  map(({message: img}) => {\n    const faceLandmarks = faceLandmarker.detect(img).faceLandmarks;\n    if (faceLandmarks.length === 0)\n        return \"c\";\n    const [x,y,z] = calculateCentroid(faceLandmarks[0]);\n    const distance = visionLine-x;\n    const relativeDistance = Math.abs(distance)/x;\n    return relativeDistance <= threshold ? \"NONE\" : distance > 0 ? \"l\" : \"r\";\n  }),\n  rewrite()\n)",
                      "language": "javascript",
                      "output": ""
                    },
                    "index": 7,
                    "lastEditedBy": "f313b510-8ff6-4ef7-8c27-070c2ae45fc1",
                    "_deleted": false
                  }
                }
              }
            ],
            "creator": "pkhexmkwbs",
            "time": 1684304265640.06
          }
        ]
      ],
      "hash": "7d9cd81ba04072c56508e8529c5f3b80fb6151beb4360c1db714f3d60de3415b"
    },
    "_meta": {
      "lwt": 1684304265641.01
    },
    "_deleted": false,
    "_attachments": {},
    "_rev": "9-lxgnmepxds"
  },
  {
    "id": "pDqGq08a4s",
    "type": "header",
    "data": {
      "text": "Replication",
      "level": 1
    },
    "index": 8,
    "createdBy": "f313b510-8ff6-4ef7-8c27-070c2ae45fc1",
    "lastEditedBy": "f313b510-8ff6-4ef7-8c27-070c2ae45fc1",
    "topic": "c70506cc-aefb-479a-9eee-9f7ef37b9d2c",
    "crdts": {
      "operations": [
        [
          {
            "creator": "pkhexmkwbs",
            "body": [
              {
                "ifMatch": {
                  "$set": {
                    "id": "pDqGq08a4s",
                    "type": "header",
                    "data": {
                      "text": "",
                      "level": 2
                    },
                    "index": 8,
                    "createdBy": "f313b510-8ff6-4ef7-8c27-070c2ae45fc1",
                    "lastEditedBy": "f313b510-8ff6-4ef7-8c27-070c2ae45fc1",
                    "topic": "c70506cc-aefb-479a-9eee-9f7ef37b9d2c"
                  }
                }
              }
            ],
            "time": 1684304281020.02
          }
        ],
        [
          {
            "body": [
              {
                "ifMatch": {
                  "$set": {
                    "data": {
                      "text": "",
                      "level": 1
                    },
                    "index": 8,
                    "lastEditedBy": "f313b510-8ff6-4ef7-8c27-070c2ae45fc1",
                    "_deleted": false
                  }
                }
              }
            ],
            "creator": "pkhexmkwbs",
            "time": 1684304284460.03
          }
        ],
        [
          {
            "body": [
              {
                "ifMatch": {
                  "$set": {
                    "data": {
                      "text": "Replication",
                      "level": 1
                    },
                    "index": 8,
                    "lastEditedBy": "f313b510-8ff6-4ef7-8c27-070c2ae45fc1",
                    "_deleted": false
                  }
                }
              }
            ],
            "creator": "pkhexmkwbs",
            "time": 1684304288704.01
          }
        ]
      ],
      "hash": "a45ab56e61b2b3ead25c95496b2f4fc6ac75660603f10125c2a4735c83756586"
    },
    "_meta": {
      "lwt": 1684304288704.02
    },
    "_deleted": false,
    "_attachments": {},
    "_rev": "4-lxgnmepxds"
  },
  {
    "id": "fqMZ7pDmbQ",
    "type": "code",
    "data": {
      "code": "const options = {\n    owner: \"sanchezcarlosjr\",\n    repo: \"computer-vision-and-graphics\",\n    filePath: \"assets/evanotebooks/9-track-human-real-time.json\",\n    commitMessage: \"Track human in real time\",\n    GITHUB_TOKEN: environment.GITHUB_TOKEN\n}\n\neditor.blocks.get$.pipe(\n  first(),\n  map(content =>\n    btoa(unescape(encodeURIComponent(JSON.stringify(content, null, 2).replaceAll(environment.GITHUB_TOKEN, \"\"))))),\n  commitOnGitHub(options)\n)",
      "language": "javascript",
      "output": ""
    },
    "index": 9,
    "createdBy": "f313b510-8ff6-4ef7-8c27-070c2ae45fc1",
    "lastEditedBy": "f313b510-8ff6-4ef7-8c27-070c2ae45fc1",
    "topic": "c70506cc-aefb-479a-9eee-9f7ef37b9d2c",
    "crdts": {
      "operations": [
        [
          {
            "creator": "pkhexmkwbs",
            "body": [
              {
                "ifMatch": {
                  "$set": {
                    "id": "fqMZ7pDmbQ",
                    "type": "code",
                    "data": {
                      "code": "",
                      "language": "javascript",
                      "output": ""
                    },
                    "index": 9,
                    "createdBy": "f313b510-8ff6-4ef7-8c27-070c2ae45fc1",
                    "lastEditedBy": "f313b510-8ff6-4ef7-8c27-070c2ae45fc1",
                    "topic": "c70506cc-aefb-479a-9eee-9f7ef37b9d2c"
                  }
                }
              }
            ],
            "time": 1684304290951.02
          }
        ],
        [
          {
            "body": [
              {
                "ifMatch": {
                  "$set": {
                    "data": {
                      "code": "const options = {\n    owner: \"sanchezcarlosjr\",\n    repo: \"computer-vision-and-graphics\",\n    filePath: \"assets/evanotebooks/image-processing.json\",\n    commitMessage: \"Apply MediaPipe models, open your webcam and write your algoritms with OpenCV\",\n    GITHUB_TOKEN: \"\"\n}\n\neditor.blocks.get$.pipe(\n  first(),\n  map(content =>\n    btoa(unescape(encodeURIComponent(JSON.stringify(content, null, 2).replaceAll(options.GITHUB_TOKEN, \"\"))))),\n  commitOnGitHub(options)\n)",
                      "language": "javascript",
                      "output": ""
                    },
                    "index": 9,
                    "lastEditedBy": "f313b510-8ff6-4ef7-8c27-070c2ae45fc1",
                    "_deleted": false
                  }
                }
              }
            ],
            "creator": "pkhexmkwbs",
            "time": 1684304300181.02
          }
        ],
        [
          {
            "body": [
              {
                "ifMatch": {
                  "$set": {
                    "data": {
                      "code": "const options = {\n    owner: \"sanchezcarlosjr\",\n    repo: \"computer-vision-and-graphics\",\n    filePath: \"assets/evanotebooks/.json\",\n    commitMessage: \"Apply MediaPipe models, open your webcam and write your algoritms with OpenCV\",\n    GITHUB_TOKEN: \"\"\n}\n\neditor.blocks.get$.pipe(\n  first(),\n  map(content =>\n    btoa(unescape(encodeURIComponent(JSON.stringify(content, null, 2).replaceAll(options.GITHUB_TOKEN, \"\"))))),\n  commitOnGitHub(options)\n)",
                      "language": "javascript",
                      "output": ""
                    },
                    "index": 9,
                    "lastEditedBy": "f313b510-8ff6-4ef7-8c27-070c2ae45fc1",
                    "_deleted": false
                  }
                }
              }
            ],
            "creator": "pkhexmkwbs",
            "time": 1684304305808.01
          }
        ],
        [
          {
            "body": [
              {
                "ifMatch": {
                  "$set": {
                    "data": {
                      "code": "const options = {\n    owner: \"sanchezcarlosjr\",\n    repo: \"computer-vision-and-graphics\",\n    filePath: \"assets/evanotebooks/9-.json\",\n    commitMessage: \"Apply MediaPipe models, open your webcam and write your algoritms with OpenCV\",\n    GITHUB_TOKEN: \"\"\n}\n\neditor.blocks.get$.pipe(\n  first(),\n  map(content =>\n    btoa(unescape(encodeURIComponent(JSON.stringify(content, null, 2).replaceAll(options.GITHUB_TOKEN, \"\"))))),\n  commitOnGitHub(options)\n)",
                      "language": "javascript",
                      "output": ""
                    },
                    "index": 9,
                    "lastEditedBy": "f313b510-8ff6-4ef7-8c27-070c2ae45fc1",
                    "_deleted": false
                  }
                }
              }
            ],
            "creator": "pkhexmkwbs",
            "time": 1684304312008.02
          }
        ],
        [
          {
            "body": [
              {
                "ifMatch": {
                  "$set": {
                    "data": {
                      "code": "const options = {\n    owner: \"sanchezcarlosjr\",\n    repo: \"computer-vision-and-graphics\",\n    filePath: \"assets/evanotebooks/9-track-human.json\",\n    commitMessage: \"Apply MediaPipe models, open your webcam and write your algoritms with OpenCV\",\n    GITHUB_TOKEN: \"\"\n}\n\neditor.blocks.get$.pipe(\n  first(),\n  map(content =>\n    btoa(unescape(encodeURIComponent(JSON.stringify(content, null, 2).replaceAll(options.GITHUB_TOKEN, \"\"))))),\n  commitOnGitHub(options)\n)",
                      "language": "javascript",
                      "output": ""
                    },
                    "index": 9,
                    "lastEditedBy": "f313b510-8ff6-4ef7-8c27-070c2ae45fc1",
                    "_deleted": false
                  }
                }
              }
            ],
            "creator": "pkhexmkwbs",
            "time": 1684304319544.01
          }
        ],
        [
          {
            "body": [
              {
                "ifMatch": {
                  "$set": {
                    "data": {
                      "code": "const options = {\n    owner: \"sanchezcarlosjr\",\n    repo: \"computer-vision-and-graphics\",\n    filePath: \"assets/evanotebooks/9-track-human-real-time.json\",\n    commitMessage: \"Apply MediaPipe models, open your webcam and write your algoritms with OpenCV\",\n    GITHUB_TOKEN: \"\"\n}\n\neditor.blocks.get$.pipe(\n  first(),\n  map(content =>\n    btoa(unescape(encodeURIComponent(JSON.stringify(content, null, 2).replaceAll(options.GITHUB_TOKEN, \"\"))))),\n  commitOnGitHub(options)\n)",
                      "language": "javascript",
                      "output": ""
                    },
                    "index": 9,
                    "lastEditedBy": "f313b510-8ff6-4ef7-8c27-070c2ae45fc1",
                    "_deleted": false
                  }
                }
              }
            ],
            "creator": "pkhexmkwbs",
            "time": 1684304324128.01
          }
        ],
        [
          {
            "body": [
              {
                "ifMatch": {
                  "$set": {
                    "data": {
                      "code": "const options = {\n    owner: \"sanchezcarlosjr\",\n    repo: \"computer-vision-and-graphics\",\n    filePath: \"assets/evanotebooks/9-track-human-real-time.json\",\n    commitMessage: \"Track human real time\",\n    GITHUB_TOKEN: \"\"\n}\n\neditor.blocks.get$.pipe(\n  first(),\n  map(content =>\n    btoa(unescape(encodeURIComponent(JSON.stringify(content, null, 2).replaceAll(options.GITHUB_TOKEN, \"\"))))),\n  commitOnGitHub(options)\n)",
                      "language": "javascript",
                      "output": ""
                    },
                    "index": 9,
                    "lastEditedBy": "f313b510-8ff6-4ef7-8c27-070c2ae45fc1",
                    "_deleted": false
                  }
                }
              }
            ],
            "creator": "pkhexmkwbs",
            "time": 1684304330896.02
          }
        ],
        [
          {
            "body": [
              {
                "ifMatch": {
                  "$set": {
                    "data": {
                      "code": "const options = {\n    owner: \"sanchezcarlosjr\",\n    repo: \"computer-vision-and-graphics\",\n    filePath: \"assets/evanotebooks/9-track-human-real-time.json\",\n    commitMessage: \"Track human in real time\",\n    GITHUB_TOKEN: evn\n}\n\neditor.blocks.get$.pipe(\n  first(),\n  map(content =>\n    btoa(unescape(encodeURIComponent(JSON.stringify(content, null, 2).replaceAll(options.GITHUB_TOKEN, \"\"))))),\n  commitOnGitHub(options)\n)",
                      "language": "javascript",
                      "output": ""
                    },
                    "index": 9,
                    "lastEditedBy": "f313b510-8ff6-4ef7-8c27-070c2ae45fc1",
                    "_deleted": false
                  }
                }
              }
            ],
            "creator": "pkhexmkwbs",
            "time": 1684304334512.06
          }
        ],
        [
          {
            "body": [
              {
                "ifMatch": {
                  "$set": {
                    "data": {
                      "code": "const options = {\n    owner: \"sanchezcarlosjr\",\n    repo: \"computer-vision-and-graphics\",\n    filePath: \"assets/evanotebooks/9-track-human-real-time.json\",\n    commitMessage: \"Track human in real time\",\n    GITHUB_TOKEN: en\n}\n\neditor.blocks.get$.pipe(\n  first(),\n  map(content =>\n    btoa(unescape(encodeURIComponent(JSON.stringify(content, null, 2).replaceAll(options.GITHUB_TOKEN, \"\"))))),\n  commitOnGitHub(options)\n)",
                      "language": "javascript",
                      "output": ""
                    },
                    "index": 9,
                    "lastEditedBy": "f313b510-8ff6-4ef7-8c27-070c2ae45fc1",
                    "_deleted": false
                  }
                }
              }
            ],
            "creator": "pkhexmkwbs",
            "time": 1684304335536.02
          }
        ],
        [
          {
            "body": [
              {
                "ifMatch": {
                  "$set": {
                    "data": {
                      "code": "const options = {\n    owner: \"sanchezcarlosjr\",\n    repo: \"computer-vision-and-graphics\",\n    filePath: \"assets/evanotebooks/9-track-human-real-time.json\",\n    commitMessage: \"Track human in real time\",\n    GITHUB_TOKEN: env\n}\n\neditor.blocks.get$.pipe(\n  first(),\n  map(content =>\n    btoa(unescape(encodeURIComponent(JSON.stringify(content, null, 2).replaceAll(options.GITHUB_TOKEN, \"\"))))),\n  commitOnGitHub(options)\n)",
                      "language": "javascript",
                      "output": ""
                    },
                    "index": 9,
                    "lastEditedBy": "f313b510-8ff6-4ef7-8c27-070c2ae45fc1",
                    "_deleted": false
                  }
                }
              }
            ],
            "creator": "pkhexmkwbs",
            "time": 1684304336104.03
          }
        ],
        [
          {
            "body": [
              {
                "ifMatch": {
                  "$set": {
                    "data": {
                      "code": "const options = {\n    owner: \"sanchezcarlosjr\",\n    repo: \"computer-vision-and-graphics\",\n    filePath: \"assets/evanotebooks/9-track-human-real-time.json\",\n    commitMessage: \"Track human in real time\",\n    GITHUB_TOKEN: environment.\n}\n\neditor.blocks.get$.pipe(\n  first(),\n  map(content =>\n    btoa(unescape(encodeURIComponent(JSON.stringify(content, null, 2).replaceAll(options.GITHUB_TOKEN, \"\"))))),\n  commitOnGitHub(options)\n)",
                      "language": "javascript",
                      "output": ""
                    },
                    "index": 9,
                    "lastEditedBy": "f313b510-8ff6-4ef7-8c27-070c2ae45fc1",
                    "_deleted": false
                  }
                }
              }
            ],
            "creator": "pkhexmkwbs",
            "time": 1684304340392.06
          }
        ],
        [
          {
            "body": [
              {
                "ifMatch": {
                  "$set": {
                    "data": {
                      "code": "const options = {\n    owner: \"sanchezcarlosjr\",\n    repo: \"computer-vision-and-graphics\",\n    filePath: \"assets/evanotebooks/9-track-human-real-time.json\",\n    commitMessage: \"Track human in real time\",\n    GITHUB_TOKEN: environment.GITHUB\n}\n\neditor.blocks.get$.pipe(\n  first(),\n  map(content =>\n    btoa(unescape(encodeURIComponent(JSON.stringify(content, null, 2).replaceAll(options.GITHUB_TOKEN, \"\"))))),\n  commitOnGitHub(options)\n)",
                      "language": "javascript",
                      "output": ""
                    },
                    "index": 9,
                    "lastEditedBy": "f313b510-8ff6-4ef7-8c27-070c2ae45fc1",
                    "_deleted": false
                  }
                }
              }
            ],
            "creator": "pkhexmkwbs",
            "time": 1684304342704.01
          }
        ],
        [
          {
            "body": [
              {
                "ifMatch": {
                  "$set": {
                    "data": {
                      "code": "const options = {\n    owner: \"sanchezcarlosjr\",\n    repo: \"computer-vision-and-graphics\",\n    filePath: \"assets/evanotebooks/9-track-human-real-time.json\",\n    commitMessage: \"Track human in real time\",\n    GITHUB_TOKEN: environment.GITHUB_\n}\n\neditor.blocks.get$.pipe(\n  first(),\n  map(content =>\n    btoa(unescape(encodeURIComponent(JSON.stringify(content, null, 2).replaceAll(options.GITHUB_TOKEN, \"\"))))),\n  commitOnGitHub(options)\n)",
                      "language": "javascript",
                      "output": ""
                    },
                    "index": 9,
                    "lastEditedBy": "f313b510-8ff6-4ef7-8c27-070c2ae45fc1",
                    "_deleted": false
                  }
                }
              }
            ],
            "creator": "pkhexmkwbs",
            "time": 1684304343496.06
          }
        ],
        [
          {
            "body": [
              {
                "ifMatch": {
                  "$set": {
                    "data": {
                      "code": "const options = {\n    owner: \"sanchezcarlosjr\",\n    repo: \"computer-vision-and-graphics\",\n    filePath: \"assets/evanotebooks/9-track-human-real-time.json\",\n    commitMessage: \"Track human in real time\",\n    GITHUB_TOKEN: environment.GITHUB_TOKEN\n}\n\neditor.blocks.get$.pipe(\n  first(),\n  map(content =>\n    btoa(unescape(encodeURIComponent(JSON.stringify(content, null, 2).replaceAll(options.GITHUB_TOKEN, \"\"))))),\n  commitOnGitHub(options)\n)",
                      "language": "javascript",
                      "output": ""
                    },
                    "index": 9,
                    "lastEditedBy": "f313b510-8ff6-4ef7-8c27-070c2ae45fc1",
                    "_deleted": false
                  }
                }
              }
            ],
            "creator": "pkhexmkwbs",
            "time": 1684304344704.06
          }
        ],
        [
          {
            "body": [
              {
                "ifMatch": {
                  "$set": {
                    "data": {
                      "code": "const options = {\n    owner: \"sanchezcarlosjr\",\n    repo: \"computer-vision-and-graphics\",\n    filePath: \"assets/evanotebooks/9-track-human-real-time.json\",\n    commitMessage: \"Track human in real time\",\n    GITHUB_TOKEN: environment.GITHUB_TOKEN\n}\n\neditor.blocks.get$.pipe(\n  first(),\n  map(content =>\n    btoa(unescape(encodeURIComponent(JSON.stringify(content, null, 2).replaceAll(environment.GITHUB_TOKEN, \"\"))))),\n  commitOnGitHub(options)\n)",
                      "language": "javascript",
                      "output": ""
                    },
                    "index": 9,
                    "lastEditedBy": "f313b510-8ff6-4ef7-8c27-070c2ae45fc1",
                    "_deleted": false
                  }
                }
              }
            ],
            "creator": "pkhexmkwbs",
            "time": 1684304350721.02
          }
        ]
      ],
      "hash": "3796cac6fa274c37141aa8546b1cd93c6fb84ae274a504aa8311bad537978bc7"
    },
    "_meta": {
      "lwt": 1684304350722.01
    },
    "_deleted": false,
    "_attachments": {},
    "_rev": "16-lxgnmepxds"
  },
  {
    "id": "9p8QTcmB7w",
    "type": "paragraph",
    "data": {
      "text": ""
    },
    "index": 10,
    "createdBy": "f313b510-8ff6-4ef7-8c27-070c2ae45fc1",
    "lastEditedBy": "f313b510-8ff6-4ef7-8c27-070c2ae45fc1",
    "topic": "c70506cc-aefb-479a-9eee-9f7ef37b9d2c",
    "crdts": {
      "operations": [
        [
          {
            "creator": "pkhexmkwbs",
            "body": [
              {
                "ifMatch": {
                  "$set": {
                    "id": "9p8QTcmB7w",
                    "type": "paragraph",
                    "data": {
                      "text": ""
                    },
                    "index": 8,
                    "createdBy": "f313b510-8ff6-4ef7-8c27-070c2ae45fc1",
                    "lastEditedBy": "f313b510-8ff6-4ef7-8c27-070c2ae45fc1",
                    "topic": "c70506cc-aefb-479a-9eee-9f7ef37b9d2c"
                  }
                }
              }
            ],
            "time": 1684303873160.02
          }
        ],
        [
          {
            "body": [
              {
                "ifMatch": {
                  "$set": {
                    "data": {
                      "text": "R"
                    },
                    "index": 9,
                    "lastEditedBy": "f313b510-8ff6-4ef7-8c27-070c2ae45fc1",
                    "_deleted": false
                  }
                }
              }
            ],
            "creator": "pkhexmkwbs",
            "time": 1684304285992.03
          }
        ],
        [
          {
            "body": [
              {
                "ifMatch": {
                  "$set": {
                    "data": {
                      "text": ""
                    },
                    "index": 9,
                    "lastEditedBy": "f313b510-8ff6-4ef7-8c27-070c2ae45fc1",
                    "_deleted": false
                  }
                }
              }
            ],
            "creator": "pkhexmkwbs",
            "time": 1684304286560.01
          }
        ]
      ],
      "hash": "a45ab56e61b2b3ead25c95496b2f4fc6ac75660603f10125c2a4735c83756586"
    },
    "_meta": {
      "lwt": 1684304291147.01
    },
    "_deleted": false,
    "_attachments": {},
    "_rev": "6-lxgnmepxds"
  }
]