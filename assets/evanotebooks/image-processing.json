[
  {
    "id": "wlaoUCOBkd",
    "type": "header",
    "data": {
      "text": "Autosaving",
      "level": 2
    },
    "index": 0,
    "createdBy": "7103d071-bcc7-4af3-83e1-29b664d2e991",
    "lastEditedBy": "7103d071-bcc7-4af3-83e1-29b664d2e991",
    "topic": "b474e039-8eea-4d66-9832-6946b8b455ca",
    "crdts": {
      "operations": [
        [
          {
            "creator": "ljiawbvuxk",
            "body": [
              {
                "ifMatch": {
                  "$set": {
                    "id": "wlaoUCOBkd",
                    "type": "header",
                    "data": {
                      "text": "Autosaving",
                      "level": 2
                    },
                    "index": 0,
                    "createdBy": "7103d071-bcc7-4af3-83e1-29b664d2e991",
                    "lastEditedBy": "7103d071-bcc7-4af3-83e1-29b664d2e991",
                    "topic": "b474e039-8eea-4d66-9832-6946b8b455ca"
                  }
                }
              }
            ],
            "time": 1682706018482.01
          }
        ]
      ],
      "hash": "dd225adfaa6e8a936b2febbb227b3e027b32583cf8818af9281b92e927a2125e"
    },
    "_meta": {
      "lwt": 1682706018483.03
    },
    "_deleted": false,
    "_attachments": {},
    "_rev": "1-letclyidnb"
  },
  {
    "id": "FRBHkujP-G",
    "type": "code",
    "data": {
      "code": "const options = {\n    owner: \"sanchezcarlosjr\",\n    repo: \"computer-vision-and-graphics\",\n    filePath: \"assets/evanotebooks/image-processing.json\",\n    commitMessage: \"Apply MediaPipe models, open your webcam and write your algoritms with OpenCV\",\n    GITHUB_TOKEN: \"\"\n}\n\neditor.blocks.get$.pipe(\n  first(),\n  map(content =>\n    btoa(unescape(encodeURIComponent(JSON.stringify(content, null, 2).replaceAll(options.GITHUB_TOKEN, \"\"))))),\n  commitOnGitHub(options)\n)",
      "language": "javascript",
      "output": ""
    },
    "index": 1,
    "createdBy": "7103d071-bcc7-4af3-83e1-29b664d2e991",
    "lastEditedBy": "7103d071-bcc7-4af3-83e1-29b664d2e991",
    "topic": "b474e039-8eea-4d66-9832-6946b8b455ca",
    "crdts": {
      "operations": [
        [
          {
            "creator": "ljiawbvuxk",
            "body": [
              {
                "ifMatch": {
                  "$set": {
                    "id": "FRBHkujP-G",
                    "type": "code",
                    "data": {
                      "code": "const options = {\n    owner: \"sanchezcarlosjr\",\n    repo: \"computer-vision-and-graphics\",\n    filePath: \"assets/evanotebooks/image-processing.json\",\n    commitMessage: \"Apply MediaPipe models, open your webcam and write your algoritms with OpenCV\",\n    GITHUB_TOKEN: \"\"\n}\n\neditor.blocks.get$.pipe(\n  first(),\n  map(content =>\n    btoa(unescape(encodeURIComponent(JSON.stringify(content, null, 2).replaceAll(options.GITHUB_TOKEN, \"\"))))),\n  commitOnGitHub(options)\n)",
                      "language": "javascript",
                      "output": ""
                    },
                    "index": 1,
                    "createdBy": "7103d071-bcc7-4af3-83e1-29b664d2e991",
                    "lastEditedBy": "7103d071-bcc7-4af3-83e1-29b664d2e991",
                    "topic": "b474e039-8eea-4d66-9832-6946b8b455ca"
                  }
                }
              }
            ],
            "time": 1682706018482.02
          }
        ],
        [
          {
            "body": [
              {
                "ifMatch": {
                  "$set": {
                    "data": {
                      "code": "const options = {\n    owner: \"sanchezcarlosjr\",\n    repo: \"computer-vision-and-graphics\",\n    filePath: \"assets/evanotebooks/image-processing.json\",\n    commitMessage: \"Apply MediaPipe models, open your webcam and write your algoritms with OpenCV\",\n    GITHUB_TOKEN: \"\"\n}\n\neditor.blocks.get$.pipe(\n  first(),\n  map(content =>\n    btoa(unescape(encodeURIComponent(JSON.stringify(content, null, 2).replaceAll(options.GITHUB_TOKEN, \"\"))))),\n  commitOnGitHub(options)\n)",
                      "language": "javascript",
                      "output": ""
                    },
                    "index": 1,
                    "lastEditedBy": "7103d071-bcc7-4af3-83e1-29b664d2e991",
                    "_deleted": false
                  }
                }
              }
            ],
            "creator": "ljiawbvuxk",
            "time": 1682706097833.01
          }
        ]
      ],
      "hash": "22c0e888a7271a6768c558b0b091f347f70d3c2f28c2e1d08fe916a2bda53d53"
    },
    "_meta": {
      "lwt": 1682706097835.01
    },
    "_deleted": false,
    "_attachments": {},
    "_rev": "2-letclyidnb"
  },
  {
    "id": "R4g_a5Du9a",
    "type": "header",
    "data": {
      "text": "Open your webcam (or whatever image stream)",
      "level": 2
    },
    "index": 2,
    "createdBy": "7103d071-bcc7-4af3-83e1-29b664d2e991",
    "lastEditedBy": "7103d071-bcc7-4af3-83e1-29b664d2e991",
    "topic": "b474e039-8eea-4d66-9832-6946b8b455ca",
    "crdts": {
      "operations": [
        [
          {
            "creator": "ljiawbvuxk",
            "body": [
              {
                "ifMatch": {
                  "$set": {
                    "id": "R4g_a5Du9a",
                    "type": "header",
                    "data": {
                      "text": "Open your webcam (or whatever image stream)",
                      "level": 2
                    },
                    "index": 2,
                    "createdBy": "7103d071-bcc7-4af3-83e1-29b664d2e991",
                    "lastEditedBy": "7103d071-bcc7-4af3-83e1-29b664d2e991",
                    "topic": "b474e039-8eea-4d66-9832-6946b8b455ca"
                  }
                }
              }
            ],
            "time": 1682706018482.03
          }
        ]
      ],
      "hash": "dd225adfaa6e8a936b2febbb227b3e027b32583cf8818af9281b92e927a2125e"
    },
    "_meta": {
      "lwt": 1682706018483.05
    },
    "_deleted": false,
    "_attachments": {},
    "_rev": "1-letclyidnb"
  },
  {
    "id": "mP07GtjkgW",
    "type": "code",
    "data": {
      "code": "captureStream().pipe(\n  imshow()\n)",
      "language": "javascript",
      "output": ""
    },
    "index": 3,
    "createdBy": "7103d071-bcc7-4af3-83e1-29b664d2e991",
    "lastEditedBy": "7103d071-bcc7-4af3-83e1-29b664d2e991",
    "topic": "b474e039-8eea-4d66-9832-6946b8b455ca",
    "crdts": {
      "operations": [
        [
          {
            "creator": "ljiawbvuxk",
            "body": [
              {
                "ifMatch": {
                  "$set": {
                    "id": "mP07GtjkgW",
                    "type": "code",
                    "data": {
                      "code": "captureStream().pipe(\n  imshow()\n)",
                      "language": "javascript",
                      "output": ""
                    },
                    "index": 3,
                    "createdBy": "7103d071-bcc7-4af3-83e1-29b664d2e991",
                    "lastEditedBy": "7103d071-bcc7-4af3-83e1-29b664d2e991",
                    "topic": "b474e039-8eea-4d66-9832-6946b8b455ca"
                  }
                }
              }
            ],
            "time": 1682706018482.04
          }
        ]
      ],
      "hash": "dd225adfaa6e8a936b2febbb227b3e027b32583cf8818af9281b92e927a2125e"
    },
    "_meta": {
      "lwt": 1682706018483.06
    },
    "_deleted": false,
    "_attachments": {},
    "_rev": "1-letclyidnb"
  },
  {
    "id": "NDEQydY8Is",
    "type": "header",
    "data": {
      "text": "Transform your image stream to gray scales",
      "level": 2
    },
    "index": 4,
    "createdBy": "7103d071-bcc7-4af3-83e1-29b664d2e991",
    "lastEditedBy": "7103d071-bcc7-4af3-83e1-29b664d2e991",
    "topic": "b474e039-8eea-4d66-9832-6946b8b455ca",
    "crdts": {
      "operations": [
        [
          {
            "creator": "ljiawbvuxk",
            "body": [
              {
                "ifMatch": {
                  "$set": {
                    "id": "NDEQydY8Is",
                    "type": "header",
                    "data": {
                      "text": "Transform your image stream to gray scales",
                      "level": 2
                    },
                    "index": 4,
                    "createdBy": "7103d071-bcc7-4af3-83e1-29b664d2e991",
                    "lastEditedBy": "7103d071-bcc7-4af3-83e1-29b664d2e991",
                    "topic": "b474e039-8eea-4d66-9832-6946b8b455ca"
                  }
                }
              }
            ],
            "time": 1682706018482.05
          }
        ]
      ],
      "hash": "dd225adfaa6e8a936b2febbb227b3e027b32583cf8818af9281b92e927a2125e"
    },
    "_meta": {
      "lwt": 1682706018483.07
    },
    "_deleted": false,
    "_attachments": {},
    "_rev": "1-letclyidnb"
  },
  {
    "id": "ppj2tO-btP",
    "type": "code",
    "data": {
      "code": "captureStream().pipe(\n  imshow(),\n  concatMap(({message:ctx}) => importOpenCV.pipe(\n    tap((cv => {\n       let imgData = ctx.getImageData(0, 0, ctx.canvas.width, ctx.canvas.height)\n       let src = cv.matFromImageData(imgData)\n       let dst = new cv.Mat()\n       cv.cvtColor(src, dst, cv.COLOR_RGBA2GRAY)\n       cv.imshow(ctx.canvas, dst)\n     })\n   )\n  ))\n)",
      "language": "javascript",
      "output": ""
    },
    "index": 5,
    "createdBy": "7103d071-bcc7-4af3-83e1-29b664d2e991",
    "lastEditedBy": "7103d071-bcc7-4af3-83e1-29b664d2e991",
    "topic": "b474e039-8eea-4d66-9832-6946b8b455ca",
    "crdts": {
      "operations": [
        [
          {
            "creator": "ljiawbvuxk",
            "body": [
              {
                "ifMatch": {
                  "$set": {
                    "id": "ppj2tO-btP",
                    "type": "code",
                    "data": {
                      "code": "captureStream().pipe(\n  imshow(),\n  concatMap(({message:ctx}) => importOpenCV.pipe(\n    tap((cv => {\n       let imgData = ctx.getImageData(0, 0, ctx.canvas.width, ctx.canvas.height)\n       let src = cv.matFromImageData(imgData)\n       let dst = new cv.Mat()\n       cv.cvtColor(src, dst, cv.COLOR_RGBA2GRAY)\n       cv.imshow(ctx.canvas, dst)\n     })\n   )\n  ))\n)",
                      "language": "javascript",
                      "output": "<canvas width=\"640\" height=\"480\"></canvas>"
                    },
                    "index": 5,
                    "createdBy": "7103d071-bcc7-4af3-83e1-29b664d2e991",
                    "lastEditedBy": "7103d071-bcc7-4af3-83e1-29b664d2e991",
                    "topic": "b474e039-8eea-4d66-9832-6946b8b455ca"
                  }
                }
              }
            ],
            "time": 1682706018483.01
          }
        ],
        [
          {
            "body": [
              {
                "ifMatch": {
                  "$set": {
                    "data": {
                      "code": "captureStream().pipe(\n  imshow(),\n  concatMap(({message:ctx}) => importOpenCV.pipe(\n    tap((cv => {\n       let imgData = ctx.getImageData(0, 0, ctx.canvas.width, ctx.canvas.height)\n       let src = cv.matFromImageData(imgData)\n       let dst = new cv.Mat()\n       cv.cvtColor(src, dst, cv.COLOR_RGBA2GRAY)\n       cv.imshow(ctx.canvas, dst)\n     })\n   )\n  ))\n)",
                      "language": "javascript",
                      "output": ""
                    },
                    "index": 5,
                    "lastEditedBy": "7103d071-bcc7-4af3-83e1-29b664d2e991",
                    "_deleted": false
                  }
                }
              }
            ],
            "creator": "ljiawbvuxk",
            "time": 1682706107850.01
          }
        ]
      ],
      "hash": "22c0e888a7271a6768c558b0b091f347f70d3c2f28c2e1d08fe916a2bda53d53"
    },
    "_meta": {
      "lwt": 1682706107850.02
    },
    "_deleted": false,
    "_attachments": {},
    "_rev": "2-letclyidnb"
  },
  {
    "id": "dk2ozjEMKB",
    "type": "header",
    "data": {
      "text": "Detect emotions",
      "level": 2
    },
    "index": 6,
    "createdBy": "7103d071-bcc7-4af3-83e1-29b664d2e991",
    "lastEditedBy": "7103d071-bcc7-4af3-83e1-29b664d2e991",
    "topic": "b474e039-8eea-4d66-9832-6946b8b455ca",
    "crdts": {
      "operations": [
        [
          {
            "creator": "ljiawbvuxk",
            "body": [
              {
                "ifMatch": {
                  "$set": {
                    "id": "dk2ozjEMKB",
                    "type": "header",
                    "data": {
                      "text": "",
                      "level": 2
                    },
                    "index": 6,
                    "createdBy": "7103d071-bcc7-4af3-83e1-29b664d2e991",
                    "lastEditedBy": "7103d071-bcc7-4af3-83e1-29b664d2e991",
                    "topic": "b474e039-8eea-4d66-9832-6946b8b455ca"
                  }
                }
              }
            ],
            "time": 1682706103044.01
          }
        ],
        [
          {
            "body": [
              {
                "ifMatch": {
                  "$set": {
                    "data": {
                      "text": "Tr",
                      "level": 2
                    },
                    "index": 6,
                    "lastEditedBy": "7103d071-bcc7-4af3-83e1-29b664d2e991",
                    "_deleted": false
                  }
                }
              }
            ],
            "creator": "ljiawbvuxk",
            "time": 1682706104332.01
          }
        ],
        [
          {
            "body": [
              {
                "ifMatch": {
                  "$set": {
                    "data": {
                      "text": "Transform&nbsp;",
                      "level": 2
                    },
                    "index": 6,
                    "lastEditedBy": "7103d071-bcc7-4af3-83e1-29b664d2e991",
                    "_deleted": false
                  }
                }
              }
            ],
            "creator": "ljiawbvuxk",
            "time": 1682706110307.01
          }
        ],
        [
          {
            "body": [
              {
                "ifMatch": {
                  "$set": {
                    "data": {
                      "text": "Detect emotions",
                      "level": 2
                    },
                    "index": 6,
                    "lastEditedBy": "7103d071-bcc7-4af3-83e1-29b664d2e991",
                    "_deleted": false
                  }
                }
              }
            ],
            "creator": "ljiawbvuxk",
            "time": 1682706120355.01
          }
        ]
      ],
      "hash": "6d22cc75006789fc27393f61d8475240081a79a05e64d5bbc377dd46a1d6503d"
    },
    "_meta": {
      "lwt": 1682706120356.01
    },
    "_deleted": false,
    "_attachments": {},
    "_rev": "5-letclyidnb"
  },
  {
    "id": "_xvsTTmEw6",
    "type": "code",
    "data": {
      "code": "import Human from 'https://cdn.jsdelivr.net/npm/@vladmandic/human@3.0.5/+esm'\n\nconst humanConfig = { // user configuration for human, used to fine-tune behavior\n  debug: true,\n  modelBasePath: 'https://vladmandic.github.io/human-models/models/',\n  filter: { enabled: true, equalization: false, flip: true },\n  face: {\n    enabled: true,\n    detector: { enabled: false },\n    iris: { enabled: false },\n    description: { enabled: false },\n    emotion: { enabled: true },\n    antispoof: { enabled: false },\n    liveness: { enabled: false },\n  },\n  body: { enabled: false },\n  hand: { enabled: false },\n  object: { enabled: false },\n  gesture: { enabled: false },\n  segmentation: { enabled: false },\n}\n\nconst human = new Human(humanConfig)\ncaptureStream().pipe(\n  concatMap(x => human.detect(x.message)),\n  map(x => x.face[0].emotion),\n  display\n)",
      "language": "javascript",
      "output": ""
    },
    "index": 7,
    "createdBy": "7103d071-bcc7-4af3-83e1-29b664d2e991",
    "lastEditedBy": "7103d071-bcc7-4af3-83e1-29b664d2e991",
    "topic": "b474e039-8eea-4d66-9832-6946b8b455ca",
    "crdts": {
      "operations": [
        [
          {
            "creator": "ljiawbvuxk",
            "body": [
              {
                "ifMatch": {
                  "$set": {
                    "id": "_xvsTTmEw6",
                    "type": "code",
                    "data": {
                      "code": "",
                      "language": "javascript",
                      "output": ""
                    },
                    "index": 7,
                    "createdBy": "7103d071-bcc7-4af3-83e1-29b664d2e991",
                    "lastEditedBy": "7103d071-bcc7-4af3-83e1-29b664d2e991",
                    "topic": "b474e039-8eea-4d66-9832-6946b8b455ca"
                  }
                }
              }
            ],
            "time": 1682706124609.01
          }
        ],
        [
          {
            "body": [
              {
                "ifMatch": {
                  "$set": {
                    "data": {
                      "code": "import Human from 'https://cdn.jsdelivr.net/npm/@vladmandic/human@3.0.5/+esm'\n\nconst humanConfig = { // user configuration for human, used to fine-tune behavior\n  debug: true,\n  modelBasePath: 'https://vladmandic.github.io/human-models/models/',\n  filter: { enabled: true, equalization: false, flip: true },\n  face: {\n    enabled: true,\n    detector: { enabled: false },\n    iris: { enabled: false },\n    description: { enabled: false },\n    emotion: { enabled: true },\n    antispoof: { enabled: false },\n    liveness: { enabled: false },\n  },\n  body: { enabled: false },\n  hand: { enabled: false },\n  object: { enabled: false },\n  gesture: { enabled: false },\n  segmentation: { enabled: false },\n}\n\nconst human = new Human(humanConfig)\ncaptureStream().pipe(\n  first(),\n  concatMap(x => human.detect(x.message)),\n  map(x => x.face[0].emotion),\n  display\n)",
                      "language": "javascript",
                      "output": ""
                    },
                    "index": 7,
                    "lastEditedBy": "7103d071-bcc7-4af3-83e1-29b664d2e991",
                    "_deleted": false
                  }
                }
              }
            ],
            "creator": "ljiawbvuxk",
            "time": 1682706125571.02
          }
        ],
        [
          {
            "body": [
              {
                "ifMatch": {
                  "$set": {
                    "data": {
                      "code": "import Human from 'https://cdn.jsdelivr.net/npm/@vladmandic/human@3.0.5/+esm'\n\nconst humanConfig = { // user configuration for human, used to fine-tune behavior\n  debug: true,\n  modelBasePath: 'https://vladmandic.github.io/human-models/models/',\n  filter: { enabled: true, equalization: false, flip: true },\n  face: {\n    enabled: true,\n    detector: { enabled: false },\n    iris: { enabled: false },\n    description: { enabled: false },\n    emotion: { enabled: true },\n    antispoof: { enabled: false },\n    liveness: { enabled: false },\n  },\n  body: { enabled: false },\n  hand: { enabled: false },\n  object: { enabled: false },\n  gesture: { enabled: false },\n  segmentation: { enabled: false },\n}\n\nconst human = new Human(humanConfig)\ncaptureStream().pipe(\n  concatMap(x => human.detect(x.message)),\n  map(x => x.face[0].emotion),\n  display\n)",
                      "language": "javascript",
                      "output": ""
                    },
                    "index": 7,
                    "lastEditedBy": "7103d071-bcc7-4af3-83e1-29b664d2e991",
                    "_deleted": false
                  }
                }
              }
            ],
            "creator": "ljiawbvuxk",
            "time": 1682706155605.01
          }
        ]
      ],
      "hash": "48e32c3c65cabc837e708b08d56d557fdcfd7551196c5e867ec1be105e28fbc3"
    },
    "_meta": {
      "lwt": 1682706155607.01
    },
    "_deleted": false,
    "_attachments": {},
    "_rev": "6-letclyidnb"
  },
  {
    "id": "DYdM7xJNzK",
    "type": "paragraph",
    "data": {
      "text": ""
    },
    "index": 8,
    "createdBy": "7103d071-bcc7-4af3-83e1-29b664d2e991",
    "lastEditedBy": "7103d071-bcc7-4af3-83e1-29b664d2e991",
    "topic": "b474e039-8eea-4d66-9832-6946b8b455ca",
    "crdts": {
      "operations": [
        [
          {
            "creator": "ljiawbvuxk",
            "body": [
              {
                "ifMatch": {
                  "$set": {
                    "id": "DYdM7xJNzK",
                    "type": "paragraph",
                    "data": {
                      "text": ""
                    },
                    "index": 6,
                    "createdBy": "7103d071-bcc7-4af3-83e1-29b664d2e991",
                    "lastEditedBy": "7103d071-bcc7-4af3-83e1-29b664d2e991",
                    "topic": "b474e039-8eea-4d66-9832-6946b8b455ca"
                  }
                }
              }
            ],
            "time": 1682706018483.02
          }
        ]
      ],
      "hash": "dd225adfaa6e8a936b2febbb227b3e027b32583cf8818af9281b92e927a2125e"
    },
    "_meta": {
      "lwt": 1682706150645.01
    },
    "_deleted": false,
    "_attachments": {},
    "_rev": "5-letclyidnb"
  }
]